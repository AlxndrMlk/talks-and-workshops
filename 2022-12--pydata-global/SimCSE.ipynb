{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597bc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simcse import SimCSE\n",
    "\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb76539",
   "metadata": {},
   "source": [
    "# BERT's Achilles' heel? \n",
    "#### Applying contrastive learning to fight anisotropy in language models.\n",
    "\n",
    "PyData Global 2022, 2022-12-02\n",
    "\n",
    "\n",
    "#### Abstract\n",
    "Transformer models became state-of-the-art in natural language processing. Word representations learned by these models offer great flexibility for many types of downstream tasks from classification to summarization. Nonetheless, these representations suffer from certain conditions that impair their effectiveness. Researchers have demonstrated that BERT and GPT embeddings tend to cluster in a narrow cone of the embedding space which leads to unwanted consequences (e.g. spurious similarities between unrelated words). During the talk we’ll introduce SimCSE – a contrastive learning method that helps to regularize the embeddings and reduce the problem of anisotropy. We will demonstrate how SimCSE can be implemented in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c4ba7",
   "metadata": {},
   "source": [
    "#### Installation\n",
    "\n",
    "To run the notebook, create and activate a **Conda** environemnt using `simcse.yml` file.\n",
    "\n",
    "\n",
    "To install SimCSE only:\n",
    "\n",
    "`pip install simcse`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493323a3",
   "metadata": {},
   "source": [
    "## Using with SimCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364e4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc87c0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings\n",
    "embeddings = model.encode('Attending PyData Global is awesome!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c801df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14462978]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5483091]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute similarities\n",
    "sentences_a = ['Attending PyData Global is awesome!']\n",
    "sentences_b = ['Jenny is hungry :(']\n",
    "similarities = model.similarity(sentences_a, sentences_b)\n",
    "print(similarities)\n",
    "\n",
    "sentences_a = ['Attending PyData Global is awesome!']\n",
    "sentences_b = ['Python conferences are great!']\n",
    "similarities = model.similarity(sentences_a, sentences_b)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e013da",
   "metadata": {},
   "source": [
    "## Using with Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59a2e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "\n",
    "# Tokenize the inputs\n",
    "texts = [\n",
    "    'I ate an apple',\n",
    "    'Jane ate an apple',\n",
    "    'Python conferences are great!'\n",
    "]\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Get the embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**inputs, output_hidden_states=True, return_dict=True).pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "590a9724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between \"I ate an apple\" and \"Jane ate an apple\" is: 0.855\n",
      "Cosine similarity between \"I ate an apple\" and \"Python conferences are great!\" is: 0.083\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarities => higher values -> more similarity\n",
    "cosine_sim_0_1 = 1 - cosine(embeddings[0], embeddings[1])\n",
    "cosine_sim_0_2 = 1 - cosine(embeddings[0], embeddings[2])\n",
    "\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[1], cosine_sim_0_1))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[2], cosine_sim_0_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d94a31",
   "metadata": {},
   "source": [
    "## Training your own SimCSE\n",
    "\n",
    "Check the instructions here: https://github.com/princeton-nlp/SimCSE#training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:simcse]",
   "language": "python",
   "name": "conda-env-simcse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
