{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "597bc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simcse import SimCSE\n",
    "\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493323a3",
   "metadata": {},
   "source": [
    "## Using with SimCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364e4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "embeddings = model.encode('Attending PyData Global is awesome!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c801df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities\n",
    "sentences_a = ['Attending PyData Global is awesome!']\n",
    "sentences_b = ['Jenny is hungry :(']\n",
    "similarities = model.similarity(sentences_a, sentences_b)\n",
    "print(similarities)\n",
    "\n",
    "sentences_a = ['Attending PyData Global is awesome!']\n",
    "sentences_b = ['Python conferences are great!']\n",
    "similarities = model.similarity(sentences_a, sentences_b)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e013da",
   "metadata": {},
   "source": [
    "## Using with Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "\n",
    "# Tokenize the inputs\n",
    "texts = [\n",
    "    'I ate an apple',\n",
    "    'Jane ate an apple',\n",
    "    'Python conferences are great!'\n",
    "]\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Get the embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**inputs, output_hidden_states=True, return_dict=True).pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarities => higher values -> more similarity\n",
    "cosine_sim_0_1 = 1 - cosine(embeddings[0], embeddings[1])\n",
    "cosine_sim_0_2 = 1 - cosine(embeddings[0], embeddings[2])\n",
    "\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[1], cosine_sim_0_1))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[2], cosine_sim_0_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8338da83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:simcse]",
   "language": "python",
   "name": "conda-env-simcse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
