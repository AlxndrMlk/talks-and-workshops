{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f45ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.8.0\n",
    "# !pip install spektral==1.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32544b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import spektral as spktrl\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "from spektral.datasets import Citation, TUDataset\n",
    "from spektral.data import SingleLoader, DisjointLoader\n",
    "from spektral.data import Dataset, Graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c91f641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Spektral 1.0.6\n",
      "Using TensorFlow 2.8.0\n",
      "Physical GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(f'Using Spektral {spktrl.__version__}')\n",
    "print(f'Using TensorFlow {tf.__version__}')\n",
    "print('Physical GPUs:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edddd1ac",
   "metadata": {},
   "source": [
    "# Practical graph neural networks in Python with TensorFlow and Spektral\n",
    "\n",
    "*PyData Berlin, 2022.04.13*\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "\n",
    "Graph neural networks (GNNs) have become one of the hottest research topics in recent years. Their popularity is reinforced by hugely successful industry applications in social networks, biology, chemistry, neuroscience and many other areas. One of the main challenges faced by data scientists and researchers who want to apply graph networks in their work is that they require different data structures and a slightly different training approach than traditional deep learning models. During the workshop we’ll demonstrate how to implement graph neural networks, how to prepare your data and – finally – how to train a GNN model for node-level and graph-level tasks using Spektral and TensorFlow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecd400",
   "metadata": {},
   "source": [
    "## 1. Node classification with functional API\n",
    "\n",
    "We'll perform node classification using [CORA](https://relational.fit.cvut.cz/dataset/CORA) citation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff02a2",
   "metadata": {},
   "source": [
    "### 1.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc400285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\envs\\tf-spektral-minimal\\lib\\site-packages\\scipy\\sparse\\_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = Citation(\"cora\", normalize_x=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a3073",
   "metadata": {},
   "source": [
    "### 1.2 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557bccd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 10556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's understand the adjacency matrix\n",
    "dataset[0].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a549b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's understand labels\n",
    "dataset[0].y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929e4c2",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.1\n",
    "\n",
    "Display the label of node 77. \n",
    "\n",
    "\n",
    "What is the label of this node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5b1071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "dataset[0].y[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7284bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1433)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let't understand features\n",
    "dataset[0].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cdcd6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of non-zero featueres over nodes\n",
    "plt.hist((dataset[0].x > 0).sum(axis=1), alpha=.7, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47e5a886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True, ..., False, False, False]),\n",
       " array([False, False, False, ..., False, False, False]),\n",
       " array([False, False, False, ...,  True,  True,  True]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understand the masks \n",
    "\n",
    "# Training, val, test \n",
    "dataset.mask_tr, dataset.mask_va, dataset.mask_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae7db5",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.2\n",
    "\n",
    "Compute the number of training, validation and test examples. \n",
    "\n",
    "What are these numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "674d36d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 140\n",
      "Number of validation examples: 500\n",
      "Number of test examples: 1000\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print(f'Number of training examples: {dataset.mask_tr.sum()}')\n",
    "print(f'Number of validation examples: {dataset.mask_va.sum()}')\n",
    "print(f'Number of test examples: {dataset.mask_te.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946711df",
   "metadata": {},
   "source": [
    "### 1.3 Prepare dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1dfb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_tr = SingleLoader(dataset)\n",
    "loader_va = SingleLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962029a",
   "metadata": {},
   "source": [
    "### 1.4 Build and compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434cfe42",
   "metadata": {},
   "source": [
    "#### 1.4.1 Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c35571d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "in_x = keras.Input(shape=(dataset[0].x.shape[1],))\n",
    "in_a = keras.Input(shape=(dataset[0].a.shape[0],), sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96a0e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout on features (but not adjacency matrix)\n",
    "dropout_1 = keras.layers.Dropout(.1)(in_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8a91e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add GAT layer\n",
    "gat_layer_1 = spktrl.layers.GATConv(\n",
    "    channels=16,\n",
    "    attn_heads=8,\n",
    "    concat_heads=True,\n",
    "    dropout_rate=.05,\n",
    "    activation='selu',\n",
    "    kernel_initializer='lecun_normal'\n",
    ")([dropout_1, in_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016b309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout\n",
    "dropout_2 = keras.layers.Dropout(.1)(gat_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945040e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final GAT layer\n",
    "gat_out = spktrl.layers.GATConv(\n",
    "    channels=dataset[0].n_labels,\n",
    "    attn_heads=8,\n",
    "    concat_heads=False,\n",
    "    dropout_rate=.05,\n",
    "    activation='softmax'\n",
    ")([dropout_2, in_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "588b2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enclose the layers in the model\n",
    "model = keras.Model(inputs=[in_x, in_a], outputs=gat_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968496c1",
   "metadata": {},
   "source": [
    "#### 1.4.2 Setup and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfd73740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some params\n",
    "LR = 5e-3 # 5e-3  # Learning rate\n",
    "EPOCHS = 10000  # Number of training epochs\n",
    "PATIENCE = 30  # Patience for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f8d7e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1433)]       0           []                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1433)         0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2708)]       0           []                               \n",
      "                                                                                                  \n",
      " gat_conv (GATConv)             (None, 128)          183808      ['dropout[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['gat_conv[0][0]']               \n",
      "                                                                                                  \n",
      " gat_conv_1 (GATConv)           (None, 7)            7287        ['dropout_1[0][0]',              \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 191,095\n",
      "Trainable params: 191,095\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\envs\\tf-spektral-minimal\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(lr=LR)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.CategoricalCrossentropy(reduction='sum'),\n",
    "    weighted_metrics=['acc'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d66d0",
   "metadata": {},
   "source": [
    "#### 1.4.3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "369279a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/1 [==============================] - 6s 6s/step - loss: 5269.5791 - acc: 0.1488 - val_loss: 5251.5698 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 5251.5752 - acc: 0.3021 - val_loss: 5224.3330 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5224.2803 - acc: 0.3021 - val_loss: 5186.9009 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5187.0742 - acc: 0.3021 - val_loss: 5139.6865 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5139.3828 - acc: 0.3021 - val_loss: 5084.0098 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5084.6245 - acc: 0.3021 - val_loss: 5021.9956 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5021.7363 - acc: 0.3021 - val_loss: 4956.6855 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4957.6719 - acc: 0.3021 - val_loss: 4891.7559 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4891.6562 - acc: 0.3021 - val_loss: 4831.0566 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4831.8584 - acc: 0.3021 - val_loss: 4777.9180 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4779.9917 - acc: 0.3021 - val_loss: 4733.9302 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4735.6968 - acc: 0.3021 - val_loss: 4696.9087 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4698.5210 - acc: 0.3021 - val_loss: 4660.4155 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4661.5093 - acc: 0.3021 - val_loss: 4617.0112 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4618.1631 - acc: 0.3021 - val_loss: 4562.8643 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4565.6333 - acc: 0.3021 - val_loss: 4498.6777 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4505.1157 - acc: 0.3021 - val_loss: 4427.1177 - val_acc: 0.3032 - lr: 0.0050\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4427.8105 - acc: 0.3021 - val_loss: 4350.9600 - val_acc: 0.3043 - lr: 0.0050\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4356.8809 - acc: 0.3032 - val_loss: 4271.8730 - val_acc: 0.3058 - lr: 0.0050\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4270.6523 - acc: 0.3061 - val_loss: 4190.2520 - val_acc: 0.3172 - lr: 0.0050\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4191.9707 - acc: 0.3187 - val_loss: 4105.6704 - val_acc: 0.3722 - lr: 0.0050\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4107.6519 - acc: 0.3800 - val_loss: 4017.2400 - val_acc: 0.4413 - lr: 0.0050\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4016.0891 - acc: 0.4354 - val_loss: 3923.8784 - val_acc: 0.5270 - lr: 0.0050\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3920.7249 - acc: 0.5255 - val_loss: 3824.6577 - val_acc: 0.5971 - lr: 0.0050\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3830.8337 - acc: 0.6008 - val_loss: 3719.0535 - val_acc: 0.6555 - lr: 0.0050\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3713.8452 - acc: 0.6477 - val_loss: 3607.0088 - val_acc: 0.6869 - lr: 0.0050\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3610.9351 - acc: 0.6854 - val_loss: 3489.1458 - val_acc: 0.7083 - lr: 0.0050\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3485.2527 - acc: 0.7086 - val_loss: 3366.4827 - val_acc: 0.7219 - lr: 0.0050\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3380.8784 - acc: 0.7190 - val_loss: 3240.4741 - val_acc: 0.7312 - lr: 0.0050\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3251.8535 - acc: 0.7293 - val_loss: 3112.8049 - val_acc: 0.7456 - lr: 0.0050\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3109.7969 - acc: 0.7400 - val_loss: 2985.3157 - val_acc: 0.7552 - lr: 0.0050\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2985.3926 - acc: 0.7522 - val_loss: 2859.7561 - val_acc: 0.7626 - lr: 0.0050\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2854.0464 - acc: 0.7692 - val_loss: 2737.4521 - val_acc: 0.7729 - lr: 0.0050\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2742.7166 - acc: 0.7733 - val_loss: 2619.4136 - val_acc: 0.7866 - lr: 0.0050\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2612.6716 - acc: 0.7843 - val_loss: 2506.1833 - val_acc: 0.7958 - lr: 0.0050\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2519.8286 - acc: 0.7973 - val_loss: 2398.1428 - val_acc: 0.8050 - lr: 0.0050\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2402.6782 - acc: 0.8035 - val_loss: 2295.4727 - val_acc: 0.8165 - lr: 0.0050\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2298.3210 - acc: 0.8113 - val_loss: 2198.3333 - val_acc: 0.8257 - lr: 0.0050\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2205.9766 - acc: 0.8220 - val_loss: 2106.8767 - val_acc: 0.8309 - lr: 0.0050\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2109.7739 - acc: 0.8275 - val_loss: 2020.9797 - val_acc: 0.8401 - lr: 0.0050\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2040.4467 - acc: 0.8383 - val_loss: 1940.2906 - val_acc: 0.8482 - lr: 0.0050\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1952.4468 - acc: 0.8497 - val_loss: 1864.3624 - val_acc: 0.8530 - lr: 0.0050\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1882.8002 - acc: 0.8493 - val_loss: 1792.7744 - val_acc: 0.8564 - lr: 0.0050\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1815.0979 - acc: 0.8586 - val_loss: 1725.1718 - val_acc: 0.8604 - lr: 0.0050\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1733.8506 - acc: 0.8575 - val_loss: 1661.3724 - val_acc: 0.8641 - lr: 0.0050\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1671.5594 - acc: 0.8597 - val_loss: 1601.1707 - val_acc: 0.8696 - lr: 0.0050\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1614.1604 - acc: 0.8652 - val_loss: 1544.2256 - val_acc: 0.8704 - lr: 0.0050\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1580.3835 - acc: 0.8722 - val_loss: 1490.2728 - val_acc: 0.8737 - lr: 0.0050\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1499.8973 - acc: 0.8704 - val_loss: 1439.0909 - val_acc: 0.8767 - lr: 0.0050\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1454.6646 - acc: 0.8737 - val_loss: 1390.4773 - val_acc: 0.8807 - lr: 0.0050\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1397.5125 - acc: 0.8811 - val_loss: 1344.1775 - val_acc: 0.8826 - lr: 0.0050\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1364.4454 - acc: 0.8770 - val_loss: 1300.0645 - val_acc: 0.8844 - lr: 0.0050\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1326.0480 - acc: 0.8844 - val_loss: 1258.0303 - val_acc: 0.8863 - lr: 0.0050\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1281.4186 - acc: 0.8866 - val_loss: 1218.0195 - val_acc: 0.8874 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1235.7917 - acc: 0.8855 - val_loss: 1180.0026 - val_acc: 0.8903 - lr: 0.0050\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1192.7092 - acc: 0.8914 - val_loss: 1143.9248 - val_acc: 0.8922 - lr: 0.0050\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1166.3488 - acc: 0.8907 - val_loss: 1109.7523 - val_acc: 0.8936 - lr: 0.0050\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1141.1881 - acc: 0.8892 - val_loss: 1077.3516 - val_acc: 0.8936 - lr: 0.0050\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1095.5416 - acc: 0.8944 - val_loss: 1046.7091 - val_acc: 0.8970 - lr: 0.0050\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1066.6796 - acc: 0.8948 - val_loss: 1017.8554 - val_acc: 0.9007 - lr: 0.0050\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1037.0337 - acc: 0.9018 - val_loss: 990.6141 - val_acc: 0.9014 - lr: 0.0050\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1027.4165 - acc: 0.8988 - val_loss: 964.9200 - val_acc: 0.9029 - lr: 0.0050\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 986.2141 - acc: 0.9018 - val_loss: 940.6005 - val_acc: 0.9051 - lr: 0.0050\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 965.9670 - acc: 0.9032 - val_loss: 917.5986 - val_acc: 0.9066 - lr: 0.0050\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 943.1537 - acc: 0.9055 - val_loss: 895.9930 - val_acc: 0.9084 - lr: 0.0050\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 926.6412 - acc: 0.9025 - val_loss: 875.6830 - val_acc: 0.9103 - lr: 0.0050\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 896.5945 - acc: 0.9044 - val_loss: 856.6255 - val_acc: 0.9114 - lr: 0.0050\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 886.1196 - acc: 0.9040 - val_loss: 838.6034 - val_acc: 0.9129 - lr: 0.0050\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 861.5866 - acc: 0.9084 - val_loss: 821.5830 - val_acc: 0.9132 - lr: 0.0050\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 842.4769 - acc: 0.9114 - val_loss: 805.4417 - val_acc: 0.9154 - lr: 0.0050\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 823.8242 - acc: 0.9103 - val_loss: 790.2225 - val_acc: 0.9169 - lr: 0.0050\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 820.9644 - acc: 0.9125 - val_loss: 775.8637 - val_acc: 0.9184 - lr: 0.0050\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 789.0794 - acc: 0.9154 - val_loss: 762.2228 - val_acc: 0.9180 - lr: 0.0050\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 796.8683 - acc: 0.9136 - val_loss: 749.2134 - val_acc: 0.9180 - lr: 0.0050\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 766.3945 - acc: 0.9177 - val_loss: 736.8334 - val_acc: 0.9173 - lr: 0.0050\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 761.2294 - acc: 0.9129 - val_loss: 725.0585 - val_acc: 0.9191 - lr: 0.0050\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 752.2963 - acc: 0.9151 - val_loss: 713.9175 - val_acc: 0.9195 - lr: 0.0050\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 742.0903 - acc: 0.9173 - val_loss: 703.3417 - val_acc: 0.9221 - lr: 0.0050\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 721.5233 - acc: 0.9184 - val_loss: 693.2645 - val_acc: 0.9225 - lr: 0.0050\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 723.7804 - acc: 0.9195 - val_loss: 683.6559 - val_acc: 0.9239 - lr: 0.0050\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 706.4901 - acc: 0.9158 - val_loss: 674.4381 - val_acc: 0.9250 - lr: 0.0050\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 695.5400 - acc: 0.9221 - val_loss: 665.5332 - val_acc: 0.9254 - lr: 0.0050\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 690.1175 - acc: 0.9232 - val_loss: 657.0449 - val_acc: 0.9269 - lr: 0.0050\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 683.9655 - acc: 0.9188 - val_loss: 648.6181 - val_acc: 0.9276 - lr: 0.0050\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 681.5261 - acc: 0.9199 - val_loss: 640.3720 - val_acc: 0.9280 - lr: 0.0050\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 668.4221 - acc: 0.9225 - val_loss: 632.5204 - val_acc: 0.9273 - lr: 0.0050\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 665.6927 - acc: 0.9202 - val_loss: 625.0342 - val_acc: 0.9276 - lr: 0.0050\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 649.4405 - acc: 0.9254 - val_loss: 617.8851 - val_acc: 0.9284 - lr: 0.0050\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 641.5067 - acc: 0.9228 - val_loss: 610.9193 - val_acc: 0.9287 - lr: 0.0050\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 632.2428 - acc: 0.9287 - val_loss: 604.0635 - val_acc: 0.9287 - lr: 0.0050\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 628.0428 - acc: 0.9273 - val_loss: 597.2743 - val_acc: 0.9291 - lr: 0.0050\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 621.0227 - acc: 0.9265 - val_loss: 590.5900 - val_acc: 0.9302 - lr: 0.0050\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 615.7864 - acc: 0.9280 - val_loss: 584.1436 - val_acc: 0.9313 - lr: 0.0050\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 597.6378 - acc: 0.9324 - val_loss: 578.0730 - val_acc: 0.9317 - lr: 0.0050\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 604.7535 - acc: 0.9265 - val_loss: 572.2458 - val_acc: 0.9324 - lr: 0.0050\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 602.5329 - acc: 0.9306 - val_loss: 566.4257 - val_acc: 0.9339 - lr: 0.0050\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 588.7867 - acc: 0.9276 - val_loss: 560.6792 - val_acc: 0.9350 - lr: 0.0050\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 590.6836 - acc: 0.9280 - val_loss: 555.1236 - val_acc: 0.9354 - lr: 0.0050\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 574.1228 - acc: 0.9295 - val_loss: 549.7001 - val_acc: 0.9343 - lr: 0.0050\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 567.5002 - acc: 0.9321 - val_loss: 544.3130 - val_acc: 0.9361 - lr: 0.0050\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 566.3769 - acc: 0.9339 - val_loss: 539.0162 - val_acc: 0.9361 - lr: 0.0050\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 557.3027 - acc: 0.9298 - val_loss: 533.7975 - val_acc: 0.9354 - lr: 0.0050\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 561.6349 - acc: 0.9284 - val_loss: 528.7173 - val_acc: 0.9354 - lr: 0.0050\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 555.5361 - acc: 0.9332 - val_loss: 523.7521 - val_acc: 0.9361 - lr: 0.0050\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 552.0467 - acc: 0.9328 - val_loss: 518.9406 - val_acc: 0.9365 - lr: 0.0050\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 552.4410 - acc: 0.9309 - val_loss: 514.2166 - val_acc: 0.9387 - lr: 0.0050\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 539.8575 - acc: 0.9335 - val_loss: 509.5653 - val_acc: 0.9398 - lr: 0.0050\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 520.9969 - acc: 0.9369 - val_loss: 504.8648 - val_acc: 0.9409 - lr: 0.0050\n",
      "Epoch 109/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 536.1606 - acc: 0.9357 - val_loss: 500.0695 - val_acc: 0.9413 - lr: 0.0050\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 529.6281 - acc: 0.9350 - val_loss: 495.2888 - val_acc: 0.9417 - lr: 0.0050\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 523.3282 - acc: 0.9380 - val_loss: 490.6259 - val_acc: 0.9431 - lr: 0.0050\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 521.3621 - acc: 0.9376 - val_loss: 485.9068 - val_acc: 0.9439 - lr: 0.0050\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 506.7145 - acc: 0.9387 - val_loss: 481.3802 - val_acc: 0.9428 - lr: 0.0050\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 506.4189 - acc: 0.9354 - val_loss: 477.1049 - val_acc: 0.9431 - lr: 0.0050\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 508.0590 - acc: 0.9365 - val_loss: 472.8388 - val_acc: 0.9435 - lr: 0.0050\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 504.2887 - acc: 0.9339 - val_loss: 468.4883 - val_acc: 0.9442 - lr: 0.0050\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 508.8749 - acc: 0.9380 - val_loss: 464.0816 - val_acc: 0.9439 - lr: 0.0050\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 490.4008 - acc: 0.9413 - val_loss: 460.0230 - val_acc: 0.9465 - lr: 0.0050\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 484.9517 - acc: 0.9387 - val_loss: 456.1379 - val_acc: 0.9472 - lr: 0.0050\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 489.4056 - acc: 0.9380 - val_loss: 452.3018 - val_acc: 0.9479 - lr: 0.0050\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 480.5375 - acc: 0.9409 - val_loss: 448.4284 - val_acc: 0.9487 - lr: 0.0050\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 473.2854 - acc: 0.9442 - val_loss: 444.4254 - val_acc: 0.9490 - lr: 0.0050\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 476.4603 - acc: 0.9424 - val_loss: 440.0731 - val_acc: 0.9494 - lr: 0.0050\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 464.1389 - acc: 0.9446 - val_loss: 435.9531 - val_acc: 0.9490 - lr: 0.0050\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 454.5648 - acc: 0.9424 - val_loss: 432.0579 - val_acc: 0.9498 - lr: 0.0050\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 464.5096 - acc: 0.9450 - val_loss: 428.3604 - val_acc: 0.9501 - lr: 0.0050\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 458.1341 - acc: 0.9428 - val_loss: 424.5482 - val_acc: 0.9509 - lr: 0.0050\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 458.2472 - acc: 0.9442 - val_loss: 420.5806 - val_acc: 0.9509 - lr: 0.0050\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 450.9623 - acc: 0.9465 - val_loss: 416.7799 - val_acc: 0.9513 - lr: 0.0050\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 447.2917 - acc: 0.9461 - val_loss: 413.3223 - val_acc: 0.9520 - lr: 0.0050\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 446.6551 - acc: 0.9453 - val_loss: 410.0310 - val_acc: 0.9524 - lr: 0.0050\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 447.7852 - acc: 0.9465 - val_loss: 406.3780 - val_acc: 0.9524 - lr: 0.0050\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 432.5276 - acc: 0.9483 - val_loss: 402.6403 - val_acc: 0.9538 - lr: 0.0050\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 437.2329 - acc: 0.9479 - val_loss: 399.1249 - val_acc: 0.9542 - lr: 0.0050\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 427.6272 - acc: 0.9494 - val_loss: 395.6502 - val_acc: 0.9546 - lr: 0.0050\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 421.9718 - acc: 0.9476 - val_loss: 391.9657 - val_acc: 0.9546 - lr: 0.0050\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 424.6513 - acc: 0.9461 - val_loss: 388.4396 - val_acc: 0.9549 - lr: 0.0050\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 417.4334 - acc: 0.9453 - val_loss: 384.7148 - val_acc: 0.9546 - lr: 0.0050\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 415.8265 - acc: 0.9505 - val_loss: 381.0645 - val_acc: 0.9553 - lr: 0.0050\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 411.9791 - acc: 0.9479 - val_loss: 377.6599 - val_acc: 0.9538 - lr: 0.0050\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 407.0360 - acc: 0.9483 - val_loss: 374.3025 - val_acc: 0.9549 - lr: 0.0050\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 402.1073 - acc: 0.9483 - val_loss: 370.8968 - val_acc: 0.9575 - lr: 0.0050\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 400.9558 - acc: 0.9490 - val_loss: 367.6328 - val_acc: 0.9575 - lr: 0.0050\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 404.2348 - acc: 0.9487 - val_loss: 364.5555 - val_acc: 0.9586 - lr: 0.0050\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 405.9951 - acc: 0.9524 - val_loss: 361.2658 - val_acc: 0.9586 - lr: 0.0050\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 398.4932 - acc: 0.9516 - val_loss: 357.7180 - val_acc: 0.9583 - lr: 0.0050\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 378.8515 - acc: 0.9561 - val_loss: 354.4866 - val_acc: 0.9590 - lr: 0.0050\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 387.8041 - acc: 0.9535 - val_loss: 351.6768 - val_acc: 0.9586 - lr: 0.0050\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 386.7191 - acc: 0.9505 - val_loss: 349.1223 - val_acc: 0.9586 - lr: 0.0050\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 377.6672 - acc: 0.9513 - val_loss: 345.9432 - val_acc: 0.9586 - lr: 0.0050\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 381.1237 - acc: 0.9520 - val_loss: 342.4313 - val_acc: 0.9597 - lr: 0.0050\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 371.7560 - acc: 0.9520 - val_loss: 339.2497 - val_acc: 0.9609 - lr: 0.0050\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 362.4130 - acc: 0.9538 - val_loss: 336.5974 - val_acc: 0.9605 - lr: 0.0050\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 369.1153 - acc: 0.9542 - val_loss: 334.0165 - val_acc: 0.9612 - lr: 0.0050\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 358.7212 - acc: 0.9531 - val_loss: 330.5715 - val_acc: 0.9620 - lr: 0.0050\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 359.0005 - acc: 0.9557 - val_loss: 326.7680 - val_acc: 0.9616 - lr: 0.0050\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 359.5347 - acc: 0.9568 - val_loss: 323.1894 - val_acc: 0.9620 - lr: 0.0050\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 361.2686 - acc: 0.9553 - val_loss: 320.1261 - val_acc: 0.9620 - lr: 0.0050\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 345.3280 - acc: 0.9572 - val_loss: 317.1634 - val_acc: 0.9620 - lr: 0.0050\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 347.7329 - acc: 0.9590 - val_loss: 314.1706 - val_acc: 0.9616 - lr: 0.0050\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 342.0498 - acc: 0.9583 - val_loss: 311.3931 - val_acc: 0.9620 - lr: 0.0050\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 347.4997 - acc: 0.9564 - val_loss: 308.7024 - val_acc: 0.9638 - lr: 0.0050\n",
      "Epoch 163/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 335.9224 - acc: 0.9561 - val_loss: 305.5936 - val_acc: 0.9638 - lr: 0.0050\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 348.2623 - acc: 0.9575 - val_loss: 302.5217 - val_acc: 0.9634 - lr: 0.0050\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 326.9847 - acc: 0.9597 - val_loss: 299.5444 - val_acc: 0.9638 - lr: 0.0050\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 338.4331 - acc: 0.9605 - val_loss: 296.9094 - val_acc: 0.9649 - lr: 0.0050\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 334.5098 - acc: 0.9572 - val_loss: 294.3071 - val_acc: 0.9649 - lr: 0.0050\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 332.8525 - acc: 0.9583 - val_loss: 291.6598 - val_acc: 0.9657 - lr: 0.0050\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 324.8434 - acc: 0.9597 - val_loss: 288.7597 - val_acc: 0.9653 - lr: 0.0050\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 323.6698 - acc: 0.9620 - val_loss: 285.7904 - val_acc: 0.9649 - lr: 0.0050\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 334.4798 - acc: 0.9535 - val_loss: 282.7884 - val_acc: 0.9660 - lr: 0.0050\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 325.4716 - acc: 0.9586 - val_loss: 280.0174 - val_acc: 0.9664 - lr: 0.0050\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 328.0927 - acc: 0.9583 - val_loss: 277.8200 - val_acc: 0.9679 - lr: 0.0050\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 316.9371 - acc: 0.9590 - val_loss: 275.8585 - val_acc: 0.9679 - lr: 0.0050\n",
      "Epoch 175/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 311.2460 - acc: 0.9631 - val_loss: 273.7018 - val_acc: 0.9675 - lr: 0.0050\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 303.5635 - acc: 0.9638 - val_loss: 271.1060 - val_acc: 0.9682 - lr: 0.0050\n",
      "Epoch 177/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 309.1106 - acc: 0.9601 - val_loss: 268.2299 - val_acc: 0.9682 - lr: 0.0050\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 306.1371 - acc: 0.9631 - val_loss: 265.5452 - val_acc: 0.9682 - lr: 0.0050\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 299.5822 - acc: 0.9653 - val_loss: 263.0999 - val_acc: 0.9694 - lr: 0.0050\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 301.7571 - acc: 0.9609 - val_loss: 260.6544 - val_acc: 0.9697 - lr: 0.0050\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 295.9918 - acc: 0.9616 - val_loss: 258.1891 - val_acc: 0.9708 - lr: 0.0050\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 298.7116 - acc: 0.9638 - val_loss: 255.7108 - val_acc: 0.9712 - lr: 0.0050\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 301.3083 - acc: 0.9634 - val_loss: 253.3656 - val_acc: 0.9716 - lr: 0.0050\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 300.0823 - acc: 0.9645 - val_loss: 251.6372 - val_acc: 0.9708 - lr: 0.0050\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 288.6296 - acc: 0.9649 - val_loss: 249.9673 - val_acc: 0.9701 - lr: 0.0050\n",
      "Epoch 186/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 296.3171 - acc: 0.9583 - val_loss: 247.6576 - val_acc: 0.9705 - lr: 0.0050\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 283.3602 - acc: 0.9645 - val_loss: 245.0930 - val_acc: 0.9716 - lr: 0.0050\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 287.3282 - acc: 0.9620 - val_loss: 243.0012 - val_acc: 0.9716 - lr: 0.0050\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 278.8987 - acc: 0.9668 - val_loss: 240.6836 - val_acc: 0.9708 - lr: 0.0050\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 283.4863 - acc: 0.9675 - val_loss: 238.3268 - val_acc: 0.9730 - lr: 0.0050\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 281.0889 - acc: 0.9638 - val_loss: 236.6096 - val_acc: 0.9730 - lr: 0.0050\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 279.3125 - acc: 0.9638 - val_loss: 235.1350 - val_acc: 0.9734 - lr: 0.0050\n",
      "Epoch 193/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 276.3925 - acc: 0.9701 - val_loss: 233.3357 - val_acc: 0.9734 - lr: 0.0050\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 266.9919 - acc: 0.9668 - val_loss: 230.9698 - val_acc: 0.9742 - lr: 0.0050\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 268.3347 - acc: 0.9631 - val_loss: 228.5040 - val_acc: 0.9742 - lr: 0.0050\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 274.1619 - acc: 0.9664 - val_loss: 226.2460 - val_acc: 0.9745 - lr: 0.0050\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 276.6987 - acc: 0.9623 - val_loss: 224.5771 - val_acc: 0.9738 - lr: 0.0050\n",
      "Epoch 198/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 266.8103 - acc: 0.9664 - val_loss: 223.4517 - val_acc: 0.9742 - lr: 0.0050\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 260.6763 - acc: 0.9671 - val_loss: 222.5812 - val_acc: 0.9738 - lr: 0.0050\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 262.9080 - acc: 0.9638 - val_loss: 220.3310 - val_acc: 0.9734 - lr: 0.0050\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 261.2527 - acc: 0.9668 - val_loss: 216.9172 - val_acc: 0.9742 - lr: 0.0050\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 262.6040 - acc: 0.9675 - val_loss: 215.4803 - val_acc: 0.9749 - lr: 0.0050\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 249.4099 - acc: 0.9671 - val_loss: 215.0749 - val_acc: 0.9760 - lr: 0.0050\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 263.1311 - acc: 0.9668 - val_loss: 213.4210 - val_acc: 0.9760 - lr: 0.0050\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 258.1695 - acc: 0.9694 - val_loss: 211.0749 - val_acc: 0.9775 - lr: 0.0050\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 254.7832 - acc: 0.9679 - val_loss: 208.1742 - val_acc: 0.9790 - lr: 0.0050\n",
      "Epoch 207/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 242.1775 - acc: 0.9727 - val_loss: 206.5827 - val_acc: 0.9786 - lr: 0.0050\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 252.2420 - acc: 0.9708 - val_loss: 205.3708 - val_acc: 0.9778 - lr: 0.0050\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 249.6324 - acc: 0.9694 - val_loss: 203.6777 - val_acc: 0.9786 - lr: 0.0050\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 241.5284 - acc: 0.9686 - val_loss: 200.9718 - val_acc: 0.9793 - lr: 0.0050\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 232.1089 - acc: 0.9716 - val_loss: 198.7164 - val_acc: 0.9797 - lr: 0.0050\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 233.8478 - acc: 0.9705 - val_loss: 197.0032 - val_acc: 0.9801 - lr: 0.0050\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 238.2342 - acc: 0.9753 - val_loss: 195.4899 - val_acc: 0.9801 - lr: 0.0050\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 234.4733 - acc: 0.9727 - val_loss: 193.9815 - val_acc: 0.9797 - lr: 0.0050\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 238.2980 - acc: 0.9705 - val_loss: 192.1942 - val_acc: 0.9804 - lr: 0.0050\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 224.5303 - acc: 0.9764 - val_loss: 190.4323 - val_acc: 0.9808 - lr: 0.0050\n",
      "Epoch 217/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 237.5294 - acc: 0.9730 - val_loss: 188.7911 - val_acc: 0.9812 - lr: 0.0050\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 223.9405 - acc: 0.9738 - val_loss: 187.2702 - val_acc: 0.9812 - lr: 0.0050\n",
      "Epoch 219/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 226.2333 - acc: 0.9749 - val_loss: 185.6325 - val_acc: 0.9815 - lr: 0.0050\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 222.0777 - acc: 0.9742 - val_loss: 183.9231 - val_acc: 0.9819 - lr: 0.0050\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 232.7361 - acc: 0.9708 - val_loss: 182.2099 - val_acc: 0.9819 - lr: 0.0050\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 220.0986 - acc: 0.9742 - val_loss: 180.6891 - val_acc: 0.9826 - lr: 0.0050\n",
      "Epoch 223/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 215.6416 - acc: 0.9753 - val_loss: 179.2571 - val_acc: 0.9823 - lr: 0.0050\n",
      "Epoch 224/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 229.4241 - acc: 0.9712 - val_loss: 177.9225 - val_acc: 0.9819 - lr: 0.0050\n",
      "Epoch 225/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 216.3090 - acc: 0.9760 - val_loss: 176.4453 - val_acc: 0.9826 - lr: 0.0050\n",
      "Epoch 226/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 227.1160 - acc: 0.9697 - val_loss: 175.1346 - val_acc: 0.9826 - lr: 0.0050\n",
      "Epoch 227/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 219.5916 - acc: 0.9730 - val_loss: 174.0347 - val_acc: 0.9819 - lr: 0.0050\n",
      "Epoch 228/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 221.1925 - acc: 0.9719 - val_loss: 172.7341 - val_acc: 0.9823 - lr: 0.0050\n",
      "Epoch 229/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 224.5921 - acc: 0.9730 - val_loss: 171.3290 - val_acc: 0.9826 - lr: 0.0050\n",
      "Epoch 230/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 213.0282 - acc: 0.9756 - val_loss: 169.9125 - val_acc: 0.9830 - lr: 0.0050\n",
      "Epoch 231/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 209.7005 - acc: 0.9742 - val_loss: 168.5088 - val_acc: 0.9830 - lr: 0.0050\n",
      "Epoch 232/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 213.8252 - acc: 0.9778 - val_loss: 166.9936 - val_acc: 0.9834 - lr: 0.0050\n",
      "Epoch 233/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 212.0022 - acc: 0.9756 - val_loss: 165.5231 - val_acc: 0.9830 - lr: 0.0050\n",
      "Epoch 234/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 207.2501 - acc: 0.9734 - val_loss: 164.4089 - val_acc: 0.9841 - lr: 0.0050\n",
      "Epoch 235/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 200.5922 - acc: 0.9745 - val_loss: 163.7773 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 236/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 204.2416 - acc: 0.9738 - val_loss: 162.5402 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 237/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 199.8883 - acc: 0.9764 - val_loss: 160.7236 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 238/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 205.0743 - acc: 0.9756 - val_loss: 159.1457 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 239/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 200.2256 - acc: 0.9753 - val_loss: 158.2975 - val_acc: 0.9830 - lr: 0.0050\n",
      "Epoch 240/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 199.0345 - acc: 0.9764 - val_loss: 157.4741 - val_acc: 0.9834 - lr: 0.0050\n",
      "Epoch 241/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 204.8221 - acc: 0.9730 - val_loss: 156.1685 - val_acc: 0.9841 - lr: 0.0050\n",
      "Epoch 242/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 204.6268 - acc: 0.9764 - val_loss: 154.7156 - val_acc: 0.9849 - lr: 0.0050\n",
      "Epoch 243/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 208.1215 - acc: 0.9775 - val_loss: 153.4929 - val_acc: 0.9845 - lr: 0.0050\n",
      "Epoch 244/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 185.1640 - acc: 0.9808 - val_loss: 152.5779 - val_acc: 0.9849 - lr: 0.0050\n",
      "Epoch 245/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 190.5385 - acc: 0.9790 - val_loss: 151.8079 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 246/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 193.6056 - acc: 0.9767 - val_loss: 151.0276 - val_acc: 0.9845 - lr: 0.0050\n",
      "Epoch 247/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 201.1398 - acc: 0.9749 - val_loss: 150.0942 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 248/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 196.9057 - acc: 0.9749 - val_loss: 149.3035 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 249/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 193.2147 - acc: 0.9764 - val_loss: 148.4728 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 250/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 196.5547 - acc: 0.9760 - val_loss: 147.1037 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 251/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 186.8772 - acc: 0.9804 - val_loss: 145.8402 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 252/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 187.0505 - acc: 0.9782 - val_loss: 144.5653 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 253/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 186.2699 - acc: 0.9808 - val_loss: 143.9539 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 254/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 182.8506 - acc: 0.9797 - val_loss: 143.4191 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 255/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 190.0761 - acc: 0.9778 - val_loss: 142.7335 - val_acc: 0.9849 - lr: 0.0050\n",
      "Epoch 256/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 183.5478 - acc: 0.9749 - val_loss: 141.3806 - val_acc: 0.9845 - lr: 0.0050\n",
      "Epoch 257/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 188.4428 - acc: 0.9767 - val_loss: 139.8222 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 258/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 177.3216 - acc: 0.9812 - val_loss: 138.3090 - val_acc: 0.9863 - lr: 0.0050\n",
      "Epoch 259/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 194.2772 - acc: 0.9749 - val_loss: 137.1132 - val_acc: 0.9863 - lr: 0.0050\n",
      "Epoch 260/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 179.2056 - acc: 0.9782 - val_loss: 136.0592 - val_acc: 0.9863 - lr: 0.0050\n",
      "Epoch 261/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 182.9604 - acc: 0.9775 - val_loss: 135.4367 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 262/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 174.8217 - acc: 0.9801 - val_loss: 135.6332 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 263/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 179.4286 - acc: 0.9790 - val_loss: 135.3686 - val_acc: 0.9863 - lr: 0.0050\n",
      "Epoch 264/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 170.5611 - acc: 0.9801 - val_loss: 134.3562 - val_acc: 0.9867 - lr: 0.0050\n",
      "Epoch 265/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 177.9503 - acc: 0.9775 - val_loss: 132.3747 - val_acc: 0.9867 - lr: 0.0050\n",
      "Epoch 266/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 181.8119 - acc: 0.9771 - val_loss: 130.4312 - val_acc: 0.9874 - lr: 0.0050\n",
      "Epoch 267/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 171.0122 - acc: 0.9790 - val_loss: 129.3024 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 268/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 168.2495 - acc: 0.9804 - val_loss: 128.9597 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 269/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 172.3871 - acc: 0.9797 - val_loss: 129.0153 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 270/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 174.1480 - acc: 0.9775 - val_loss: 128.7449 - val_acc: 0.9886 - lr: 0.0050\n",
      "Epoch 271/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 179.6108 - acc: 0.9786 - val_loss: 127.1408 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 272/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 174.7443 - acc: 0.9801 - val_loss: 126.0254 - val_acc: 0.9874 - lr: 0.0050\n",
      "Epoch 273/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 170.8768 - acc: 0.9801 - val_loss: 125.2324 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 274/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 171.4101 - acc: 0.9815 - val_loss: 124.7539 - val_acc: 0.9874 - lr: 0.0050\n",
      "Epoch 275/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 163.1806 - acc: 0.9826 - val_loss: 123.9596 - val_acc: 0.9874 - lr: 0.0050\n",
      "Epoch 276/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 165.3436 - acc: 0.9819 - val_loss: 122.8985 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 277/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 167.6024 - acc: 0.9808 - val_loss: 122.0500 - val_acc: 0.9874 - lr: 0.0050\n",
      "Epoch 278/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 164.9951 - acc: 0.9826 - val_loss: 121.6339 - val_acc: 0.9874 - lr: 0.0050\n",
      "Epoch 279/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 158.7762 - acc: 0.9801 - val_loss: 120.9614 - val_acc: 0.9867 - lr: 0.0050\n",
      "Epoch 280/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 163.4755 - acc: 0.9812 - val_loss: 119.5856 - val_acc: 0.9867 - lr: 0.0050\n",
      "Epoch 281/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 158.8696 - acc: 0.9778 - val_loss: 118.5993 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 282/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 171.5356 - acc: 0.9786 - val_loss: 117.7041 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 283/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 170.5070 - acc: 0.9778 - val_loss: 117.1097 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 284/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 165.9996 - acc: 0.9778 - val_loss: 116.4668 - val_acc: 0.9874 - lr: 0.0050\n",
      "Epoch 285/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 173.8774 - acc: 0.9778 - val_loss: 115.7377 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 286/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 155.8791 - acc: 0.9819 - val_loss: 114.9341 - val_acc: 0.9874 - lr: 0.0050\n",
      "Epoch 287/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 158.6870 - acc: 0.9778 - val_loss: 114.1954 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 288/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 158.6813 - acc: 0.9815 - val_loss: 113.4794 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 289/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 153.9165 - acc: 0.9819 - val_loss: 112.6491 - val_acc: 0.9882 - lr: 0.0050\n",
      "Epoch 290/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 155.8276 - acc: 0.9801 - val_loss: 111.9147 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 291/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 156.8633 - acc: 0.9778 - val_loss: 111.4606 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 292/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 149.3089 - acc: 0.9852 - val_loss: 110.9009 - val_acc: 0.9889 - lr: 0.0050\n",
      "Epoch 293/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 161.0152 - acc: 0.9793 - val_loss: 109.8848 - val_acc: 0.9886 - lr: 0.0050\n",
      "Epoch 294/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 150.9265 - acc: 0.9793 - val_loss: 108.6260 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 295/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 149.4595 - acc: 0.9823 - val_loss: 107.6158 - val_acc: 0.9900 - lr: 0.0050\n",
      "Epoch 296/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 151.2198 - acc: 0.9819 - val_loss: 106.9860 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 297/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 140.8945 - acc: 0.9849 - val_loss: 106.5188 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 298/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 151.1478 - acc: 0.9808 - val_loss: 105.8751 - val_acc: 0.9900 - lr: 0.0050\n",
      "Epoch 299/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 147.8247 - acc: 0.9812 - val_loss: 105.1013 - val_acc: 0.9900 - lr: 0.0050\n",
      "Epoch 300/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 157.0918 - acc: 0.9782 - val_loss: 104.5306 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 301/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 143.8594 - acc: 0.9830 - val_loss: 104.3416 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 302/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 149.3489 - acc: 0.9826 - val_loss: 103.7047 - val_acc: 0.9889 - lr: 0.0050\n",
      "Epoch 303/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 152.6491 - acc: 0.9815 - val_loss: 102.7314 - val_acc: 0.9889 - lr: 0.0050\n",
      "Epoch 304/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 138.7274 - acc: 0.9852 - val_loss: 101.7200 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 305/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 148.4395 - acc: 0.9823 - val_loss: 100.4903 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 306/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 147.4168 - acc: 0.9808 - val_loss: 99.7276 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 307/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 139.0529 - acc: 0.9863 - val_loss: 99.5301 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 308/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 140.6427 - acc: 0.9830 - val_loss: 99.6789 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 309/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 148.4598 - acc: 0.9826 - val_loss: 99.9724 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 310/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 146.2840 - acc: 0.9823 - val_loss: 99.6843 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 311/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 135.6647 - acc: 0.9841 - val_loss: 98.4225 - val_acc: 0.9900 - lr: 0.0050\n",
      "Epoch 312/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 138.8062 - acc: 0.9812 - val_loss: 96.6608 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 313/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 129.1599 - acc: 0.9830 - val_loss: 95.9238 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 314/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 134.3295 - acc: 0.9871 - val_loss: 95.7837 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 315/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 141.3376 - acc: 0.9852 - val_loss: 95.2801 - val_acc: 0.9889 - lr: 0.0050\n",
      "Epoch 316/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 132.0031 - acc: 0.9845 - val_loss: 94.7407 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 317/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 128.5004 - acc: 0.9856 - val_loss: 94.6592 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 318/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 130.8643 - acc: 0.9856 - val_loss: 94.3434 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 319/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 136.8685 - acc: 0.9852 - val_loss: 93.2395 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 320/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 137.6362 - acc: 0.9841 - val_loss: 91.7851 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 321/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 127.8127 - acc: 0.9838 - val_loss: 91.0751 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 322/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 127.5867 - acc: 0.9838 - val_loss: 91.1883 - val_acc: 0.9900 - lr: 0.0050\n",
      "Epoch 323/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 137.2503 - acc: 0.9830 - val_loss: 91.5298 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 324/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 132.1403 - acc: 0.9826 - val_loss: 91.4741 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 325/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 145.3651 - acc: 0.9823 - val_loss: 90.3746 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 326/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 125.9869 - acc: 0.9834 - val_loss: 89.3407 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 327/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 125.0608 - acc: 0.9856 - val_loss: 88.4012 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 328/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 136.7539 - acc: 0.9823 - val_loss: 87.6605 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 329/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 135.6365 - acc: 0.9838 - val_loss: 87.0920 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 330/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 130.6778 - acc: 0.9841 - val_loss: 86.7628 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 331/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 123.7056 - acc: 0.9845 - val_loss: 86.7851 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 332/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 122.7944 - acc: 0.9871 - val_loss: 86.4255 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 333/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 127.6538 - acc: 0.9863 - val_loss: 85.7043 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 334/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 130.7132 - acc: 0.9849 - val_loss: 84.4983 - val_acc: 0.9915 - lr: 0.0050\n",
      "Epoch 335/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 124.8870 - acc: 0.9852 - val_loss: 83.7837 - val_acc: 0.9919 - lr: 0.0050\n",
      "Epoch 336/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 123.1049 - acc: 0.9845 - val_loss: 83.5691 - val_acc: 0.9922 - lr: 0.0050\n",
      "Epoch 337/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 118.7463 - acc: 0.9860 - val_loss: 83.3074 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 338/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 115.3268 - acc: 0.9871 - val_loss: 82.9406 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 339/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 128.0410 - acc: 0.9841 - val_loss: 82.0002 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 340/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 121.9950 - acc: 0.9871 - val_loss: 81.2063 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 341/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 120.1819 - acc: 0.9856 - val_loss: 80.5648 - val_acc: 0.9915 - lr: 0.0050\n",
      "Epoch 342/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 116.9153 - acc: 0.9867 - val_loss: 80.0597 - val_acc: 0.9919 - lr: 0.0050\n",
      "Epoch 343/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 114.6838 - acc: 0.9871 - val_loss: 79.7060 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 344/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 132.0239 - acc: 0.9867 - val_loss: 79.5178 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 345/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 120.6146 - acc: 0.9856 - val_loss: 79.1564 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 346/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 121.9346 - acc: 0.9856 - val_loss: 78.4628 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 347/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 119.2029 - acc: 0.9867 - val_loss: 77.7892 - val_acc: 0.9915 - lr: 0.0050\n",
      "Epoch 348/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 119.1051 - acc: 0.9845 - val_loss: 77.2967 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 349/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 120.9943 - acc: 0.9841 - val_loss: 76.9235 - val_acc: 0.9919 - lr: 0.0050\n",
      "Epoch 350/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 110.1483 - acc: 0.9904 - val_loss: 76.5730 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 351/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 113.9459 - acc: 0.9871 - val_loss: 76.2137 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 352/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 119.4199 - acc: 0.9874 - val_loss: 75.8157 - val_acc: 0.9915 - lr: 0.0050\n",
      "Epoch 353/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 115.5648 - acc: 0.9860 - val_loss: 75.6138 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 354/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 116.9602 - acc: 0.9856 - val_loss: 75.5268 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 355/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 120.0406 - acc: 0.9856 - val_loss: 75.1217 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 356/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 109.7904 - acc: 0.9874 - val_loss: 74.3171 - val_acc: 0.9919 - lr: 0.0050\n",
      "Epoch 357/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 109.2043 - acc: 0.9871 - val_loss: 73.6339 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 358/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 104.1857 - acc: 0.9889 - val_loss: 73.1134 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 359/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 123.9561 - acc: 0.9845 - val_loss: 72.7065 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 360/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 115.3126 - acc: 0.9838 - val_loss: 72.1521 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 361/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 111.8311 - acc: 0.9871 - val_loss: 71.5649 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 362/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 105.5149 - acc: 0.9874 - val_loss: 71.0186 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 363/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 102.9951 - acc: 0.9882 - val_loss: 70.3789 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 364/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 106.9575 - acc: 0.9871 - val_loss: 69.8094 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 365/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 109.9739 - acc: 0.9874 - val_loss: 69.5179 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 366/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 107.5006 - acc: 0.9867 - val_loss: 69.2866 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 367/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 111.7575 - acc: 0.9886 - val_loss: 68.9517 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 368/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 98.8694 - acc: 0.9897 - val_loss: 68.5445 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 369/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 106.5875 - acc: 0.9871 - val_loss: 68.1764 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 370/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 105.0571 - acc: 0.9886 - val_loss: 67.7764 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 371/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 100.0350 - acc: 0.9889 - val_loss: 67.4607 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 372/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 108.0858 - acc: 0.9874 - val_loss: 67.2610 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 373/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 111.3843 - acc: 0.9871 - val_loss: 66.9932 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 374/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 108.9896 - acc: 0.9845 - val_loss: 66.9092 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 375/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 101.5143 - acc: 0.9897 - val_loss: 66.5532 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 376/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 117.8997 - acc: 0.9867 - val_loss: 65.7183 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 377/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 114.8037 - acc: 0.9871 - val_loss: 65.2398 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 378/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 100.7594 - acc: 0.9886 - val_loss: 65.1528 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 379/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 105.3415 - acc: 0.9878 - val_loss: 65.0740 - val_acc: 0.9934 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 105.2599 - acc: 0.9867 - val_loss: 64.8906 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 381/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 99.1428 - acc: 0.9908 - val_loss: 64.4476 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 382/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 105.7502 - acc: 0.9878 - val_loss: 63.8406 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 383/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 103.1762 - acc: 0.9886 - val_loss: 63.6310 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 384/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 109.8737 - acc: 0.9863 - val_loss: 63.5295 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 385/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 93.9433 - acc: 0.9897 - val_loss: 63.3478 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 386/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 103.0110 - acc: 0.9874 - val_loss: 62.9947 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 387/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 103.0312 - acc: 0.9878 - val_loss: 62.4846 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 388/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 97.2075 - acc: 0.9871 - val_loss: 61.9087 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 389/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 96.2758 - acc: 0.9886 - val_loss: 61.5220 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 390/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 116.4439 - acc: 0.9852 - val_loss: 61.0615 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 391/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 92.3698 - acc: 0.9874 - val_loss: 60.6544 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 392/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 100.0483 - acc: 0.9878 - val_loss: 60.2847 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 393/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 97.9310 - acc: 0.9893 - val_loss: 59.9988 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 394/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 92.9344 - acc: 0.9893 - val_loss: 59.6332 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 395/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 89.0347 - acc: 0.9904 - val_loss: 59.2555 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 396/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 97.2617 - acc: 0.9900 - val_loss: 58.9901 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 397/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 89.8351 - acc: 0.9911 - val_loss: 58.8363 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 398/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 107.1174 - acc: 0.9878 - val_loss: 58.5464 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 399/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 93.3276 - acc: 0.9889 - val_loss: 58.1311 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 400/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 94.6995 - acc: 0.9897 - val_loss: 57.8066 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 401/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 95.3555 - acc: 0.9886 - val_loss: 57.6493 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 402/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 99.9275 - acc: 0.9904 - val_loss: 57.2921 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 403/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 90.3764 - acc: 0.9893 - val_loss: 57.0085 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 404/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 98.7637 - acc: 0.9867 - val_loss: 56.5638 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 405/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 91.0522 - acc: 0.9897 - val_loss: 56.1760 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 406/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 92.0591 - acc: 0.9886 - val_loss: 55.9295 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 407/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 88.2451 - acc: 0.9893 - val_loss: 56.0357 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 408/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 91.9333 - acc: 0.9897 - val_loss: 55.9853 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 409/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 90.2606 - acc: 0.9900 - val_loss: 55.6149 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 410/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 91.4536 - acc: 0.9882 - val_loss: 55.0181 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 411/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.0946 - acc: 0.9874 - val_loss: 54.5041 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 412/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 86.0391 - acc: 0.9904 - val_loss: 54.2520 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 413/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 95.3698 - acc: 0.9882 - val_loss: 54.0497 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 414/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 88.1184 - acc: 0.9919 - val_loss: 54.1309 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 415/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 94.3758 - acc: 0.9904 - val_loss: 54.3634 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 416/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 86.1262 - acc: 0.9904 - val_loss: 54.3208 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 417/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 82.8607 - acc: 0.9911 - val_loss: 54.0118 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 418/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 90.6228 - acc: 0.9889 - val_loss: 53.3584 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 419/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 85.7787 - acc: 0.9915 - val_loss: 52.6235 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 420/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 96.7458 - acc: 0.9893 - val_loss: 52.0043 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 421/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 90.8275 - acc: 0.9893 - val_loss: 51.7374 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 422/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 81.0665 - acc: 0.9911 - val_loss: 51.7637 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 423/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 83.1282 - acc: 0.9911 - val_loss: 51.7302 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 424/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 80.1316 - acc: 0.9908 - val_loss: 51.6043 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 425/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 87.2522 - acc: 0.9915 - val_loss: 51.2480 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 426/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 85.4402 - acc: 0.9900 - val_loss: 50.8556 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 427/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 92.5489 - acc: 0.9904 - val_loss: 50.4685 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 428/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 90.6595 - acc: 0.9897 - val_loss: 50.0533 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 429/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 81.4238 - acc: 0.9908 - val_loss: 49.7824 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 430/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 92.2881 - acc: 0.9900 - val_loss: 49.6190 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 431/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 80.8158 - acc: 0.9915 - val_loss: 49.5071 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 432/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 79.5942 - acc: 0.9904 - val_loss: 49.1946 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 433/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 84.1409 - acc: 0.9904 - val_loss: 48.7692 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 434/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 80.6349 - acc: 0.9889 - val_loss: 48.5289 - val_acc: 0.9959 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 79.2856 - acc: 0.9915 - val_loss: 48.4700 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 436/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 91.4640 - acc: 0.9904 - val_loss: 48.3158 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 437/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 85.2482 - acc: 0.9908 - val_loss: 47.9150 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 438/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 84.1563 - acc: 0.9908 - val_loss: 47.6782 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 439/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 76.6561 - acc: 0.9908 - val_loss: 47.4568 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 440/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 84.9972 - acc: 0.9911 - val_loss: 47.1510 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 441/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 89.2508 - acc: 0.9897 - val_loss: 46.8917 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 442/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 70.7423 - acc: 0.9934 - val_loss: 46.6621 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 443/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 86.2104 - acc: 0.9900 - val_loss: 46.4948 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 444/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 75.5242 - acc: 0.9904 - val_loss: 46.4760 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 445/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 79.8204 - acc: 0.9930 - val_loss: 46.3716 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 446/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 78.5757 - acc: 0.9911 - val_loss: 46.2446 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 447/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 84.6736 - acc: 0.9878 - val_loss: 45.8875 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 448/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 76.1651 - acc: 0.9919 - val_loss: 45.4516 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 449/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 67.9796 - acc: 0.9926 - val_loss: 45.2213 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 450/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 75.8960 - acc: 0.9908 - val_loss: 45.0557 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 451/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 86.1472 - acc: 0.9889 - val_loss: 44.8482 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 452/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 74.7662 - acc: 0.9904 - val_loss: 44.7204 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 453/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 78.5516 - acc: 0.9900 - val_loss: 44.4022 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 454/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 82.7427 - acc: 0.9915 - val_loss: 44.0123 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 455/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 77.2608 - acc: 0.9919 - val_loss: 43.7287 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 456/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 77.7190 - acc: 0.9897 - val_loss: 43.4460 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 457/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 76.7425 - acc: 0.9904 - val_loss: 43.3002 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 458/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 73.4594 - acc: 0.9908 - val_loss: 43.1395 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 459/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 74.7492 - acc: 0.9922 - val_loss: 42.7618 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 460/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 73.6902 - acc: 0.9919 - val_loss: 42.4444 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 461/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 72.2574 - acc: 0.9911 - val_loss: 42.1302 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 462/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 85.8894 - acc: 0.9893 - val_loss: 41.9458 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 463/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 77.7900 - acc: 0.9904 - val_loss: 41.8497 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 464/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 69.7659 - acc: 0.9922 - val_loss: 41.7808 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 465/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 80.2407 - acc: 0.9911 - val_loss: 41.7415 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 466/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 75.3559 - acc: 0.9919 - val_loss: 41.5097 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 467/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 75.9613 - acc: 0.9919 - val_loss: 41.3614 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 468/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 66.8447 - acc: 0.9930 - val_loss: 41.3347 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 469/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 72.8098 - acc: 0.9922 - val_loss: 41.2569 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 470/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 88.9641 - acc: 0.9897 - val_loss: 40.8547 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 471/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 68.8217 - acc: 0.9911 - val_loss: 40.5041 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 472/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 71.0443 - acc: 0.9922 - val_loss: 40.5973 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 473/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 67.5152 - acc: 0.9937 - val_loss: 40.9916 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 474/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 68.7373 - acc: 0.9926 - val_loss: 41.1852 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 475/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 85.9947 - acc: 0.9893 - val_loss: 40.8797 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 476/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 82.0002 - acc: 0.9882 - val_loss: 40.2647 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 477/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 69.0128 - acc: 0.9919 - val_loss: 39.9419 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 478/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.6022 - acc: 0.9922 - val_loss: 39.9785 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 479/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 81.6444 - acc: 0.9915 - val_loss: 40.1752 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 480/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 70.3223 - acc: 0.9911 - val_loss: 40.3547 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 481/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.5850 - acc: 0.9904 - val_loss: 40.3841 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 482/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 64.8259 - acc: 0.9941 - val_loss: 40.0481 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 483/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 72.0466 - acc: 0.9904 - val_loss: 39.7210 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 484/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 69.6516 - acc: 0.9904 - val_loss: 39.3437 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 485/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 71.2501 - acc: 0.9926 - val_loss: 39.0162 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 486/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 74.2216 - acc: 0.9911 - val_loss: 38.7485 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 487/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 66.5630 - acc: 0.9934 - val_loss: 38.5300 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 488/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 67.3923 - acc: 0.9937 - val_loss: 38.4551 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 489/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 62.1102 - acc: 0.9941 - val_loss: 38.3625 - val_acc: 0.9959 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 71.1991 - acc: 0.9937 - val_loss: 38.1714 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 491/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 64.3230 - acc: 0.9937 - val_loss: 37.9241 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 492/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 73.5699 - acc: 0.9919 - val_loss: 37.5870 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 493/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 70.2121 - acc: 0.9922 - val_loss: 37.2738 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 494/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 77.5345 - acc: 0.9904 - val_loss: 36.9351 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 495/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 62.9963 - acc: 0.9919 - val_loss: 36.6790 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 496/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 66.2844 - acc: 0.9934 - val_loss: 36.5357 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 497/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 65.9674 - acc: 0.9926 - val_loss: 36.5608 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 498/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 63.9490 - acc: 0.9934 - val_loss: 36.6590 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 499/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.3051 - acc: 0.9948 - val_loss: 36.7427 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 500/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 74.1416 - acc: 0.9915 - val_loss: 36.7184 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 501/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 65.9948 - acc: 0.9930 - val_loss: 36.6025 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 502/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 62.0533 - acc: 0.9941 - val_loss: 36.5937 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 503/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 70.3455 - acc: 0.9930 - val_loss: 36.5163 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 504/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 61.1888 - acc: 0.9930 - val_loss: 36.3320 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 505/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 61.3025 - acc: 0.9934 - val_loss: 36.2808 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 506/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 62.7785 - acc: 0.9937 - val_loss: 36.1584 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 507/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 66.9558 - acc: 0.9908 - val_loss: 35.8305 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 508/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 59.9023 - acc: 0.9937 - val_loss: 35.4554 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 509/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 65.6067 - acc: 0.9934 - val_loss: 35.0034 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 510/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 64.6798 - acc: 0.9922 - val_loss: 34.6485 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 511/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 73.8593 - acc: 0.9919 - val_loss: 34.5944 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 512/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 61.2963 - acc: 0.9930 - val_loss: 34.7479 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 513/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 67.9671 - acc: 0.9915 - val_loss: 34.9496 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 514/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 65.9966 - acc: 0.9934 - val_loss: 34.9602 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 515/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 63.6976 - acc: 0.9937 - val_loss: 34.8045 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 516/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 64.4854 - acc: 0.9934 - val_loss: 34.3604 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 517/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 68.3866 - acc: 0.9922 - val_loss: 33.8950 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 518/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 56.9902 - acc: 0.9941 - val_loss: 33.7732 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 519/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 59.9594 - acc: 0.9934 - val_loss: 33.7284 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 520/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 65.1572 - acc: 0.9930 - val_loss: 33.8296 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 521/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 63.9895 - acc: 0.9926 - val_loss: 33.7398 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 522/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 70.9504 - acc: 0.9926 - val_loss: 33.5170 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 523/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 57.8159 - acc: 0.9963 - val_loss: 33.2703 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 524/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 59.7421 - acc: 0.9937 - val_loss: 33.1130 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 525/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 57.5698 - acc: 0.9934 - val_loss: 33.0216 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 526/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.8598 - acc: 0.9919 - val_loss: 32.7812 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 527/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 69.0073 - acc: 0.9919 - val_loss: 32.6312 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 528/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 58.1500 - acc: 0.9937 - val_loss: 32.4342 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 529/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 53.8439 - acc: 0.9948 - val_loss: 32.3075 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 530/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 64.9420 - acc: 0.9922 - val_loss: 32.2633 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 531/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 59.9313 - acc: 0.9941 - val_loss: 32.2990 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 532/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 61.9699 - acc: 0.9915 - val_loss: 32.2341 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 533/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 65.1488 - acc: 0.9926 - val_loss: 32.0693 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 534/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 59.8031 - acc: 0.9934 - val_loss: 31.7025 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 535/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 64.3725 - acc: 0.9919 - val_loss: 31.4465 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 536/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 65.0480 - acc: 0.9919 - val_loss: 31.3893 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 537/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.7629 - acc: 0.9945 - val_loss: 31.4732 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 538/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 60.4099 - acc: 0.9941 - val_loss: 31.5469 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 539/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 77.1953 - acc: 0.9911 - val_loss: 31.3972 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 540/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 66.6239 - acc: 0.9919 - val_loss: 31.1301 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 541/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 56.0919 - acc: 0.9930 - val_loss: 30.8691 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 542/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 59.9348 - acc: 0.9937 - val_loss: 30.6947 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 543/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 56.6669 - acc: 0.9919 - val_loss: 30.5385 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 544/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 60.8607 - acc: 0.9922 - val_loss: 30.3491 - val_acc: 0.9963 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 64.9183 - acc: 0.9922 - val_loss: 30.2951 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 546/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 58.4230 - acc: 0.9934 - val_loss: 30.2781 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 547/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.7462 - acc: 0.9941 - val_loss: 30.2847 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 548/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 59.7960 - acc: 0.9915 - val_loss: 30.2867 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 549/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 54.3257 - acc: 0.9948 - val_loss: 30.2411 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 550/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 59.9647 - acc: 0.9937 - val_loss: 30.1718 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 551/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 60.2131 - acc: 0.9941 - val_loss: 30.1478 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 552/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 60.1470 - acc: 0.9908 - val_loss: 30.0607 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 553/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 58.2143 - acc: 0.9930 - val_loss: 29.9349 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 554/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 68.9638 - acc: 0.9919 - val_loss: 29.8386 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 555/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 57.3499 - acc: 0.9934 - val_loss: 29.8420 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 556/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 56.0676 - acc: 0.9945 - val_loss: 29.7612 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 557/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 56.3400 - acc: 0.9945 - val_loss: 29.8290 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 558/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 56.0944 - acc: 0.9930 - val_loss: 29.6857 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 559/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 66.8843 - acc: 0.9919 - val_loss: 29.3847 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 560/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 54.6212 - acc: 0.9922 - val_loss: 29.1641 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 561/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 57.0955 - acc: 0.9926 - val_loss: 29.0301 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 562/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 49.7267 - acc: 0.9948 - val_loss: 28.9628 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 563/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 56.5033 - acc: 0.9941 - val_loss: 28.8223 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 564/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 52.9253 - acc: 0.9934 - val_loss: 28.6068 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 565/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 53.1456 - acc: 0.9945 - val_loss: 28.4887 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 566/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 53.1642 - acc: 0.9948 - val_loss: 28.4403 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 567/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 48.0324 - acc: 0.9970 - val_loss: 28.6629 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 568/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 49.4864 - acc: 0.9952 - val_loss: 29.0584 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 569/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 52.4011 - acc: 0.9952 - val_loss: 29.3590 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 570/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 51.4767 - acc: 0.9941 - val_loss: 29.3933 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 571/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.0036 - acc: 0.9952 - val_loss: 29.0438 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 572/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 51.2638 - acc: 0.9941 - val_loss: 28.4447 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 573/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 49.5847 - acc: 0.9945 - val_loss: 27.9542 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 574/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 54.1899 - acc: 0.9937 - val_loss: 27.6806 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 575/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 52.6561 - acc: 0.9934 - val_loss: 27.8521 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 576/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.0209 - acc: 0.9948 - val_loss: 28.2086 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 577/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 54.3100 - acc: 0.9934 - val_loss: 28.3321 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 578/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 58.4542 - acc: 0.9937 - val_loss: 28.0697 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 579/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 53.5129 - acc: 0.9941 - val_loss: 27.7088 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 580/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 56.6222 - acc: 0.9934 - val_loss: 27.2016 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 581/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 51.7965 - acc: 0.9948 - val_loss: 26.7946 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 582/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 44.4824 - acc: 0.9959 - val_loss: 26.6406 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 583/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 52.4524 - acc: 0.9941 - val_loss: 26.7254 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 584/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 56.6514 - acc: 0.9941 - val_loss: 26.9812 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 585/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 50.3406 - acc: 0.9934 - val_loss: 27.0571 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 586/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 45.3701 - acc: 0.9948 - val_loss: 27.0516 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 587/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 52.1640 - acc: 0.9948 - val_loss: 26.8506 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 588/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 45.9853 - acc: 0.9956 - val_loss: 26.5638 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 589/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 49.8623 - acc: 0.9952 - val_loss: 26.3977 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 590/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 52.1524 - acc: 0.9945 - val_loss: 26.3467 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 591/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 54.1251 - acc: 0.9941 - val_loss: 26.2944 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 592/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 50.5878 - acc: 0.9930 - val_loss: 26.2177 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 593/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 48.0279 - acc: 0.9937 - val_loss: 26.0884 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 594/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 49.0018 - acc: 0.9945 - val_loss: 25.8934 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 595/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 54.4534 - acc: 0.9937 - val_loss: 25.6976 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 596/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 54.1048 - acc: 0.9934 - val_loss: 25.4846 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 597/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 50.1419 - acc: 0.9945 - val_loss: 25.2918 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 598/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 46.9623 - acc: 0.9952 - val_loss: 25.1949 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 599/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 46.9708 - acc: 0.9948 - val_loss: 25.1527 - val_acc: 0.9974 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 47.9665 - acc: 0.9952 - val_loss: 25.1412 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 601/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 50.9657 - acc: 0.9930 - val_loss: 25.2062 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 602/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 49.9306 - acc: 0.9952 - val_loss: 25.2627 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 603/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 56.5848 - acc: 0.9934 - val_loss: 25.2161 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 604/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 45.0000 - acc: 0.9956 - val_loss: 25.1278 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 605/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 52.3607 - acc: 0.9952 - val_loss: 25.0268 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 606/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 42.9891 - acc: 0.9952 - val_loss: 24.9833 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 607/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 50.9847 - acc: 0.9941 - val_loss: 24.8988 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 608/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 48.5388 - acc: 0.9952 - val_loss: 24.7691 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 609/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 47.6704 - acc: 0.9945 - val_loss: 24.6067 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 610/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 47.5456 - acc: 0.9930 - val_loss: 24.4923 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 611/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 50.9528 - acc: 0.9945 - val_loss: 24.4017 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 612/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 55.6182 - acc: 0.9952 - val_loss: 24.2870 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 613/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 47.5785 - acc: 0.9941 - val_loss: 24.1876 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 614/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 55.6802 - acc: 0.9934 - val_loss: 24.0629 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 615/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 46.7297 - acc: 0.9952 - val_loss: 23.9886 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 616/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 45.7196 - acc: 0.9959 - val_loss: 23.9192 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 617/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 50.1715 - acc: 0.9945 - val_loss: 23.8545 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 618/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 42.8877 - acc: 0.9952 - val_loss: 23.7622 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 619/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 47.2465 - acc: 0.9934 - val_loss: 23.6306 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 620/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 48.8247 - acc: 0.9948 - val_loss: 23.5169 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 621/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 44.3412 - acc: 0.9956 - val_loss: 23.4786 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 622/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 48.4367 - acc: 0.9945 - val_loss: 23.4435 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 623/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 54.6720 - acc: 0.9926 - val_loss: 23.4573 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 624/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 45.5612 - acc: 0.9948 - val_loss: 23.4584 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 625/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 42.2425 - acc: 0.9941 - val_loss: 23.4019 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 626/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 45.8858 - acc: 0.9959 - val_loss: 23.3385 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 627/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 53.4849 - acc: 0.9937 - val_loss: 23.3127 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 628/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 53.9068 - acc: 0.9934 - val_loss: 23.3004 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 629/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 44.4687 - acc: 0.9952 - val_loss: 23.2529 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 630/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 47.9233 - acc: 0.9941 - val_loss: 23.3204 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 631/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 43.3778 - acc: 0.9948 - val_loss: 23.3394 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 632/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 49.8403 - acc: 0.9952 - val_loss: 23.2319 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 633/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 49.1979 - acc: 0.9941 - val_loss: 23.0697 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 634/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 45.5264 - acc: 0.9956 - val_loss: 22.9173 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 635/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 49.6134 - acc: 0.9941 - val_loss: 22.7762 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 636/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 39.0985 - acc: 0.9963 - val_loss: 22.6504 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 637/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 49.2913 - acc: 0.9948 - val_loss: 22.5397 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 638/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 48.4041 - acc: 0.9948 - val_loss: 22.4231 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 639/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 45.0515 - acc: 0.9948 - val_loss: 22.3459 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 640/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 40.5358 - acc: 0.9956 - val_loss: 22.2758 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 641/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 45.3409 - acc: 0.9948 - val_loss: 22.2615 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 642/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 42.9547 - acc: 0.9959 - val_loss: 22.3286 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 643/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 47.3776 - acc: 0.9952 - val_loss: 22.3268 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 644/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 45.1276 - acc: 0.9948 - val_loss: 22.3771 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 645/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 38.8706 - acc: 0.9959 - val_loss: 22.3851 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 646/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 46.5956 - acc: 0.9952 - val_loss: 22.3854 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 647/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 42.5364 - acc: 0.9956 - val_loss: 22.3663 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 648/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 42.7807 - acc: 0.9948 - val_loss: 22.3245 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 649/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 38.6855 - acc: 0.9952 - val_loss: 22.2731 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 650/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 43.9222 - acc: 0.9948 - val_loss: 22.2299 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 651/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 47.5183 - acc: 0.9930 - val_loss: 22.2318 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 652/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 59.1476 - acc: 0.9915 - val_loss: 22.3821 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 653/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.3359 - acc: 0.9948 - val_loss: 22.5610 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 654/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 38.7109 - acc: 0.9956 - val_loss: 22.5666 - val_acc: 0.9974 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 41.1412 - acc: 0.9959 - val_loss: 22.4411 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 656/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 44.9831 - acc: 0.9948 - val_loss: 22.2219 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 657/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 51.7708 - acc: 0.9948 - val_loss: 21.9016 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 658/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 47.9388 - acc: 0.9948 - val_loss: 21.7368 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 659/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 41.3173 - acc: 0.9952 - val_loss: 21.7463 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 660/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 41.5250 - acc: 0.9956 - val_loss: 21.8379 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 661/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 39.6673 - acc: 0.9952 - val_loss: 21.8998 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 662/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 44.0225 - acc: 0.9941 - val_loss: 21.8446 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 663/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 39.8755 - acc: 0.9959 - val_loss: 21.6852 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 664/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 41.4095 - acc: 0.9963 - val_loss: 21.5721 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 665/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 37.7494 - acc: 0.9956 - val_loss: 21.5356 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 666/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 40.8615 - acc: 0.9956 - val_loss: 21.5894 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 667/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 41.9308 - acc: 0.9952 - val_loss: 21.6070 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 668/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 48.5341 - acc: 0.9956 - val_loss: 21.5496 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 669/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 41.0632 - acc: 0.9941 - val_loss: 21.5102 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 670/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 40.1121 - acc: 0.9948 - val_loss: 21.4099 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 671/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 42.5831 - acc: 0.9948 - val_loss: 21.2646 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 672/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 41.8367 - acc: 0.9952 - val_loss: 21.1357 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 673/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 36.3625 - acc: 0.9967 - val_loss: 21.0356 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 674/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 41.4805 - acc: 0.9956 - val_loss: 20.9415 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 675/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 41.5431 - acc: 0.9952 - val_loss: 20.8305 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 676/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 47.7193 - acc: 0.9934 - val_loss: 20.7886 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 677/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 35.1907 - acc: 0.9967 - val_loss: 20.8506 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 678/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 40.0542 - acc: 0.9959 - val_loss: 20.9179 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 679/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 41.2869 - acc: 0.9948 - val_loss: 20.9428 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 680/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 44.3535 - acc: 0.9941 - val_loss: 20.8983 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 681/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 40.0203 - acc: 0.9948 - val_loss: 20.7905 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 682/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 42.9363 - acc: 0.9952 - val_loss: 20.7063 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 683/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 37.5993 - acc: 0.9952 - val_loss: 20.6640 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 684/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 35.9174 - acc: 0.9963 - val_loss: 20.5891 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 685/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 43.6329 - acc: 0.9956 - val_loss: 20.5199 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 686/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 36.9912 - acc: 0.9959 - val_loss: 20.5002 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 687/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 40.1470 - acc: 0.9937 - val_loss: 20.4377 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 688/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 39.7525 - acc: 0.9945 - val_loss: 20.3530 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 689/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.4233 - acc: 0.9963 - val_loss: 20.3213 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 690/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 40.9850 - acc: 0.9945 - val_loss: 20.2129 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 691/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 41.1541 - acc: 0.9959 - val_loss: 20.0768 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 692/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 37.3888 - acc: 0.9941 - val_loss: 19.9126 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 693/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 36.0135 - acc: 0.9959 - val_loss: 19.7781 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 694/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 39.8202 - acc: 0.9952 - val_loss: 19.6715 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 695/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 41.2753 - acc: 0.9945 - val_loss: 19.6141 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 696/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 38.7095 - acc: 0.9952 - val_loss: 19.5829 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 697/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.4700 - acc: 0.9948 - val_loss: 19.5864 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 698/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 37.1610 - acc: 0.9959 - val_loss: 19.5722 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 699/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 36.7511 - acc: 0.9959 - val_loss: 19.5830 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 700/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 44.0327 - acc: 0.9937 - val_loss: 19.6175 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 701/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 35.5901 - acc: 0.9967 - val_loss: 19.6657 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 702/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 39.6030 - acc: 0.9959 - val_loss: 19.6567 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 703/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 35.2882 - acc: 0.9959 - val_loss: 19.6212 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 704/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 35.2811 - acc: 0.9967 - val_loss: 19.6342 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 705/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 41.3115 - acc: 0.9956 - val_loss: 19.6309 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 706/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 36.7777 - acc: 0.9959 - val_loss: 19.5657 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 707/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 40.2632 - acc: 0.9959 - val_loss: 19.3981 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 708/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 34.8089 - acc: 0.9963 - val_loss: 19.1662 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 709/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 39.4320 - acc: 0.9956 - val_loss: 18.9740 - val_acc: 0.9978 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 710/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 38.3927 - acc: 0.9956 - val_loss: 18.8202 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 711/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 38.1074 - acc: 0.9952 - val_loss: 18.7774 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 712/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 38.1604 - acc: 0.9956 - val_loss: 18.8171 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 713/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 35.5449 - acc: 0.9963 - val_loss: 18.8897 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 714/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 39.6141 - acc: 0.9948 - val_loss: 18.9739 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 715/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 40.7819 - acc: 0.9959 - val_loss: 19.0087 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 716/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 35.0536 - acc: 0.9956 - val_loss: 19.0226 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 717/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 40.0213 - acc: 0.9956 - val_loss: 18.9834 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 718/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 43.5163 - acc: 0.9948 - val_loss: 18.8523 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 719/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 38.5682 - acc: 0.9948 - val_loss: 18.7407 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 720/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 34.3747 - acc: 0.9967 - val_loss: 18.6022 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 721/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 39.8942 - acc: 0.9956 - val_loss: 18.5009 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 722/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 37.4760 - acc: 0.9959 - val_loss: 18.4787 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 723/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 32.7316 - acc: 0.9956 - val_loss: 18.5246 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 724/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 45.6595 - acc: 0.9952 - val_loss: 18.5652 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 725/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 34.9749 - acc: 0.9956 - val_loss: 18.5843 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 726/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 42.6509 - acc: 0.9941 - val_loss: 18.5583 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 727/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 40.8394 - acc: 0.9952 - val_loss: 18.5496 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 728/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 33.7732 - acc: 0.9963 - val_loss: 18.5988 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 729/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 41.3339 - acc: 0.9941 - val_loss: 18.5785 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 730/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 32.2244 - acc: 0.9967 - val_loss: 18.5148 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 731/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 39.7800 - acc: 0.9941 - val_loss: 18.3769 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 732/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 38.3921 - acc: 0.9952 - val_loss: 18.2619 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 733/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 33.5071 - acc: 0.9952 - val_loss: 18.2429 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 734/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 32.0116 - acc: 0.9970 - val_loss: 18.3137 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 735/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 34.4977 - acc: 0.9963 - val_loss: 18.4314 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 736/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 40.8468 - acc: 0.9959 - val_loss: 18.5532 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 737/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 39.3359 - acc: 0.9952 - val_loss: 18.4873 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 738/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 36.8396 - acc: 0.9952 - val_loss: 18.2445 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 739/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 33.9082 - acc: 0.9963 - val_loss: 18.0045 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 740/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 40.6197 - acc: 0.9956 - val_loss: 17.8978 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 741/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 32.9004 - acc: 0.9963 - val_loss: 17.8869 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 742/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 33.3320 - acc: 0.9967 - val_loss: 17.9772 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 743/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 44.3633 - acc: 0.9945 - val_loss: 18.0710 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 744/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 35.3738 - acc: 0.9952 - val_loss: 18.1069 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 745/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 33.3893 - acc: 0.9956 - val_loss: 18.0689 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 746/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 42.1166 - acc: 0.9945 - val_loss: 18.0387 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 747/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 30.6675 - acc: 0.9963 - val_loss: 18.0591 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 748/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 33.7230 - acc: 0.9963 - val_loss: 18.0247 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 749/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 30.4791 - acc: 0.9963 - val_loss: 17.9551 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 750/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 30.4136 - acc: 0.9963 - val_loss: 17.9287 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 751/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 35.2057 - acc: 0.9959 - val_loss: 17.9287 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 752/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.4878 - acc: 0.9970 - val_loss: 17.9203 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 753/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 32.9058 - acc: 0.9956 - val_loss: 17.7913 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 754/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 36.1680 - acc: 0.9959 - val_loss: 17.5751 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 755/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 40.4001 - acc: 0.9945 - val_loss: 17.3852 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 756/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 40.3291 - acc: 0.9941 - val_loss: 17.3455 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 757/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 30.6613 - acc: 0.9967 - val_loss: 17.4423 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 758/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 39.2424 - acc: 0.9952 - val_loss: 17.5920 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 759/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 33.2767 - acc: 0.9967 - val_loss: 17.6763 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 760/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 30.6048 - acc: 0.9959 - val_loss: 17.7697 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 761/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 36.3530 - acc: 0.9959 - val_loss: 17.6332 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 762/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.0649 - acc: 0.9948 - val_loss: 17.4041 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 763/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 32.8818 - acc: 0.9959 - val_loss: 17.1839 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 764/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 35.0471 - acc: 0.9956 - val_loss: 17.0449 - val_acc: 0.9978 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 35.0409 - acc: 0.9956 - val_loss: 16.9653 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 766/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 29.5702 - acc: 0.9970 - val_loss: 16.9050 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 767/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 35.8463 - acc: 0.9967 - val_loss: 16.8694 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 768/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 32.2402 - acc: 0.9956 - val_loss: 16.8376 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 769/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 36.0083 - acc: 0.9952 - val_loss: 16.7828 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 770/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 36.0081 - acc: 0.9952 - val_loss: 16.7367 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 771/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 35.5555 - acc: 0.9959 - val_loss: 16.6946 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 772/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 29.4311 - acc: 0.9970 - val_loss: 16.6581 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 773/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.6850 - acc: 0.9967 - val_loss: 16.5942 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 774/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.6725 - acc: 0.9974 - val_loss: 16.5514 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 775/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 28.9947 - acc: 0.9963 - val_loss: 16.5178 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 776/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 31.5552 - acc: 0.9970 - val_loss: 16.4884 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 777/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 37.1929 - acc: 0.9952 - val_loss: 16.4668 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 778/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 30.3666 - acc: 0.9956 - val_loss: 16.4679 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 779/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 31.9073 - acc: 0.9963 - val_loss: 16.4725 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 780/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 40.1448 - acc: 0.9948 - val_loss: 16.4830 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 781/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 30.1031 - acc: 0.9963 - val_loss: 16.4985 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 782/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 31.7153 - acc: 0.9948 - val_loss: 16.4478 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 783/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 37.7685 - acc: 0.9952 - val_loss: 16.4070 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 784/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 32.0332 - acc: 0.9963 - val_loss: 16.3130 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 785/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 33.9443 - acc: 0.9959 - val_loss: 16.2284 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 786/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 33.2344 - acc: 0.9959 - val_loss: 16.1986 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 787/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.9804 - acc: 0.9970 - val_loss: 16.2139 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 788/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 37.7802 - acc: 0.9963 - val_loss: 16.2388 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 789/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 31.3234 - acc: 0.9959 - val_loss: 16.2852 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 790/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.8422 - acc: 0.9956 - val_loss: 16.2938 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 791/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 33.5930 - acc: 0.9963 - val_loss: 16.3347 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 792/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 34.2929 - acc: 0.9963 - val_loss: 16.3292 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 793/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 36.6892 - acc: 0.9959 - val_loss: 16.2920 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 794/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 33.6677 - acc: 0.9952 - val_loss: 16.2479 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 795/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 32.6123 - acc: 0.9956 - val_loss: 16.1933 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 796/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 34.5398 - acc: 0.9956 - val_loss: 16.1216 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 797/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 33.4089 - acc: 0.9959 - val_loss: 16.0247 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 798/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 39.8174 - acc: 0.9952 - val_loss: 15.9675 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 799/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 33.1232 - acc: 0.9967 - val_loss: 15.8967 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 800/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 31.3484 - acc: 0.9963 - val_loss: 15.8554 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 801/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 30.6868 - acc: 0.9963 - val_loss: 15.8153 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 802/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.4848 - acc: 0.9970 - val_loss: 15.8265 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 803/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.6662 - acc: 0.9978 - val_loss: 15.9007 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 804/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.1816 - acc: 0.9959 - val_loss: 15.9377 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 805/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 25.3750 - acc: 0.9974 - val_loss: 16.0262 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 806/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 29.0405 - acc: 0.9970 - val_loss: 16.0941 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 807/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 31.6458 - acc: 0.9967 - val_loss: 16.0477 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 808/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 39.0446 - acc: 0.9956 - val_loss: 15.9791 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 809/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 33.7622 - acc: 0.9959 - val_loss: 15.8277 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 810/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 30.7872 - acc: 0.9967 - val_loss: 15.6901 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 811/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 31.8073 - acc: 0.9963 - val_loss: 15.5901 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 812/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 29.3608 - acc: 0.9963 - val_loss: 15.5547 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 813/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.4192 - acc: 0.9963 - val_loss: 15.5777 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 814/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 28.4600 - acc: 0.9967 - val_loss: 15.5944 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 815/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.7050 - acc: 0.9963 - val_loss: 15.6671 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 816/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 31.2227 - acc: 0.9967 - val_loss: 15.6359 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 817/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 32.8036 - acc: 0.9956 - val_loss: 15.6228 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 818/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 30.8057 - acc: 0.9963 - val_loss: 15.5931 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 819/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 34.2134 - acc: 0.9967 - val_loss: 15.5208 - val_acc: 0.9974 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 30.2647 - acc: 0.9959 - val_loss: 15.4641 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 821/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 38.3082 - acc: 0.9956 - val_loss: 15.3953 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 822/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 30.7135 - acc: 0.9963 - val_loss: 15.3655 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 823/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 28.5737 - acc: 0.9963 - val_loss: 15.3560 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 824/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.8824 - acc: 0.9956 - val_loss: 15.3315 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 825/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 27.7115 - acc: 0.9970 - val_loss: 15.2980 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 826/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.2444 - acc: 0.9967 - val_loss: 15.2626 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 827/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.5259 - acc: 0.9974 - val_loss: 15.2334 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 828/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.8234 - acc: 0.9974 - val_loss: 15.1868 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 829/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 31.5080 - acc: 0.9959 - val_loss: 15.1252 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 830/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 30.7770 - acc: 0.9967 - val_loss: 15.0474 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 831/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.4568 - acc: 0.9959 - val_loss: 15.0004 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 832/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 26.6425 - acc: 0.9967 - val_loss: 14.9947 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 833/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 26.5858 - acc: 0.9978 - val_loss: 14.9842 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 834/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.2572 - acc: 0.9956 - val_loss: 14.9562 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 835/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 30.1854 - acc: 0.9963 - val_loss: 14.9108 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 836/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 31.4038 - acc: 0.9967 - val_loss: 14.8694 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 837/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.8021 - acc: 0.9974 - val_loss: 14.8417 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 838/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 27.5526 - acc: 0.9970 - val_loss: 14.8358 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 839/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.0871 - acc: 0.9967 - val_loss: 14.8239 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 840/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 27.1891 - acc: 0.9974 - val_loss: 14.8263 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 841/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 34.6664 - acc: 0.9948 - val_loss: 14.8107 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 842/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 28.7486 - acc: 0.9967 - val_loss: 14.8031 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 843/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.3493 - acc: 0.9970 - val_loss: 14.8265 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 844/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 30.8870 - acc: 0.9959 - val_loss: 14.7691 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 845/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 32.3203 - acc: 0.9956 - val_loss: 14.7265 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 846/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 32.0375 - acc: 0.9948 - val_loss: 14.6904 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 847/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.1133 - acc: 0.9956 - val_loss: 14.6611 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 848/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 29.2760 - acc: 0.9967 - val_loss: 14.6694 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 849/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 29.9111 - acc: 0.9956 - val_loss: 14.6728 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 850/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 30.3450 - acc: 0.9963 - val_loss: 14.6706 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 851/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 29.4521 - acc: 0.9952 - val_loss: 14.6818 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 852/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.1601 - acc: 0.9967 - val_loss: 14.6756 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 853/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 28.5854 - acc: 0.9956 - val_loss: 14.6868 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 854/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 32.0312 - acc: 0.9963 - val_loss: 14.6513 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 855/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 28.1653 - acc: 0.9963 - val_loss: 14.5586 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 856/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.6665 - acc: 0.9970 - val_loss: 14.4381 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 857/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.2725 - acc: 0.9963 - val_loss: 14.3737 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 858/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.0615 - acc: 0.9970 - val_loss: 14.3039 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 859/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 26.7998 - acc: 0.9970 - val_loss: 14.2430 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 860/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 26.0200 - acc: 0.9974 - val_loss: 14.1956 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 861/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 34.5946 - acc: 0.9956 - val_loss: 14.1648 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 862/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.9034 - acc: 0.9967 - val_loss: 14.1757 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 863/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.9410 - acc: 0.9956 - val_loss: 14.1922 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 864/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 29.7400 - acc: 0.9956 - val_loss: 14.2104 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 865/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 32.4456 - acc: 0.9959 - val_loss: 14.2314 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 866/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 29.7272 - acc: 0.9963 - val_loss: 14.2736 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 867/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 29.5031 - acc: 0.9963 - val_loss: 14.3547 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 868/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.4819 - acc: 0.9970 - val_loss: 14.4149 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 869/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.8013 - acc: 0.9952 - val_loss: 14.3914 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 870/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 31.4469 - acc: 0.9959 - val_loss: 14.3212 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 871/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 30.6116 - acc: 0.9967 - val_loss: 14.1997 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 872/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 29.7870 - acc: 0.9956 - val_loss: 14.1303 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 873/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.9802 - acc: 0.9970 - val_loss: 14.1454 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 874/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 29.8496 - acc: 0.9963 - val_loss: 14.1430 - val_acc: 0.9978 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 34.7373 - acc: 0.9945 - val_loss: 14.1430 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 876/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 26.1276 - acc: 0.9963 - val_loss: 14.1563 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 877/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.2801 - acc: 0.9970 - val_loss: 14.1793 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 878/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.0384 - acc: 0.9967 - val_loss: 14.1856 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 879/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 26.4494 - acc: 0.9974 - val_loss: 14.1533 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 880/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 33.1179 - acc: 0.9956 - val_loss: 14.1209 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 881/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22.6140 - acc: 0.9978 - val_loss: 14.0810 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 882/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 26.1558 - acc: 0.9970 - val_loss: 14.0117 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 883/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 29.4678 - acc: 0.9963 - val_loss: 14.0192 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 884/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 25.0468 - acc: 0.9970 - val_loss: 14.0650 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 885/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 28.9709 - acc: 0.9956 - val_loss: 14.1023 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 886/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.1964 - acc: 0.9967 - val_loss: 14.1788 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 887/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 35.5522 - acc: 0.9937 - val_loss: 14.2598 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 888/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 26.3420 - acc: 0.9967 - val_loss: 14.2495 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 889/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 30.3377 - acc: 0.9959 - val_loss: 14.1584 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 890/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.2814 - acc: 0.9967 - val_loss: 14.0415 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 891/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 28.8516 - acc: 0.9967 - val_loss: 13.8780 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 892/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 33.8334 - acc: 0.9952 - val_loss: 13.7151 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 893/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.5457 - acc: 0.9967 - val_loss: 13.6006 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 894/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 33.9224 - acc: 0.9956 - val_loss: 13.5018 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 895/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 25.0807 - acc: 0.9952 - val_loss: 13.4479 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 896/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 24.4288 - acc: 0.9970 - val_loss: 13.4272 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 897/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 28.6121 - acc: 0.9963 - val_loss: 13.4314 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 898/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.0406 - acc: 0.9978 - val_loss: 13.4541 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 899/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.6738 - acc: 0.9978 - val_loss: 13.4918 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 900/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.8333 - acc: 0.9970 - val_loss: 13.5399 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 901/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 25.6457 - acc: 0.9967 - val_loss: 13.5467 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 902/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.8314 - acc: 0.9974 - val_loss: 13.5503 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 903/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 26.4554 - acc: 0.9974 - val_loss: 13.5308 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 904/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 30.1335 - acc: 0.9959 - val_loss: 13.4894 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 905/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.3476 - acc: 0.9967 - val_loss: 13.4892 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 906/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 29.4909 - acc: 0.9963 - val_loss: 13.5247 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 907/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.7868 - acc: 0.9967 - val_loss: 13.5845 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 908/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 26.2339 - acc: 0.9967 - val_loss: 13.6734 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 909/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22.1817 - acc: 0.9974 - val_loss: 13.7696 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 910/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.6869 - acc: 0.9970 - val_loss: 13.8465 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 911/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.1295 - acc: 0.9970 - val_loss: 13.8393 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 912/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 26.8666 - acc: 0.9970 - val_loss: 13.8169 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 913/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.5157 - acc: 0.9959 - val_loss: 13.7576 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 914/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.8778 - acc: 0.9970 - val_loss: 13.6836 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 915/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.3475 - acc: 0.9963 - val_loss: 13.6359 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 916/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.1484 - acc: 0.9959 - val_loss: 13.5994 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 917/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 29.4308 - acc: 0.9959 - val_loss: 13.6035 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 918/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.4184 - acc: 0.9974 - val_loss: 13.5894 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 919/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.3214 - acc: 0.9974 - val_loss: 13.5677 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 920/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 37.2942 - acc: 0.9956 - val_loss: 13.4761 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 921/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.1184 - acc: 0.9978 - val_loss: 13.4680 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 922/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.6188 - acc: 0.9978 - val_loss: 13.4104 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 923/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.9870 - acc: 0.9970 - val_loss: 13.3357 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 924/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 24.5420 - acc: 0.9974 - val_loss: 13.2647 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 925/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.7249 - acc: 0.9963 - val_loss: 13.2375 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 926/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.3367 - acc: 0.9967 - val_loss: 13.1794 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 927/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.5404 - acc: 0.9970 - val_loss: 13.1115 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 928/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 25.0071 - acc: 0.9970 - val_loss: 13.0874 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 929/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.3907 - acc: 0.9974 - val_loss: 13.0794 - val_acc: 0.9982 - lr: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.3900 - acc: 0.9967 - val_loss: 13.1044 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 931/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 26.2922 - acc: 0.9959 - val_loss: 13.1492 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 932/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.7257 - acc: 0.9959 - val_loss: 13.1555 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 933/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.6910 - acc: 0.9963 - val_loss: 13.1132 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 934/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 33.3392 - acc: 0.9967 - val_loss: 13.0544 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 935/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.5418 - acc: 0.9974 - val_loss: 12.9910 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 936/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 25.1552 - acc: 0.9963 - val_loss: 12.9251 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 937/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 25.8364 - acc: 0.9952 - val_loss: 12.9054 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 938/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 26.2740 - acc: 0.9970 - val_loss: 12.9210 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 939/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.3713 - acc: 0.9967 - val_loss: 12.9520 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 940/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.5110 - acc: 0.9974 - val_loss: 12.9768 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 941/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 25.3710 - acc: 0.9963 - val_loss: 12.9683 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 942/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 22.4602 - acc: 0.9967 - val_loss: 12.9836 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 943/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 24.8488 - acc: 0.9963 - val_loss: 12.9961 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 944/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 30.2434 - acc: 0.9959 - val_loss: 12.9475 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 945/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 24.6318 - acc: 0.9967 - val_loss: 12.8614 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 946/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 28.3544 - acc: 0.9959 - val_loss: 12.7993 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 947/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 27.8293 - acc: 0.9970 - val_loss: 12.7279 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 948/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 26.2953 - acc: 0.9967 - val_loss: 12.6481 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 949/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 32.6096 - acc: 0.9959 - val_loss: 12.5988 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 950/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.7357 - acc: 0.9978 - val_loss: 12.5613 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 951/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 28.1212 - acc: 0.9963 - val_loss: 12.5462 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 952/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.2918 - acc: 0.9978 - val_loss: 12.6004 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 953/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22.4067 - acc: 0.9978 - val_loss: 12.6593 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 954/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 21.1450 - acc: 0.9974 - val_loss: 12.7335 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 955/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 29.7776 - acc: 0.9945 - val_loss: 12.7802 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 956/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 28.2435 - acc: 0.9959 - val_loss: 12.7705 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 957/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.3342 - acc: 0.9974 - val_loss: 12.7440 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 958/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 27.8644 - acc: 0.9963 - val_loss: 12.7010 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 959/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 24.8710 - acc: 0.9970 - val_loss: 12.6624 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 960/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.8325 - acc: 0.9959 - val_loss: 12.6132 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 961/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 21.3517 - acc: 0.9970 - val_loss: 12.5736 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 962/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.5545 - acc: 0.9978 - val_loss: 12.5347 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 963/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 25.5655 - acc: 0.9963 - val_loss: 12.5306 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 964/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.2473 - acc: 0.9970 - val_loss: 12.4968 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 965/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 26.0494 - acc: 0.9963 - val_loss: 12.4623 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 966/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 26.1780 - acc: 0.9970 - val_loss: 12.4258 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 967/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 32.9062 - acc: 0.9952 - val_loss: 12.4397 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 968/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 31.9425 - acc: 0.9959 - val_loss: 12.4563 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 969/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.7654 - acc: 0.9967 - val_loss: 12.4689 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 970/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.9705 - acc: 0.9974 - val_loss: 12.4909 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 971/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.9872 - acc: 0.9978 - val_loss: 12.5022 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 972/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.6288 - acc: 0.9970 - val_loss: 12.5049 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 973/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.7456 - acc: 0.9967 - val_loss: 12.4825 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 974/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 25.6591 - acc: 0.9967 - val_loss: 12.4455 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 975/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.3154 - acc: 0.9970 - val_loss: 12.4065 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 976/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 25.4101 - acc: 0.9967 - val_loss: 12.3663 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 977/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.6068 - acc: 0.9967 - val_loss: 12.3214 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 978/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.1620 - acc: 0.9978 - val_loss: 12.3310 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 979/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 20.8104 - acc: 0.9970 - val_loss: 12.3490 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 980/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.9211 - acc: 0.9963 - val_loss: 12.3600 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 981/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.2594 - acc: 0.9967 - val_loss: 12.3544 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 982/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.5644 - acc: 0.9959 - val_loss: 12.3493 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 983/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.8110 - acc: 0.9967 - val_loss: 12.3283 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 984/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.2047 - acc: 0.9963 - val_loss: 12.2514 - val_acc: 0.9982 - lr: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.8675 - acc: 0.9963 - val_loss: 12.1749 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 986/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.5491 - acc: 0.9963 - val_loss: 12.1241 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 987/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.7442 - acc: 0.9978 - val_loss: 12.1226 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 988/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 21.5903 - acc: 0.9974 - val_loss: 12.1392 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 989/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 27.6461 - acc: 0.9970 - val_loss: 12.1865 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 990/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 26.6264 - acc: 0.9963 - val_loss: 12.2144 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 991/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.5324 - acc: 0.9970 - val_loss: 12.2318 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 992/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.5614 - acc: 0.9959 - val_loss: 12.2008 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 993/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 22.0225 - acc: 0.9978 - val_loss: 12.1645 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 994/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 29.5450 - acc: 0.9941 - val_loss: 12.1395 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 995/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.7472 - acc: 0.9967 - val_loss: 12.1134 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 996/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 26.2403 - acc: 0.9974 - val_loss: 12.0688 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 997/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 21.8233 - acc: 0.9970 - val_loss: 12.0324 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 998/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 26.9659 - acc: 0.9970 - val_loss: 12.0099 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 999/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.7925 - acc: 0.9978 - val_loss: 12.0041 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1000/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 22.6277 - acc: 0.9974 - val_loss: 12.0259 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1001/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 25.0918 - acc: 0.9970 - val_loss: 12.0577 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1002/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.1290 - acc: 0.9970 - val_loss: 12.0702 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1003/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.8579 - acc: 0.9974 - val_loss: 12.0303 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1004/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 20.7200 - acc: 0.9970 - val_loss: 11.9881 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1005/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 25.0246 - acc: 0.9963 - val_loss: 11.9241 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1006/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 20.7215 - acc: 0.9970 - val_loss: 11.8775 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1007/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 24.3778 - acc: 0.9970 - val_loss: 11.8441 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1008/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.6967 - acc: 0.9978 - val_loss: 11.8719 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1009/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 25.2511 - acc: 0.9963 - val_loss: 11.9378 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1010/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 26.2610 - acc: 0.9970 - val_loss: 11.9773 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1011/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.0055 - acc: 0.9967 - val_loss: 12.0660 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1012/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.2372 - acc: 0.9970 - val_loss: 12.1102 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 1013/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.0209 - acc: 0.9970 - val_loss: 12.1014 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 1014/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.8176 - acc: 0.9970 - val_loss: 12.0843 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 1015/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22.1860 - acc: 0.9974 - val_loss: 12.0314 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 1016/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 21.1513 - acc: 0.9978 - val_loss: 11.9534 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1017/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 25.5840 - acc: 0.9967 - val_loss: 11.8535 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1018/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.8582 - acc: 0.9978 - val_loss: 11.7847 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1019/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.6316 - acc: 0.9970 - val_loss: 11.7117 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1020/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 36.5069 - acc: 0.9963 - val_loss: 11.6713 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1021/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 21.2396 - acc: 0.9967 - val_loss: 11.6759 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 1022/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.9886 - acc: 0.9974 - val_loss: 11.7210 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1023/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.3429 - acc: 0.9963 - val_loss: 11.7808 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1024/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.7558 - acc: 0.9974 - val_loss: 11.8331 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1025/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.4391 - acc: 0.9974 - val_loss: 11.9292 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1026/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.7258 - acc: 0.9945 - val_loss: 12.0652 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1027/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.1611 - acc: 0.9978 - val_loss: 12.1328 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1028/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.6001 - acc: 0.9970 - val_loss: 12.1858 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1029/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.9088 - acc: 0.9974 - val_loss: 12.1806 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1030/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.9985 - acc: 0.9974 - val_loss: 12.1267 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1031/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.8979 - acc: 0.9974 - val_loss: 12.0049 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1032/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 25.0253 - acc: 0.9967 - val_loss: 11.8678 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1033/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 21.8567 - acc: 0.9974 - val_loss: 11.7670 - val_acc: 0.9982 - lr: 0.0045\n",
      "Epoch 1034/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.0976 - acc: 0.9970 - val_loss: 11.7117 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 1035/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 20.5954 - acc: 0.9978 - val_loss: 11.7074 - val_acc: 0.9978 - lr: 0.0045\n",
      "Epoch 1036/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.8683 - acc: 0.9974 - val_loss: 11.7356 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1037/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.9533 - acc: 0.9974 - val_loss: 11.7844 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1038/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.5141 - acc: 0.9963 - val_loss: 11.8072 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1039/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 27.3289 - acc: 0.9963 - val_loss: 11.8063 - val_acc: 0.9978 - lr: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.3035 - acc: 0.9967 - val_loss: 11.8295 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1041/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22.3381 - acc: 0.9970 - val_loss: 11.8095 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1042/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 22.2769 - acc: 0.9974 - val_loss: 11.7346 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1043/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 21.3945 - acc: 0.9967 - val_loss: 11.6696 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1044/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.9872 - acc: 0.9970 - val_loss: 11.5831 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1045/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 18.6944 - acc: 0.9978 - val_loss: 11.5310 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1046/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.6300 - acc: 0.9963 - val_loss: 11.4919 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1047/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 22.3507 - acc: 0.9970 - val_loss: 11.4104 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1048/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22.8181 - acc: 0.9974 - val_loss: 11.3806 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1049/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.0573 - acc: 0.9970 - val_loss: 11.3765 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1050/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.9911 - acc: 0.9978 - val_loss: 11.4182 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1051/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 21.9599 - acc: 0.9970 - val_loss: 11.4902 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1052/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.8285 - acc: 0.9974 - val_loss: 11.5356 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1053/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.0342 - acc: 0.9978 - val_loss: 11.6173 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1054/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.8855 - acc: 0.9970 - val_loss: 11.6193 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1055/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 20.2695 - acc: 0.9978 - val_loss: 11.5786 - val_acc: 0.9978 - lr: 0.0040\n",
      "Epoch 1056/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.6803 - acc: 0.9982 - val_loss: 11.4994 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1057/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22.2592 - acc: 0.9974 - val_loss: 11.4730 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1058/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22.0438 - acc: 0.9970 - val_loss: 11.5103 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1059/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.1455 - acc: 0.9974 - val_loss: 11.5215 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1060/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.9659 - acc: 0.9978 - val_loss: 11.4970 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1061/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 21.4298 - acc: 0.9970 - val_loss: 11.5059 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1062/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.0058 - acc: 0.9970 - val_loss: 11.5112 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1063/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22.4187 - acc: 0.9970 - val_loss: 11.4696 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1064/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22.8857 - acc: 0.9970 - val_loss: 11.4072 - val_acc: 0.9982 - lr: 0.0040\n",
      "Epoch 1065/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 26.5103 - acc: 0.9963 - val_loss: 11.3282 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1066/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 24.0710 - acc: 0.9967 - val_loss: 11.2654 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1067/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.0034 - acc: 0.9963 - val_loss: 11.2305 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1068/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.8466 - acc: 0.9978 - val_loss: 11.2382 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1069/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.2046 - acc: 0.9974 - val_loss: 11.2867 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1070/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 21.7427 - acc: 0.9970 - val_loss: 11.3578 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1071/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 22.0784 - acc: 0.9974 - val_loss: 11.3982 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1072/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 19.4245 - acc: 0.9974 - val_loss: 11.4500 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1073/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 24.0517 - acc: 0.9967 - val_loss: 11.4369 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1074/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 20.3020 - acc: 0.9967 - val_loss: 11.3665 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1075/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 19.3230 - acc: 0.9967 - val_loss: 11.2917 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1076/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.4856 - acc: 0.9974 - val_loss: 11.2499 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1077/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.2819 - acc: 0.9970 - val_loss: 11.2481 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1078/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.1940 - acc: 0.9970 - val_loss: 11.3003 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1079/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.5078 - acc: 0.9967 - val_loss: 11.3613 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1080/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 31.2015 - acc: 0.9941 - val_loss: 11.3485 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1081/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 22.4182 - acc: 0.9970 - val_loss: 11.2735 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1082/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.2557 - acc: 0.9967 - val_loss: 11.1924 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1083/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 25.1206 - acc: 0.9970 - val_loss: 11.1371 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1084/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.7434 - acc: 0.9963 - val_loss: 11.0835 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1085/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 21.4092 - acc: 0.9970 - val_loss: 11.0465 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1086/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.2371 - acc: 0.9974 - val_loss: 11.0463 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1087/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.8829 - acc: 0.9967 - val_loss: 11.0860 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1088/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 20.4428 - acc: 0.9967 - val_loss: 11.1204 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1089/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.8338 - acc: 0.9974 - val_loss: 11.1412 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1090/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.8476 - acc: 0.9974 - val_loss: 11.1865 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1091/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.7368 - acc: 0.9978 - val_loss: 11.2219 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1092/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.1492 - acc: 0.9970 - val_loss: 11.2289 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1093/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.4614 - acc: 0.9978 - val_loss: 11.2090 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1094/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 22.6376 - acc: 0.9963 - val_loss: 11.1818 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1095/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 21.2163 - acc: 0.9978 - val_loss: 11.1304 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1096/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.9929 - acc: 0.9974 - val_loss: 11.0712 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1097/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 22.2453 - acc: 0.9963 - val_loss: 11.0424 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1098/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22.1862 - acc: 0.9963 - val_loss: 11.0350 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1099/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.0925 - acc: 0.9970 - val_loss: 11.0638 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1100/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 24.9592 - acc: 0.9963 - val_loss: 11.1066 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1101/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 21.0875 - acc: 0.9970 - val_loss: 11.1092 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1102/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 24.2070 - acc: 0.9967 - val_loss: 11.0607 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1103/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 24.0899 - acc: 0.9974 - val_loss: 11.0056 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1104/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 26.4674 - acc: 0.9963 - val_loss: 10.9342 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1105/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.4916 - acc: 0.9967 - val_loss: 10.8928 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1106/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 20.7293 - acc: 0.9967 - val_loss: 10.8532 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1107/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 25.9574 - acc: 0.9963 - val_loss: 10.8384 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1108/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.2448 - acc: 0.9970 - val_loss: 10.8842 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1109/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 25.7144 - acc: 0.9963 - val_loss: 10.9446 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1110/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.1306 - acc: 0.9959 - val_loss: 11.0205 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1111/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.9084 - acc: 0.9967 - val_loss: 11.0261 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1112/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.5277 - acc: 0.9978 - val_loss: 10.9963 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1113/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.7553 - acc: 0.9978 - val_loss: 10.9242 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1114/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.3753 - acc: 0.9970 - val_loss: 10.8548 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1115/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.0135 - acc: 0.9967 - val_loss: 10.7907 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1116/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 18.4868 - acc: 0.9978 - val_loss: 10.7556 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1117/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.2803 - acc: 0.9967 - val_loss: 10.7528 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1118/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 16.7283 - acc: 0.9978 - val_loss: 10.7612 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1119/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.0560 - acc: 0.9985 - val_loss: 10.7898 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1120/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.6751 - acc: 0.9982 - val_loss: 10.8147 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1121/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.1414 - acc: 0.9982 - val_loss: 10.8319 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1122/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.6416 - acc: 0.9978 - val_loss: 10.8502 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1123/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 20.7861 - acc: 0.9974 - val_loss: 10.8620 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1124/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.1157 - acc: 0.9970 - val_loss: 10.8549 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1125/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.8333 - acc: 0.9970 - val_loss: 10.8307 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1126/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 19.7366 - acc: 0.9974 - val_loss: 10.8117 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1127/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.3299 - acc: 0.9970 - val_loss: 10.8237 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1128/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.2883 - acc: 0.9967 - val_loss: 10.8420 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1129/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 21.7214 - acc: 0.9974 - val_loss: 10.8999 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1130/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.4199 - acc: 0.9978 - val_loss: 10.9458 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1131/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.5075 - acc: 0.9967 - val_loss: 11.0052 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1132/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.4814 - acc: 0.9970 - val_loss: 11.0535 - val_acc: 0.9982 - lr: 0.0036\n",
      "Epoch 1133/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.6347 - acc: 0.9978 - val_loss: 11.1561 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1134/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.8511 - acc: 0.9978 - val_loss: 11.2106 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1135/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.3931 - acc: 0.9967 - val_loss: 11.1768 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1136/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 25.3721 - acc: 0.9956 - val_loss: 11.0680 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1137/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.0331 - acc: 0.9970 - val_loss: 10.9633 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1138/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.0439 - acc: 0.9978 - val_loss: 10.8588 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1139/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 20.2836 - acc: 0.9978 - val_loss: 10.7925 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1140/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.3704 - acc: 0.9970 - val_loss: 10.7816 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1141/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.8862 - acc: 0.9967 - val_loss: 10.8165 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1142/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 20.4161 - acc: 0.9974 - val_loss: 10.8345 - val_acc: 0.9978 - lr: 0.0033\n",
      "Epoch 1143/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.4162 - acc: 0.9982 - val_loss: 10.8278 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1144/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 20.2126 - acc: 0.9974 - val_loss: 10.7949 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1145/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.3077 - acc: 0.9974 - val_loss: 10.7505 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1146/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.8581 - acc: 0.9967 - val_loss: 10.6968 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1147/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 19.9238 - acc: 0.9967 - val_loss: 10.6507 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1148/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.3003 - acc: 0.9963 - val_loss: 10.6123 - val_acc: 0.9982 - lr: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1149/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 21.3114 - acc: 0.9978 - val_loss: 10.5946 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1150/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 26.8765 - acc: 0.9959 - val_loss: 10.5685 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1151/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 20.1561 - acc: 0.9970 - val_loss: 10.5382 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1152/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.9409 - acc: 0.9974 - val_loss: 10.5193 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1153/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 19.0631 - acc: 0.9974 - val_loss: 10.5124 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1154/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 20.1952 - acc: 0.9970 - val_loss: 10.5188 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1155/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.8652 - acc: 0.9974 - val_loss: 10.5087 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1156/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.1169 - acc: 0.9970 - val_loss: 10.4974 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1157/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.5396 - acc: 0.9982 - val_loss: 10.4906 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1158/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.5217 - acc: 0.9985 - val_loss: 10.5010 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1159/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 20.4324 - acc: 0.9974 - val_loss: 10.5078 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1160/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 19.2213 - acc: 0.9974 - val_loss: 10.5182 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1161/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.1703 - acc: 0.9974 - val_loss: 10.5468 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1162/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 20.7420 - acc: 0.9967 - val_loss: 10.5700 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1163/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.7860 - acc: 0.9978 - val_loss: 10.5780 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1164/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.6299 - acc: 0.9974 - val_loss: 10.5834 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1165/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.3037 - acc: 0.9974 - val_loss: 10.5766 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1166/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.9051 - acc: 0.9978 - val_loss: 10.5686 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1167/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.3284 - acc: 0.9978 - val_loss: 10.5610 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1168/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 26.5635 - acc: 0.9970 - val_loss: 10.5480 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1169/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.2404 - acc: 0.9985 - val_loss: 10.5413 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1170/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.6497 - acc: 0.9970 - val_loss: 10.5403 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1171/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 21.1557 - acc: 0.9974 - val_loss: 10.5264 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1172/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 21.1198 - acc: 0.9970 - val_loss: 10.5268 - val_acc: 0.9982 - lr: 0.0033\n",
      "Epoch 1173/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 20.1492 - acc: 0.9974 - val_loss: 10.5241 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1174/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.3346 - acc: 0.9970 - val_loss: 10.5119 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1175/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 20.4769 - acc: 0.9978 - val_loss: 10.5056 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1176/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.7990 - acc: 0.9978 - val_loss: 10.4893 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1177/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.8702 - acc: 0.9970 - val_loss: 10.4698 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1178/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.6600 - acc: 0.9970 - val_loss: 10.4729 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1179/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 18.6140 - acc: 0.9978 - val_loss: 10.4693 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1180/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.9997 - acc: 0.9967 - val_loss: 10.4636 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1181/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.8382 - acc: 0.9970 - val_loss: 10.4575 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1182/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.5583 - acc: 0.9978 - val_loss: 10.4835 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1183/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.1285 - acc: 0.9978 - val_loss: 10.5458 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1184/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.4277 - acc: 0.9970 - val_loss: 10.5925 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1185/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.8204 - acc: 0.9970 - val_loss: 10.5752 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1186/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 25.5632 - acc: 0.9956 - val_loss: 10.5376 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1187/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.3168 - acc: 0.9978 - val_loss: 10.4927 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1188/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.6372 - acc: 0.9974 - val_loss: 10.4651 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1189/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.8793 - acc: 0.9974 - val_loss: 10.4773 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1190/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 17.8571 - acc: 0.9978 - val_loss: 10.4954 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1191/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3885 - acc: 0.9974 - val_loss: 10.5049 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1192/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.1445 - acc: 0.9963 - val_loss: 10.5219 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1193/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.2543 - acc: 0.9970 - val_loss: 10.5174 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1194/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.4507 - acc: 0.9982 - val_loss: 10.5074 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1195/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.7747 - acc: 0.9974 - val_loss: 10.4927 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1196/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.7944 - acc: 0.9978 - val_loss: 10.4584 - val_acc: 0.9982 - lr: 0.0030\n",
      "Epoch 1197/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 20.1343 - acc: 0.9970 - val_loss: 10.4131 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1198/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.4148 - acc: 0.9978 - val_loss: 10.4092 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1199/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.0007 - acc: 0.9985 - val_loss: 10.4239 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1200/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.5272 - acc: 0.9978 - val_loss: 10.4459 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1201/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 18.2835 - acc: 0.9978 - val_loss: 10.4454 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1202/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 21.0009 - acc: 0.9974 - val_loss: 10.4496 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1203/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 18.2134 - acc: 0.9978 - val_loss: 10.4107 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1204/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.3012 - acc: 0.9974 - val_loss: 10.3609 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1205/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.6598 - acc: 0.9970 - val_loss: 10.3383 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1206/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 19.8231 - acc: 0.9967 - val_loss: 10.3284 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1207/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.7691 - acc: 0.9978 - val_loss: 10.3026 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1208/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.4959 - acc: 0.9974 - val_loss: 10.2846 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1209/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22.6249 - acc: 0.9982 - val_loss: 10.2465 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1210/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.3407 - acc: 0.9978 - val_loss: 10.2130 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1211/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 25.1511 - acc: 0.9978 - val_loss: 10.1951 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1212/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.5349 - acc: 0.9970 - val_loss: 10.1713 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1213/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 19.6303 - acc: 0.9974 - val_loss: 10.1655 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1214/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 17.1414 - acc: 0.9982 - val_loss: 10.1719 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1215/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.4046 - acc: 0.9978 - val_loss: 10.1857 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1216/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.4010 - acc: 0.9967 - val_loss: 10.2048 - val_acc: 0.9978 - lr: 0.0027\n",
      "Epoch 1217/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.9213 - acc: 0.9978 - val_loss: 10.2116 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1218/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.8764 - acc: 0.9978 - val_loss: 10.2039 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1219/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.0759 - acc: 0.9967 - val_loss: 10.1896 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1220/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.1363 - acc: 0.9978 - val_loss: 10.1689 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1221/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 17.9193 - acc: 0.9978 - val_loss: 10.1485 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1222/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.7803 - acc: 0.9974 - val_loss: 10.1414 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1223/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.7109 - acc: 0.9974 - val_loss: 10.1433 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1224/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 20.8489 - acc: 0.9974 - val_loss: 10.1427 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1225/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.1226 - acc: 0.9974 - val_loss: 10.1434 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1226/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.0435 - acc: 0.9974 - val_loss: 10.1390 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1227/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 19.8457 - acc: 0.9970 - val_loss: 10.1327 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1228/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 20.3547 - acc: 0.9967 - val_loss: 10.1382 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1229/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.4635 - acc: 0.9967 - val_loss: 10.1438 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1230/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.2602 - acc: 0.9974 - val_loss: 10.1477 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1231/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 17.1552 - acc: 0.9978 - val_loss: 10.1495 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1232/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3984 - acc: 0.9978 - val_loss: 10.1569 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1233/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.5106 - acc: 0.9982 - val_loss: 10.1681 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1234/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.9745 - acc: 0.9974 - val_loss: 10.1797 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1235/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 20.0710 - acc: 0.9974 - val_loss: 10.1841 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1236/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 19.7369 - acc: 0.9978 - val_loss: 10.1786 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1237/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.7617 - acc: 0.9974 - val_loss: 10.1741 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1238/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 17.7145 - acc: 0.9974 - val_loss: 10.1594 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1239/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.8450 - acc: 0.9974 - val_loss: 10.1330 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1240/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.8325 - acc: 0.9982 - val_loss: 10.1181 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1241/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.2070 - acc: 0.9974 - val_loss: 10.1074 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1242/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 19.8848 - acc: 0.9974 - val_loss: 10.0952 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1243/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.8882 - acc: 0.9978 - val_loss: 10.0856 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1244/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.8760 - acc: 0.9978 - val_loss: 10.0827 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1245/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 18.3759 - acc: 0.9974 - val_loss: 10.0878 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1246/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 17.9731 - acc: 0.9970 - val_loss: 10.0984 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1247/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.5149 - acc: 0.9978 - val_loss: 10.1272 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1248/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.9329 - acc: 0.9967 - val_loss: 10.1648 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1249/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.4096 - acc: 0.9978 - val_loss: 10.1995 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1250/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.9296 - acc: 0.9978 - val_loss: 10.2495 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1251/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.0173 - acc: 0.9982 - val_loss: 10.2982 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1252/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.5351 - acc: 0.9963 - val_loss: 10.3536 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1253/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3781 - acc: 0.9978 - val_loss: 10.4125 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1254/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.7330 - acc: 0.9974 - val_loss: 10.4631 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1255/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 17.6804 - acc: 0.9974 - val_loss: 10.5203 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1256/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.4075 - acc: 0.9967 - val_loss: 10.5878 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1257/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.6232 - acc: 0.9974 - val_loss: 10.6030 - val_acc: 0.9982 - lr: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1258/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.3286 - acc: 0.9974 - val_loss: 10.6171 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1259/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.2420 - acc: 0.9982 - val_loss: 10.6172 - val_acc: 0.9982 - lr: 0.0027\n",
      "Epoch 1260/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 16.4164 - acc: 0.9978 - val_loss: 10.6086 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1261/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.6978 - acc: 0.9974 - val_loss: 10.5409 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1262/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.5016 - acc: 0.9970 - val_loss: 10.4390 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1263/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 17.2816 - acc: 0.9982 - val_loss: 10.3419 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1264/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 20.9448 - acc: 0.9974 - val_loss: 10.2451 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1265/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 26.5190 - acc: 0.9963 - val_loss: 10.1769 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1266/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 14.5403 - acc: 0.9982 - val_loss: 10.1248 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1267/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.2777 - acc: 0.9974 - val_loss: 10.0932 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1268/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.7292 - acc: 0.9978 - val_loss: 10.0607 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1269/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.4656 - acc: 0.9974 - val_loss: 10.0412 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1270/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.7058 - acc: 0.9985 - val_loss: 10.0301 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1271/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.0543 - acc: 0.9959 - val_loss: 10.0158 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1272/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.5586 - acc: 0.9970 - val_loss: 10.0086 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1273/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.8933 - acc: 0.9970 - val_loss: 10.0156 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1274/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.0326 - acc: 0.9974 - val_loss: 10.0327 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1275/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 17.4703 - acc: 0.9970 - val_loss: 10.0529 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1276/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.1465 - acc: 0.9982 - val_loss: 10.0578 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1277/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.3610 - acc: 0.9970 - val_loss: 10.0534 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1278/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.6314 - acc: 0.9978 - val_loss: 10.0483 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1279/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 19.7034 - acc: 0.9978 - val_loss: 10.0402 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1280/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.6950 - acc: 0.9970 - val_loss: 10.0390 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1281/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 21.8975 - acc: 0.9963 - val_loss: 10.0435 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1282/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 20.2028 - acc: 0.9978 - val_loss: 10.0458 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1283/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 20.0246 - acc: 0.9978 - val_loss: 10.0477 - val_acc: 0.9978 - lr: 0.0024\n",
      "Epoch 1284/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.1868 - acc: 0.9982 - val_loss: 10.0577 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1285/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 18.6769 - acc: 0.9970 - val_loss: 10.0853 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1286/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.5209 - acc: 0.9978 - val_loss: 10.1013 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1287/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 18.1339 - acc: 0.9974 - val_loss: 10.1062 - val_acc: 0.9982 - lr: 0.0024\n",
      "Epoch 1288/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.3729 - acc: 0.9970 - val_loss: 10.1025 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1289/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.0298 - acc: 0.9974 - val_loss: 10.0870 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1290/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 18.8854 - acc: 0.9970 - val_loss: 10.0699 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1291/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.4475 - acc: 0.9974 - val_loss: 10.0570 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1292/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.3686 - acc: 0.9974 - val_loss: 10.0351 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1293/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.7482 - acc: 0.9974 - val_loss: 10.0080 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1294/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.5441 - acc: 0.9978 - val_loss: 9.9934 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1295/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.2947 - acc: 0.9974 - val_loss: 9.9963 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1296/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 17.6987 - acc: 0.9970 - val_loss: 10.0045 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1297/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.5974 - acc: 0.9974 - val_loss: 10.0023 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1298/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.2449 - acc: 0.9978 - val_loss: 9.9997 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1299/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.2661 - acc: 0.9970 - val_loss: 9.9900 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1300/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.8558 - acc: 0.9978 - val_loss: 9.9785 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1301/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 21.4357 - acc: 0.9974 - val_loss: 9.9720 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1302/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 17.4925 - acc: 0.9978 - val_loss: 9.9574 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1303/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.5178 - acc: 0.9978 - val_loss: 9.9414 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1304/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 16.0424 - acc: 0.9982 - val_loss: 9.9299 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1305/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 29.4027 - acc: 0.9967 - val_loss: 9.9223 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1306/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.0514 - acc: 0.9974 - val_loss: 9.9185 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1307/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.3532 - acc: 0.9978 - val_loss: 9.9205 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1308/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.5253 - acc: 0.9974 - val_loss: 9.9284 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1309/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.6991 - acc: 0.9967 - val_loss: 9.9349 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1310/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.9049 - acc: 0.9967 - val_loss: 9.9401 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1311/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 26.1080 - acc: 0.9970 - val_loss: 9.9326 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1312/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.8050 - acc: 0.9978 - val_loss: 9.9311 - val_acc: 0.9982 - lr: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1313/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.2112 - acc: 0.9974 - val_loss: 9.9287 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1314/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 17.2031 - acc: 0.9978 - val_loss: 9.9252 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1315/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22.8873 - acc: 0.9963 - val_loss: 9.9281 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1316/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 14.5030 - acc: 0.9982 - val_loss: 9.9350 - val_acc: 0.9978 - lr: 0.0022\n",
      "Epoch 1317/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.9066 - acc: 0.9974 - val_loss: 9.9466 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1318/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 14.9433 - acc: 0.9974 - val_loss: 9.9654 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1319/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 16.7578 - acc: 0.9974 - val_loss: 9.9798 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1320/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 20.4211 - acc: 0.9978 - val_loss: 9.9710 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1321/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.8903 - acc: 0.9974 - val_loss: 9.9686 - val_acc: 0.9982 - lr: 0.0022\n",
      "Epoch 1322/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.5549 - acc: 0.9974 - val_loss: 9.9631 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1323/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 20.1499 - acc: 0.9974 - val_loss: 9.9544 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1324/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.8856 - acc: 0.9978 - val_loss: 9.9363 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1325/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.1008 - acc: 0.9970 - val_loss: 9.9016 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1326/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.7326 - acc: 0.9978 - val_loss: 9.8750 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1327/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.2788 - acc: 0.9974 - val_loss: 9.8572 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1328/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.9703 - acc: 0.9974 - val_loss: 9.8410 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1329/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.5819 - acc: 0.9970 - val_loss: 9.8261 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1330/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.4657 - acc: 0.9978 - val_loss: 9.8216 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1331/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.1512 - acc: 0.9974 - val_loss: 9.8287 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1332/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.1883 - acc: 0.9978 - val_loss: 9.8437 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1333/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 15.7019 - acc: 0.9978 - val_loss: 9.8536 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1334/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 15.8334 - acc: 0.9978 - val_loss: 9.8455 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1335/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.3568 - acc: 0.9978 - val_loss: 9.8368 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1336/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 15.9553 - acc: 0.9978 - val_loss: 9.8245 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1337/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 16.2016 - acc: 0.9982 - val_loss: 9.8090 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1338/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.9235 - acc: 0.9974 - val_loss: 9.8001 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1339/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 21.2465 - acc: 0.9963 - val_loss: 9.8028 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1340/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.6784 - acc: 0.9978 - val_loss: 9.8301 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1341/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 31.3707 - acc: 0.9974 - val_loss: 9.8592 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1342/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.7267 - acc: 0.9967 - val_loss: 9.8832 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1343/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 19.5285 - acc: 0.9982 - val_loss: 9.9233 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1344/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.7320 - acc: 0.9974 - val_loss: 9.9665 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1345/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.7576 - acc: 0.9974 - val_loss: 10.0061 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1346/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.0694 - acc: 0.9974 - val_loss: 10.0089 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1347/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 17.4083 - acc: 0.9974 - val_loss: 10.0251 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1348/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.8876 - acc: 0.9974 - val_loss: 10.0158 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1349/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 16.6816 - acc: 0.9978 - val_loss: 10.0012 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1350/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.5953 - acc: 0.9978 - val_loss: 9.9718 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1351/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.6674 - acc: 0.9978 - val_loss: 9.9325 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1352/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 15.1250 - acc: 0.9982 - val_loss: 9.8930 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1353/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 15.0887 - acc: 0.9982 - val_loss: 9.8575 - val_acc: 0.9982 - lr: 0.0019\n",
      "Epoch 1354/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 16.4565 - acc: 0.9974 - val_loss: 9.8297 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1355/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.1483 - acc: 0.9982 - val_loss: 9.8007 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1356/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.6280 - acc: 0.9970 - val_loss: 9.7729 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1357/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.3762 - acc: 0.9978 - val_loss: 9.7604 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1358/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 17.2817 - acc: 0.9970 - val_loss: 9.7382 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1359/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 19.5566 - acc: 0.9978 - val_loss: 9.7159 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1360/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.1649 - acc: 0.9970 - val_loss: 9.6912 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1361/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3480 - acc: 0.9970 - val_loss: 9.6737 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1362/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.1300 - acc: 0.9978 - val_loss: 9.6603 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1363/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 20.0329 - acc: 0.9967 - val_loss: 9.6544 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1364/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.8301 - acc: 0.9978 - val_loss: 9.6567 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1365/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.9845 - acc: 0.9978 - val_loss: 9.6673 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1366/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.1156 - acc: 0.9982 - val_loss: 9.6817 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1367/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.4032 - acc: 0.9982 - val_loss: 9.6968 - val_acc: 0.9982 - lr: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1368/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 15.6794 - acc: 0.9982 - val_loss: 9.7046 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1369/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22.0102 - acc: 0.9967 - val_loss: 9.6932 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1370/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.3856 - acc: 0.9970 - val_loss: 9.6873 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1371/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.8297 - acc: 0.9978 - val_loss: 9.6823 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1372/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.8885 - acc: 0.9982 - val_loss: 9.6668 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1373/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.2646 - acc: 0.9978 - val_loss: 9.6494 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1374/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 18.8013 - acc: 0.9974 - val_loss: 9.6402 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1375/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 16.4007 - acc: 0.9974 - val_loss: 9.6331 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1376/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.0475 - acc: 0.9974 - val_loss: 9.6239 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1377/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 17.3693 - acc: 0.9978 - val_loss: 9.6217 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1378/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.2651 - acc: 0.9978 - val_loss: 9.6257 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1379/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.0937 - acc: 0.9982 - val_loss: 9.6313 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1380/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 16.5216 - acc: 0.9978 - val_loss: 9.6452 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1381/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.9554 - acc: 0.9974 - val_loss: 9.6670 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1382/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.4326 - acc: 0.9978 - val_loss: 9.6907 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1383/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 19.8531 - acc: 0.9982 - val_loss: 9.7049 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1384/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.5399 - acc: 0.9970 - val_loss: 9.7239 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1385/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.0677 - acc: 0.9982 - val_loss: 9.7331 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1386/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.5939 - acc: 0.9970 - val_loss: 9.7280 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1387/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.2415 - acc: 0.9978 - val_loss: 9.7113 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1388/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 14.7889 - acc: 0.9974 - val_loss: 9.6914 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1389/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.3403 - acc: 0.9974 - val_loss: 9.6595 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1390/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 20.7183 - acc: 0.9978 - val_loss: 9.6224 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1391/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.7910 - acc: 0.9967 - val_loss: 9.6010 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1392/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.6285 - acc: 0.9974 - val_loss: 9.5894 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1393/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.6871 - acc: 0.9974 - val_loss: 9.5866 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1394/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.7000 - acc: 0.9978 - val_loss: 9.5849 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1395/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.8464 - acc: 0.9974 - val_loss: 9.5854 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1396/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.2340 - acc: 0.9974 - val_loss: 9.5854 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1397/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.2790 - acc: 0.9982 - val_loss: 9.5861 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1398/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 20.1335 - acc: 0.9974 - val_loss: 9.5953 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1399/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.7874 - acc: 0.9982 - val_loss: 9.6012 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1400/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 15.7045 - acc: 0.9982 - val_loss: 9.6097 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1401/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.0295 - acc: 0.9974 - val_loss: 9.6231 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1402/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 17.6497 - acc: 0.9978 - val_loss: 9.6392 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1403/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.5188 - acc: 0.9978 - val_loss: 9.6582 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1404/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.6889 - acc: 0.9974 - val_loss: 9.6765 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1405/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 19.1754 - acc: 0.9967 - val_loss: 9.6906 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1406/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.1674 - acc: 0.9963 - val_loss: 9.6972 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1407/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.7314 - acc: 0.9978 - val_loss: 9.6950 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1408/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.8362 - acc: 0.9982 - val_loss: 9.6956 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1409/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.2747 - acc: 0.9974 - val_loss: 9.6960 - val_acc: 0.9982 - lr: 0.0017\n",
      "Epoch 1410/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 15.2082 - acc: 0.9982 - val_loss: 9.7039 - val_acc: 0.9982 - lr: 0.0016\n",
      "Epoch 1411/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.7156 - acc: 0.9985 - val_loss: 9.7202 - val_acc: 0.9982 - lr: 0.0016\n",
      "Epoch 1412/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.0123 - acc: 0.9982 - val_loss: 9.7473 - val_acc: 0.9982 - lr: 0.0016\n",
      "Epoch 1413/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 20.2861 - acc: 0.9967 - val_loss: 9.7567 - val_acc: 0.9982 - lr: 0.0016\n",
      "Epoch 1414/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.5970 - acc: 0.9970 - val_loss: 9.7503 - val_acc: 0.9982 - lr: 0.0016\n",
      "Epoch 1415/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.3209 - acc: 0.9978 - val_loss: 9.7427 - val_acc: 0.9982 - lr: 0.0016\n",
      "Epoch 1416/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.5073 - acc: 0.9978 - val_loss: 9.7367 - val_acc: 0.9982 - lr: 0.0016\n",
      "Epoch 1417/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.1756 - acc: 0.9970 - val_loss: 9.7342 - val_acc: 0.9982 - lr: 0.0016\n",
      "Epoch 1418/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.5538 - acc: 0.9974 - val_loss: 9.7428 - val_acc: 0.9982 - lr: 0.0016\n",
      "Epoch 1419/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.5834 - acc: 0.9985 - val_loss: 9.7575 - val_acc: 0.9978 - lr: 0.0016\n",
      "Epoch 1420/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 17.2902 - acc: 0.9974 - val_loss: 9.7841 - val_acc: 0.9978 - lr: 0.0016\n",
      "Epoch 1421/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.8248 - acc: 0.9970 - val_loss: 9.7803 - val_acc: 0.9978 - lr: 0.0016\n",
      "Epoch 1422/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.6955 - acc: 0.9982 - val_loss: 9.7785 - val_acc: 0.9978 - lr: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1423/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.3844 - acc: 0.9978 - val_loss: 9.7785 - val_acc: 0.9978 - lr: 0.0016\n",
      "Epoch 1424/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.1795 - acc: 0.9982 - val_loss: 9.7698 - val_acc: 0.9978 - lr: 0.0016\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=PATIENCE//2, min_lr=5e-6, factor=.9)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_va.load(),\n",
    "    validation_steps=loader_va.steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4367816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Train', lw=2)\n",
    "plt.plot(history.history['val_loss'], label='Val', lw=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22c511",
   "metadata": {},
   "source": [
    "### 1.5 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e29f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model.\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5849 - acc: 0.9982\n",
      "Done.\n",
      "Test loss: 9.584897994995117\n",
      "Test accuracy: 0.9981536269187927\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(\"Evaluating model.\")\n",
    "loader_te = SingleLoader(dataset)\n",
    "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90d3b6",
   "metadata": {},
   "source": [
    "#### Exercise 1.4.1\n",
    "\n",
    "Add one more hidden GAT layer, build, compile, train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ec539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "in_x = keras.Input(shape=(dataset[0].x.shape[1],))\n",
    "in_a = keras.Input(shape=(dataset[0].a.shape[0],), sparse=True)\n",
    "\n",
    "# Add dropout on features (but not adjacency matrix)\n",
    "dropout_1 = keras.layers.Dropout(.1)(in_x)\n",
    "\n",
    "# Add GAT layer\n",
    "gat_layer_1 = spktrl.layers.GATConv(\n",
    "    channels=16,\n",
    "    attn_heads=8,\n",
    "    concat_heads=True,\n",
    "    dropout_rate=.05,\n",
    "    activation='selu',\n",
    "    kernel_initializer='lecun_normal'\n",
    ")([dropout_1, in_a])\n",
    "\n",
    "# Add dropout\n",
    "dropout_2 = keras.layers.Dropout(.1)(gat_layer_1)\n",
    "\n",
    "\n",
    "\n",
    "######## YOUR CODE STARTS HERE ########\n",
    "\n",
    "# Add another GAT layer\n",
    "gat_layer_2 = ...\n",
    "\n",
    "# Add another dropout layer\n",
    "dropout_3 = ...\n",
    "\n",
    "######## YOUR CODE ENDS HERE ########\n",
    "\n",
    "\n",
    "# Final GAT layer\n",
    "gat_out = spktrl.layers.GATConv(\n",
    "    channels=dataset[0].n_labels,\n",
    "    attn_heads=8,\n",
    "    concat_heads=False,\n",
    "    dropout_rate=.05,\n",
    "    activation='softmax'\n",
    ")([dropout_3, in_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enclose the layers in the model\n",
    "model = keras.Model(inputs=[in_x, in_a], outputs=gat_out)\n",
    "\n",
    "# Set some params\n",
    "LR = 5e-3 # 5e-3  # Learning rate\n",
    "EPOCHS = 10000  # Number of training epochs\n",
    "PATIENCE = 30  # Patience for early stopping\n",
    "\n",
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(lr=LR)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.CategoricalCrossentropy(reduction='sum'),\n",
    "    weighted_metrics=['acc'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc49a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=PATIENCE//2, min_lr=5e-6, factor=.9)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "######## YOUR CODE STARTS HERE ########\n",
    "history = model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_va.load(),\n",
    "    validation_steps=...,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=...\n",
    ")\n",
    "######## YOUR CODE ENDS HERE ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train', lw=2)\n",
    "plt.plot(history.history['val_loss'], label='Val', lw=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47217a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print(\"Evaluating model.\")\n",
    "loader_te = SingleLoader(dataset)\n",
    "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce3473",
   "metadata": {},
   "source": [
    "## 2. Graph classification with model sub-classing API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e09359",
   "metadata": {},
   "source": [
    "We'll use **Proteins** dataset, a part of [TU Datasets](https://chrsmrrs.github.io/datasets/).\n",
    "\n",
    "Proteins dataset is stored in a **disjoint** format.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/disjoint.png\" width=400>\n",
    "\n",
    "\n",
    "We'll need not only adjacency matrix and feature matrix, but also index matrix to identify which nodes belong to which batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe3ec90",
   "metadata": {},
   "source": [
    "### 2.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f03b6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded PROTEINS.\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(\"PROTEINS\", clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7076559",
   "metadata": {},
   "source": [
    "#### Exercise 2.1.1\n",
    "\n",
    "Check how many nodes are in the 8th graph of **Proteins** dataset.\n",
    "\n",
    "How many are there in 172nd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b652b457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=19, n_node_features=4, n_edge_features=None, n_labels=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "dataset[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10022eed",
   "metadata": {},
   "source": [
    "### 2.2 Split + dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae672425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / test split\n",
    "idxs = np.random.permutation(len(dataset))  # Random split\n",
    "split = int(0.9 * len(dataset))\n",
    "idx_tr, idx_te = np.split(idxs, [split])\n",
    "\n",
    "# Get train and test datsets\n",
    "dataset_tr, dataset_te = dataset[idx_tr], dataset[idx_te]\n",
    "\n",
    "# Get loaders \n",
    "loader_tr = DisjointLoader(dataset_tr, batch_size=32, epochs=10)\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e79139",
   "metadata": {},
   "source": [
    "### 2.3 Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02c709a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(keras.models.Model):\n",
    "    \n",
    "    def __init__(self, channels, n_layers, dropout_rate=.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = spktrl.layers.GCNConv(channels)\n",
    "        self.convs = []\n",
    "        \n",
    "        for _ in range(1, n_layers):\n",
    "            self.convs.append(\n",
    "                spktrl.layers.GCNConv(channels)\n",
    "            )\n",
    "        self.pool = spktrl.layers.GlobalAvgPool()\n",
    "        self.dense1 = keras.layers.Dense(channels, activation='relu')\n",
    "        self.dropout = keras.layers.Dropout(dropout_rate)\n",
    "        self.dense2 = keras.layers.Dense(dataset.n_labels, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a, i = inputs\n",
    "        x = self.conv1([x, a])\n",
    "        for conv in self.convs:\n",
    "            x = conv([x, a])\n",
    "        x = self.pool([x, i])\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80546ca3",
   "metadata": {},
   "source": [
    "### 2.3 Compile, train & evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a9ec3f",
   "metadata": {},
   "source": [
    "#### 2.3.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a18eceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some params\n",
    "LR = 5e-3 # 5e-3  # Learning rate\n",
    "EPOCHS = 10  # Number of training epochs\n",
    "PATIENCE = 30  # Patience for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "774074c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = GCN(\n",
    "    channels=16,\n",
    "    dropout_rate=.1,\n",
    "    n_layers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00e2994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = keras.optimizers.RMSprop(LR)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.CategoricalCrossentropy(reduction='sum'),\n",
    "    weighted_metrics=['acc'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48612ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 7/28 [======>.......................] - ETA: 0s - loss: 258.7665 - acc: 0.4866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\envs\\tf-spektral-minimal\\lib\\site-packages\\spektral\\data\\utils.py:213: UserWarning: you are shuffling a 'TUDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 22ms/step - loss: 123.7635 - acc: 0.5576 - val_loss: 23.7878 - val_acc: 0.3367\n",
      "Epoch 2/10\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 25.7452 - acc: 0.6202WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 25.2934 - acc: 0.6237\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 22.1513 - acc: 0.6556\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 21.1284 - acc: 0.6340\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 21.0358 - acc: 0.6465\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 20.9220 - acc: 0.6465\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 20.8778 - acc: 0.6465\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 20.6952 - acc: 0.6465\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 20.6270 - acc: 0.6465\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 20.6415 - acc: 0.6465\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_te.load(),\n",
    "    validation_steps=loader_te.steps_per_epoch,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfdacfd",
   "metadata": {},
   "source": [
    "#### Exercise 2.3.1\n",
    "\n",
    "Train a GCN with:\n",
    "\n",
    "* 32 channels \n",
    "* 6 layers\n",
    "* Adam optimizer (use the same learning rate, `LR`)\n",
    "\n",
    "Are the results better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f265e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loaders \n",
    "loader_tr = DisjointLoader(dataset_tr, batch_size=32, epochs=10)\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=32, epochs=1)\n",
    "\n",
    "######## YOUR CODE STARTS HERE ########\n",
    "model = ...\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = ...\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.CategoricalCrossentropy(reduction='sum'),\n",
    "    weighted_metrics=['acc'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_te.load(),\n",
    "    validation_steps=loader_te.steps_per_epoch,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be30e85a",
   "metadata": {},
   "source": [
    "## 3. Building a custom dataset\n",
    "\n",
    "To build your own dataset, you should store your data in a specific location. \n",
    "\n",
    "Locally it's: `~/.spektral/datasets/[ClassName]`\n",
    "\n",
    "You can overwrite it by defining the `path` property of a `Dataset` class. \n",
    "\n",
    "\n",
    "\n",
    "Path on **Colab**: `/usr/local/lib/python3.7/dist-packages/spectral/datasets`\n",
    "\n",
    "\n",
    "___________________________\n",
    "\n",
    "<img src=\"img/tensorcell.png\" width=150>\n",
    "\n",
    "<br>\n",
    "\n",
    "Now, we're going to look at a dataset class that we used in one of our experiments at [TensorCell](https://www.tensorcell.com/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "___________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bccdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorcellDataset(Dataset):\n",
    "    \n",
    "    \"\"\"A Tensorcell dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_variant, allow_self_loops=True, circular_mapping=False, add_constant_feature=False, add_one_hot_index=False, **kwargs):\n",
    "        \"\"\"\n",
    "        :param dataset_variant: A dataset to pick. Currently takes: `ochota_100k`, `centrum_100k`, `mokotow_100k`\n",
    "        :type dataset_variant: str\n",
    "        :param circular_mapping: If node values should be mapped to a unit circle\n",
    "        :type circular_dataset: bool\n",
    "\n",
    "        ...\n",
    "        :return: None\n",
    "        :rtype: None\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_variant = dataset_variant\n",
    "        self.allow_self_loops = allow_self_loops\n",
    "        self.circular_mapping = circular_mapping\n",
    "        self.add_constant_feature = add_constant_feature\n",
    "        self.add_one_hot_index = add_one_hot_index\n",
    "        \n",
    "        # Construct filenames\n",
    "        dataset_info = dataset_variant.split('_')\n",
    "        district = dataset_info[0]\n",
    "        n_rows = dataset_info[1]\n",
    "        \n",
    "        self.filename_A = f'{district}_A.txt'\n",
    "        self.filename_Xy = f'{district}_X_{n_rows}.txt'\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        :return: output\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        \n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "        \n",
    "        # Read files\n",
    "        adjacency_matrix = np.loadtxt(os.path.join(self.path, self.filename_A))\n",
    "        features = np.loadtxt(os.path.join(self.path, self.filename_Xy), delimiter=',')\n",
    "\n",
    "        # Add/remove self loops in the adjacency matrix\n",
    "        if self.allow_self_loops:\n",
    "            np.fill_diagonal(adjacency_matrix, 1)\n",
    "        else:\n",
    "            np.fill_diagonal(adjacency_matrix, 0)\n",
    "\n",
    "        \n",
    "        # Construct graph objects\n",
    "        for row in range(features.shape[0]):\n",
    "\n",
    "            # If `circular_mapping` -> map to a circular representation\n",
    "            if self.circular_mapping:\n",
    "                x = self.get_circular_components(features[row, :-1]).T\n",
    "            else:\n",
    "                x = features[row, :-1][:, np.newaxis]\n",
    "\n",
    "            # Add constant feature 1\n",
    "            if self.add_constant_feature:\n",
    "                x = np.hstack([x, np.ones(x.shape[0])[:, np.newaxis]])\n",
    "\n",
    "            # Add one-hot encoded node label\n",
    "            if self.add_one_hot_index:\n",
    "\n",
    "                x_plus_oh = []\n",
    "\n",
    "                for i, d in enumerate(x):\n",
    "                    one_hot_index = np.zeros(x.shape[0])\n",
    "                    one_hot_index[i] = 1\n",
    "                    x_plus_oh.append(np.hstack([d, one_hot_index]))\n",
    "\n",
    "                x = np.array(x_plus_oh)\n",
    "\n",
    "            # Construct a graph \n",
    "            output.append(\n",
    "                Graph(\n",
    "                    x=x, \n",
    "                    a=adjacency_matrix, \n",
    "                    y=features[row, -1])\n",
    "            )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorcellDataset('ochota_100k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-spektral-minimal]",
   "language": "python",
   "name": "conda-env-tf-spektral-minimal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
