{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f45ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.8.0\n",
    "# !pip install spektral==1.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32544b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import spektral as spktrl\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "from spektral.datasets import Citation, TUDataset\n",
    "from spektral.data import SingleLoader, DisjointLoader\n",
    "from spektral.data import Dataset, Graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c91f641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Spektral 1.0.6\n",
      "Using TensorFlow 2.8.0\n",
      "Physical GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(f'Using Spektral {spktrl.__version__}')\n",
    "print(f'Using TensorFlow {tf.__version__}')\n",
    "print('Physical GPUs:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edddd1ac",
   "metadata": {},
   "source": [
    "# Practical graph neural networks in Python with TensorFlow and Spektral\n",
    "\n",
    "*PyData Berlin, 2022.04.13*\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "\n",
    "Graph neural networks (GNNs) have become one of the hottest research topics in recent years. Their popularity is reinforced by hugely successful industry applications in social networks, biology, chemistry, neuroscience and many other areas. One of the main challenges faced by data scientists and researchers who want to apply graph networks in their work is that they require different data structures and a slightly different training approach than traditional deep learning models. During the workshop we’ll demonstrate how to implement graph neural networks, how to prepare your data and – finally – how to train a GNN model for node-level and graph-level tasks using Spektral and TensorFlow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecd400",
   "metadata": {},
   "source": [
    "## 1. Node classification with functional API\n",
    "\n",
    "We'll perform node classification using [CORA](https://relational.fit.cvut.cz/dataset/CORA) citation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff02a2",
   "metadata": {},
   "source": [
    "### 1.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc400285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cora dataset.\n",
      "Pre-processing node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\envs\\tf-spektral-minimal\\lib\\site-packages\\scipy\\sparse\\_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = Citation(\"cora\", normalize_x=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a3073",
   "metadata": {},
   "source": [
    "### 1.2 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557bccd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 10556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's understand the adjacency matrix\n",
    "dataset[0].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a549b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's understand labels\n",
    "dataset[0].y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929e4c2",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.1\n",
    "\n",
    "Display the label of node 77. \n",
    "\n",
    "\n",
    "What is the label of this node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5b1071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "dataset[0].y[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7284bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1433)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let't understand features\n",
    "dataset[0].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cdcd6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of non-zero featueres over nodes\n",
    "plt.hist((dataset[0].x > 0).sum(axis=1), alpha=.7, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e5a886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True, ..., False, False, False]),\n",
       " array([False, False, False, ..., False, False, False]),\n",
       " array([False, False, False, ...,  True,  True,  True]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understand the masks \n",
    "\n",
    "# Training, val, test \n",
    "dataset.mask_tr, dataset.mask_va, dataset.mask_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae7db5",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.2\n",
    "\n",
    "Compute the number of training, validation and test examples. \n",
    "\n",
    "What are these numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "674d36d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 140\n",
      "Number of validation examples: 500\n",
      "Number of test examples: 1000\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print(f'Number of training examples: {dataset.mask_tr.sum()}')\n",
    "print(f'Number of validation examples: {dataset.mask_va.sum()}')\n",
    "print(f'Number of test examples: {dataset.mask_te.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946711df",
   "metadata": {},
   "source": [
    "### 1.3 Prepare dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1dfb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_tr = SingleLoader(dataset)\n",
    "loader_va = SingleLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962029a",
   "metadata": {},
   "source": [
    "### 1.4 Build and compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434cfe42",
   "metadata": {},
   "source": [
    "#### 1.4.1 Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c35571d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "in_x = keras.Input(shape=(dataset[0].x.shape[1],))\n",
    "in_a = keras.Input(shape=(dataset[0].a.shape[0],), sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96a0e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout on features (but not adjacency matrix)\n",
    "dropout_1 = keras.layers.Dropout(.1)(in_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8a91e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add GAT layer\n",
    "gat_layer_1 = spktrl.layers.GATConv(\n",
    "    channels=16,\n",
    "    attn_heads=8,\n",
    "    concat_heads=True,\n",
    "    dropout_rate=.05,\n",
    "    activation='selu',\n",
    "    kernel_initializer='lecun_normal'\n",
    ")([dropout_1, in_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016b309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout\n",
    "dropout_2 = keras.layers.Dropout(.1)(gat_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "945040e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final GAT layer\n",
    "gat_out = spktrl.layers.GATConv(\n",
    "    channels=dataset[0].n_labels,\n",
    "    attn_heads=8,\n",
    "    concat_heads=False,\n",
    "    dropout_rate=.05,\n",
    "    activation='softmax'\n",
    ")([dropout_2, in_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "588b2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enclose the layers in the model\n",
    "model = keras.Model(inputs=[in_x, in_a], outputs=gat_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968496c1",
   "metadata": {},
   "source": [
    "#### 1.4.2 Setup and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfd73740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some params\n",
    "LR = 5e-3 # 5e-3  # Learning rate\n",
    "EPOCHS = 10000  # Number of training epochs\n",
    "PATIENCE = 30  # Patience for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f8d7e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1433)]       0           []                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1433)         0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2708)]       0           []                               \n",
      "                                                                                                  \n",
      " gat_conv (GATConv)             (None, 128)          183808      ['dropout[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['gat_conv[0][0]']               \n",
      "                                                                                                  \n",
      " gat_conv_1 (GATConv)           (None, 7)            7287        ['dropout_1[0][0]',              \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 191,095\n",
      "Trainable params: 191,095\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\envs\\tf-spektral-minimal\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(lr=LR)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.CategoricalCrossentropy(reduction='sum'),\n",
    "    weighted_metrics=['acc'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d66d0",
   "metadata": {},
   "source": [
    "#### 1.4.3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "369279a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/1 [==============================] - 4s 4s/step - loss: 5269.4502 - acc: 0.1920 - val_loss: 5250.2720 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5250.3164 - acc: 0.3028 - val_loss: 5220.9497 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5221.0884 - acc: 0.3021 - val_loss: 5180.5308 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5180.5630 - acc: 0.3021 - val_loss: 5129.6333 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5129.4375 - acc: 0.3021 - val_loss: 5069.9312 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5070.0918 - acc: 0.3021 - val_loss: 5004.1396 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5003.2622 - acc: 0.3021 - val_loss: 4935.8794 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4936.2476 - acc: 0.3021 - val_loss: 4869.4023 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4869.8936 - acc: 0.3021 - val_loss: 4809.0029 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4807.9683 - acc: 0.3021 - val_loss: 4757.9985 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4756.3638 - acc: 0.3021 - val_loss: 4716.7109 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4720.2642 - acc: 0.3021 - val_loss: 4680.4121 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4681.2661 - acc: 0.3021 - val_loss: 4640.7344 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4643.1279 - acc: 0.3021 - val_loss: 4590.7510 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4588.2988 - acc: 0.3021 - val_loss: 4528.9839 - val_acc: 0.3021 - lr: 0.0050\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4524.2544 - acc: 0.3021 - val_loss: 4457.8618 - val_acc: 0.3039 - lr: 0.0050\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4467.0771 - acc: 0.3039 - val_loss: 4380.9351 - val_acc: 0.3039 - lr: 0.0050\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4385.1382 - acc: 0.3039 - val_loss: 4301.0459 - val_acc: 0.3039 - lr: 0.0050\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4305.2739 - acc: 0.3043 - val_loss: 4219.4268 - val_acc: 0.3065 - lr: 0.0050\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4229.0693 - acc: 0.3072 - val_loss: 4136.1064 - val_acc: 0.3309 - lr: 0.0050\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4132.2700 - acc: 0.3416 - val_loss: 4050.1399 - val_acc: 0.3988 - lr: 0.0050\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4048.9292 - acc: 0.4003 - val_loss: 3960.1746 - val_acc: 0.4749 - lr: 0.0050\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3958.7209 - acc: 0.4734 - val_loss: 3864.9937 - val_acc: 0.5388 - lr: 0.0050\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3860.1694 - acc: 0.5454 - val_loss: 3763.8010 - val_acc: 0.6019 - lr: 0.0050\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3761.5742 - acc: 0.6004 - val_loss: 3656.3452 - val_acc: 0.6455 - lr: 0.0050\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3657.4878 - acc: 0.6440 - val_loss: 3542.6685 - val_acc: 0.6813 - lr: 0.0050\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3552.5532 - acc: 0.6787 - val_loss: 3423.4890 - val_acc: 0.7046 - lr: 0.0050\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3429.2412 - acc: 0.7016 - val_loss: 3300.1641 - val_acc: 0.7212 - lr: 0.0050\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3297.3169 - acc: 0.7205 - val_loss: 3174.4133 - val_acc: 0.7338 - lr: 0.0050\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3188.3257 - acc: 0.7304 - val_loss: 3048.0493 - val_acc: 0.7463 - lr: 0.0050\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3055.4968 - acc: 0.7459 - val_loss: 2922.7183 - val_acc: 0.7589 - lr: 0.0050\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2927.9614 - acc: 0.7563 - val_loss: 2799.7539 - val_acc: 0.7718 - lr: 0.0050\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2820.0464 - acc: 0.7677 - val_loss: 2680.1919 - val_acc: 0.7803 - lr: 0.0050\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2684.7668 - acc: 0.7806 - val_loss: 2564.7808 - val_acc: 0.7914 - lr: 0.0050\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2582.5388 - acc: 0.7921 - val_loss: 2454.1326 - val_acc: 0.8002 - lr: 0.0050\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2457.9712 - acc: 0.7954 - val_loss: 2348.7390 - val_acc: 0.8069 - lr: 0.0050\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2364.0820 - acc: 0.8054 - val_loss: 2248.9458 - val_acc: 0.8146 - lr: 0.0050\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2261.4338 - acc: 0.8120 - val_loss: 2154.8008 - val_acc: 0.8253 - lr: 0.0050\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2183.8228 - acc: 0.8242 - val_loss: 2066.1404 - val_acc: 0.8353 - lr: 0.0050\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2087.9797 - acc: 0.8275 - val_loss: 1982.7548 - val_acc: 0.8468 - lr: 0.0050\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1994.1923 - acc: 0.8375 - val_loss: 1904.2384 - val_acc: 0.8538 - lr: 0.0050\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1911.8744 - acc: 0.8486 - val_loss: 1830.3077 - val_acc: 0.8589 - lr: 0.0050\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1846.1202 - acc: 0.8556 - val_loss: 1760.6339 - val_acc: 0.8626 - lr: 0.0050\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1774.9290 - acc: 0.8597 - val_loss: 1695.0029 - val_acc: 0.8678 - lr: 0.0050\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1707.1361 - acc: 0.8752 - val_loss: 1633.0569 - val_acc: 0.8715 - lr: 0.0050\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1654.3643 - acc: 0.8711 - val_loss: 1574.7836 - val_acc: 0.8774 - lr: 0.0050\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1589.2980 - acc: 0.8752 - val_loss: 1519.9147 - val_acc: 0.8804 - lr: 0.0050\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1531.8062 - acc: 0.8848 - val_loss: 1468.1450 - val_acc: 0.8833 - lr: 0.0050\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1482.9135 - acc: 0.8826 - val_loss: 1419.1547 - val_acc: 0.8866 - lr: 0.0050\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1439.9937 - acc: 0.8804 - val_loss: 1372.6516 - val_acc: 0.8881 - lr: 0.0050\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1401.9708 - acc: 0.8837 - val_loss: 1328.3146 - val_acc: 0.8888 - lr: 0.0050\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1348.2721 - acc: 0.8881 - val_loss: 1285.9163 - val_acc: 0.8907 - lr: 0.0050\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1304.8051 - acc: 0.8855 - val_loss: 1245.4688 - val_acc: 0.8925 - lr: 0.0050\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1258.7417 - acc: 0.8914 - val_loss: 1206.8859 - val_acc: 0.8929 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1210.7207 - acc: 0.8900 - val_loss: 1170.2078 - val_acc: 0.8940 - lr: 0.0050\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1187.5861 - acc: 0.8866 - val_loss: 1135.3073 - val_acc: 0.8951 - lr: 0.0050\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1156.4413 - acc: 0.8944 - val_loss: 1102.1844 - val_acc: 0.8966 - lr: 0.0050\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1127.9291 - acc: 0.8951 - val_loss: 1070.7739 - val_acc: 0.8988 - lr: 0.0050\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1090.1654 - acc: 0.8948 - val_loss: 1041.0105 - val_acc: 0.9003 - lr: 0.0050\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1066.6021 - acc: 0.8962 - val_loss: 1012.8201 - val_acc: 0.9010 - lr: 0.0050\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1043.0952 - acc: 0.9010 - val_loss: 986.0704 - val_acc: 0.9021 - lr: 0.0050\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1000.9891 - acc: 0.9055 - val_loss: 960.7184 - val_acc: 0.9044 - lr: 0.0050\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 987.8611 - acc: 0.9014 - val_loss: 936.7091 - val_acc: 0.9066 - lr: 0.0050\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 951.0027 - acc: 0.9066 - val_loss: 914.1179 - val_acc: 0.9081 - lr: 0.0050\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 938.4402 - acc: 0.9044 - val_loss: 892.8004 - val_acc: 0.9088 - lr: 0.0050\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 921.0182 - acc: 0.9073 - val_loss: 872.7059 - val_acc: 0.9106 - lr: 0.0050\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 895.7396 - acc: 0.9114 - val_loss: 853.7740 - val_acc: 0.9114 - lr: 0.0050\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 884.2048 - acc: 0.9077 - val_loss: 835.9346 - val_acc: 0.9125 - lr: 0.0050\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 850.7516 - acc: 0.9103 - val_loss: 818.9969 - val_acc: 0.9140 - lr: 0.0050\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 841.7618 - acc: 0.9099 - val_loss: 802.9130 - val_acc: 0.9147 - lr: 0.0050\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 816.3818 - acc: 0.9099 - val_loss: 787.7273 - val_acc: 0.9147 - lr: 0.0050\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 810.6022 - acc: 0.9110 - val_loss: 773.3134 - val_acc: 0.9162 - lr: 0.0050\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 798.6052 - acc: 0.9117 - val_loss: 759.6995 - val_acc: 0.9180 - lr: 0.0050\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 789.4940 - acc: 0.9136 - val_loss: 746.7700 - val_acc: 0.9191 - lr: 0.0050\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 757.4811 - acc: 0.9184 - val_loss: 734.4795 - val_acc: 0.9195 - lr: 0.0050\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 759.0008 - acc: 0.9173 - val_loss: 722.8864 - val_acc: 0.9206 - lr: 0.0050\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 752.6054 - acc: 0.9154 - val_loss: 712.0168 - val_acc: 0.9217 - lr: 0.0050\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 731.9168 - acc: 0.9217 - val_loss: 701.8918 - val_acc: 0.9225 - lr: 0.0050\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 731.0823 - acc: 0.9217 - val_loss: 692.1316 - val_acc: 0.9239 - lr: 0.0050\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 718.5344 - acc: 0.9225 - val_loss: 682.2875 - val_acc: 0.9250 - lr: 0.0050\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 709.5428 - acc: 0.9232 - val_loss: 672.6022 - val_acc: 0.9247 - lr: 0.0050\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 704.5272 - acc: 0.9191 - val_loss: 663.3912 - val_acc: 0.9236 - lr: 0.0050\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 684.6877 - acc: 0.9213 - val_loss: 654.7346 - val_acc: 0.9250 - lr: 0.0050\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 677.2130 - acc: 0.9225 - val_loss: 646.3749 - val_acc: 0.9258 - lr: 0.0050\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 669.4967 - acc: 0.9206 - val_loss: 638.2845 - val_acc: 0.9261 - lr: 0.0050\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 659.4568 - acc: 0.9254 - val_loss: 630.3967 - val_acc: 0.9276 - lr: 0.0050\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 652.1116 - acc: 0.9225 - val_loss: 622.7997 - val_acc: 0.9284 - lr: 0.0050\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 653.0305 - acc: 0.9228 - val_loss: 615.5074 - val_acc: 0.9287 - lr: 0.0050\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 639.0818 - acc: 0.9232 - val_loss: 608.4903 - val_acc: 0.9287 - lr: 0.0050\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 629.1140 - acc: 0.9265 - val_loss: 601.6993 - val_acc: 0.9291 - lr: 0.0050\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 619.3837 - acc: 0.9273 - val_loss: 595.0991 - val_acc: 0.9298 - lr: 0.0050\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 622.3227 - acc: 0.9273 - val_loss: 588.7531 - val_acc: 0.9302 - lr: 0.0050\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 610.7578 - acc: 0.9295 - val_loss: 582.5014 - val_acc: 0.9309 - lr: 0.0050\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 614.6837 - acc: 0.9258 - val_loss: 576.3723 - val_acc: 0.9309 - lr: 0.0050\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 596.9874 - acc: 0.9291 - val_loss: 570.3474 - val_acc: 0.9321 - lr: 0.0050\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 583.1385 - acc: 0.9280 - val_loss: 564.5630 - val_acc: 0.9317 - lr: 0.0050\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 593.2824 - acc: 0.9284 - val_loss: 558.8028 - val_acc: 0.9321 - lr: 0.0050\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 578.0942 - acc: 0.9284 - val_loss: 553.1838 - val_acc: 0.9321 - lr: 0.0050\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 575.9226 - acc: 0.9302 - val_loss: 547.7063 - val_acc: 0.9335 - lr: 0.0050\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 575.4973 - acc: 0.9313 - val_loss: 542.4687 - val_acc: 0.9339 - lr: 0.0050\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 571.2725 - acc: 0.9328 - val_loss: 536.9891 - val_acc: 0.9339 - lr: 0.0050\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 564.6201 - acc: 0.9324 - val_loss: 531.6449 - val_acc: 0.9354 - lr: 0.0050\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 559.7292 - acc: 0.9317 - val_loss: 526.6121 - val_acc: 0.9350 - lr: 0.0050\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 546.9222 - acc: 0.9350 - val_loss: 521.6190 - val_acc: 0.9350 - lr: 0.0050\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 539.4468 - acc: 0.9321 - val_loss: 516.6056 - val_acc: 0.9357 - lr: 0.0050\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 536.9435 - acc: 0.9339 - val_loss: 511.6415 - val_acc: 0.9372 - lr: 0.0050\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 539.6395 - acc: 0.9332 - val_loss: 506.7061 - val_acc: 0.9365 - lr: 0.0050\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 535.5349 - acc: 0.9317 - val_loss: 502.0579 - val_acc: 0.9383 - lr: 0.0050\n",
      "Epoch 109/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 527.8198 - acc: 0.9354 - val_loss: 497.7463 - val_acc: 0.9398 - lr: 0.0050\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 520.1163 - acc: 0.9357 - val_loss: 493.2611 - val_acc: 0.9405 - lr: 0.0050\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 513.3343 - acc: 0.9335 - val_loss: 488.5224 - val_acc: 0.9405 - lr: 0.0050\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 522.3237 - acc: 0.9369 - val_loss: 483.6100 - val_acc: 0.9405 - lr: 0.0050\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 505.7929 - acc: 0.9380 - val_loss: 479.1636 - val_acc: 0.9398 - lr: 0.0050\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 506.0371 - acc: 0.9380 - val_loss: 475.1804 - val_acc: 0.9417 - lr: 0.0050\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 504.7724 - acc: 0.9391 - val_loss: 471.3073 - val_acc: 0.9424 - lr: 0.0050\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 497.8476 - acc: 0.9380 - val_loss: 467.0031 - val_acc: 0.9424 - lr: 0.0050\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 496.3948 - acc: 0.9372 - val_loss: 462.3315 - val_acc: 0.9442 - lr: 0.0050\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 491.6246 - acc: 0.9409 - val_loss: 457.8379 - val_acc: 0.9450 - lr: 0.0050\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 484.3803 - acc: 0.9391 - val_loss: 453.9570 - val_acc: 0.9442 - lr: 0.0050\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 483.7350 - acc: 0.9424 - val_loss: 450.3462 - val_acc: 0.9439 - lr: 0.0050\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 487.7695 - acc: 0.9357 - val_loss: 446.4904 - val_acc: 0.9450 - lr: 0.0050\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 473.1631 - acc: 0.9409 - val_loss: 442.3218 - val_acc: 0.9465 - lr: 0.0050\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 463.9738 - acc: 0.9417 - val_loss: 437.9458 - val_acc: 0.9479 - lr: 0.0050\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 468.3665 - acc: 0.9413 - val_loss: 433.9186 - val_acc: 0.9487 - lr: 0.0050\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 467.8509 - acc: 0.9417 - val_loss: 430.2161 - val_acc: 0.9501 - lr: 0.0050\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 457.1544 - acc: 0.9424 - val_loss: 426.7643 - val_acc: 0.9498 - lr: 0.0050\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 455.2140 - acc: 0.9428 - val_loss: 423.2327 - val_acc: 0.9501 - lr: 0.0050\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 453.0528 - acc: 0.9431 - val_loss: 419.7682 - val_acc: 0.9513 - lr: 0.0050\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 454.6775 - acc: 0.9483 - val_loss: 415.9458 - val_acc: 0.9520 - lr: 0.0050\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 447.3552 - acc: 0.9439 - val_loss: 411.9439 - val_acc: 0.9527 - lr: 0.0050\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 446.1849 - acc: 0.9446 - val_loss: 408.1430 - val_acc: 0.9516 - lr: 0.0050\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 434.5150 - acc: 0.9465 - val_loss: 404.5854 - val_acc: 0.9535 - lr: 0.0050\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 434.1957 - acc: 0.9476 - val_loss: 400.9133 - val_acc: 0.9535 - lr: 0.0050\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 429.4239 - acc: 0.9509 - val_loss: 397.0356 - val_acc: 0.9546 - lr: 0.0050\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 433.7521 - acc: 0.9494 - val_loss: 393.3572 - val_acc: 0.9557 - lr: 0.0050\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 427.0772 - acc: 0.9501 - val_loss: 390.0232 - val_acc: 0.9553 - lr: 0.0050\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 420.5076 - acc: 0.9524 - val_loss: 386.9117 - val_acc: 0.9549 - lr: 0.0050\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 424.1143 - acc: 0.9479 - val_loss: 383.3559 - val_acc: 0.9553 - lr: 0.0050\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 414.7589 - acc: 0.9505 - val_loss: 379.6655 - val_acc: 0.9557 - lr: 0.0050\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 406.7195 - acc: 0.9527 - val_loss: 376.2619 - val_acc: 0.9557 - lr: 0.0050\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 403.7491 - acc: 0.9516 - val_loss: 373.2584 - val_acc: 0.9579 - lr: 0.0050\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 404.8466 - acc: 0.9494 - val_loss: 370.2790 - val_acc: 0.9579 - lr: 0.0050\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 403.1677 - acc: 0.9494 - val_loss: 367.0473 - val_acc: 0.9586 - lr: 0.0050\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 392.0610 - acc: 0.9535 - val_loss: 363.7706 - val_acc: 0.9583 - lr: 0.0050\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 394.5721 - acc: 0.9498 - val_loss: 359.9385 - val_acc: 0.9601 - lr: 0.0050\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 394.0343 - acc: 0.9527 - val_loss: 356.8515 - val_acc: 0.9590 - lr: 0.0050\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 394.1634 - acc: 0.9516 - val_loss: 354.0085 - val_acc: 0.9594 - lr: 0.0050\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 394.7185 - acc: 0.9516 - val_loss: 350.9608 - val_acc: 0.9612 - lr: 0.0050\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 378.8626 - acc: 0.9538 - val_loss: 347.3597 - val_acc: 0.9616 - lr: 0.0050\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 393.2057 - acc: 0.9546 - val_loss: 344.1648 - val_acc: 0.9616 - lr: 0.0050\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 377.2544 - acc: 0.9531 - val_loss: 341.4756 - val_acc: 0.9601 - lr: 0.0050\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 374.8614 - acc: 0.9516 - val_loss: 338.8564 - val_acc: 0.9594 - lr: 0.0050\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 364.3219 - acc: 0.9561 - val_loss: 336.3574 - val_acc: 0.9590 - lr: 0.0050\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 382.7354 - acc: 0.9487 - val_loss: 332.6278 - val_acc: 0.9605 - lr: 0.0050\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 373.7498 - acc: 0.9505 - val_loss: 329.4163 - val_acc: 0.9623 - lr: 0.0050\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 368.4721 - acc: 0.9538 - val_loss: 326.9512 - val_acc: 0.9627 - lr: 0.0050\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 355.9235 - acc: 0.9557 - val_loss: 324.5903 - val_acc: 0.9631 - lr: 0.0050\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 358.6212 - acc: 0.9572 - val_loss: 322.1726 - val_acc: 0.9638 - lr: 0.0050\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 353.1936 - acc: 0.9575 - val_loss: 318.8426 - val_acc: 0.9634 - lr: 0.0050\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 350.9515 - acc: 0.9564 - val_loss: 315.6515 - val_acc: 0.9642 - lr: 0.0050\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 352.8948 - acc: 0.9575 - val_loss: 313.3734 - val_acc: 0.9623 - lr: 0.0050\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 346.9224 - acc: 0.9553 - val_loss: 311.7917 - val_acc: 0.9616 - lr: 0.0050\n",
      "Epoch 163/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 348.3588 - acc: 0.9557 - val_loss: 309.1431 - val_acc: 0.9620 - lr: 0.0050\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 345.1612 - acc: 0.9583 - val_loss: 305.6827 - val_acc: 0.9631 - lr: 0.0050\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 338.6689 - acc: 0.9561 - val_loss: 302.4495 - val_acc: 0.9660 - lr: 0.0050\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 327.8270 - acc: 0.9572 - val_loss: 299.6049 - val_acc: 0.9653 - lr: 0.0050\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 336.9610 - acc: 0.9572 - val_loss: 296.8317 - val_acc: 0.9649 - lr: 0.0050\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 337.3746 - acc: 0.9572 - val_loss: 293.6708 - val_acc: 0.9657 - lr: 0.0050\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 321.1694 - acc: 0.9620 - val_loss: 290.9247 - val_acc: 0.9664 - lr: 0.0050\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 325.4843 - acc: 0.9597 - val_loss: 288.9342 - val_acc: 0.9671 - lr: 0.0050\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 322.1769 - acc: 0.9616 - val_loss: 287.2458 - val_acc: 0.9668 - lr: 0.0050\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 320.3377 - acc: 0.9634 - val_loss: 285.2829 - val_acc: 0.9668 - lr: 0.0050\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 328.8411 - acc: 0.9597 - val_loss: 281.9917 - val_acc: 0.9668 - lr: 0.0050\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 327.8641 - acc: 0.9557 - val_loss: 278.4492 - val_acc: 0.9675 - lr: 0.0050\n",
      "Epoch 175/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 312.6192 - acc: 0.9631 - val_loss: 275.5628 - val_acc: 0.9697 - lr: 0.0050\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 321.0099 - acc: 0.9623 - val_loss: 273.8116 - val_acc: 0.9697 - lr: 0.0050\n",
      "Epoch 177/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 313.2237 - acc: 0.9597 - val_loss: 272.1732 - val_acc: 0.9697 - lr: 0.0050\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 311.7277 - acc: 0.9616 - val_loss: 269.5701 - val_acc: 0.9708 - lr: 0.0050\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 300.1136 - acc: 0.9649 - val_loss: 266.6364 - val_acc: 0.9708 - lr: 0.0050\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 307.9108 - acc: 0.9631 - val_loss: 263.9393 - val_acc: 0.9716 - lr: 0.0050\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 302.0493 - acc: 0.9634 - val_loss: 262.1723 - val_acc: 0.9712 - lr: 0.0050\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 296.7565 - acc: 0.9638 - val_loss: 260.7403 - val_acc: 0.9697 - lr: 0.0050\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 300.8218 - acc: 0.9627 - val_loss: 258.7614 - val_acc: 0.9697 - lr: 0.0050\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 297.8665 - acc: 0.9616 - val_loss: 255.5609 - val_acc: 0.9701 - lr: 0.0050\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 287.9814 - acc: 0.9649 - val_loss: 252.7324 - val_acc: 0.9712 - lr: 0.0050\n",
      "Epoch 186/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 288.4280 - acc: 0.9616 - val_loss: 250.7677 - val_acc: 0.9719 - lr: 0.0050\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 287.0445 - acc: 0.9616 - val_loss: 249.1155 - val_acc: 0.9727 - lr: 0.0050\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 292.4097 - acc: 0.9634 - val_loss: 247.2424 - val_acc: 0.9727 - lr: 0.0050\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 283.8846 - acc: 0.9623 - val_loss: 244.5774 - val_acc: 0.9738 - lr: 0.0050\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 281.3635 - acc: 0.9642 - val_loss: 242.2942 - val_acc: 0.9742 - lr: 0.0050\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 286.7149 - acc: 0.9620 - val_loss: 240.8454 - val_acc: 0.9734 - lr: 0.0050\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 278.2634 - acc: 0.9645 - val_loss: 239.5862 - val_acc: 0.9738 - lr: 0.0050\n",
      "Epoch 193/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 266.3083 - acc: 0.9686 - val_loss: 238.0988 - val_acc: 0.9742 - lr: 0.0050\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 277.0571 - acc: 0.9649 - val_loss: 235.0636 - val_acc: 0.9745 - lr: 0.0050\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 281.0676 - acc: 0.9638 - val_loss: 232.4437 - val_acc: 0.9756 - lr: 0.0050\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 271.8833 - acc: 0.9671 - val_loss: 230.8195 - val_acc: 0.9753 - lr: 0.0050\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 274.4910 - acc: 0.9634 - val_loss: 229.3636 - val_acc: 0.9764 - lr: 0.0050\n",
      "Epoch 198/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 285.9108 - acc: 0.9649 - val_loss: 227.3001 - val_acc: 0.9764 - lr: 0.0050\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 269.5052 - acc: 0.9671 - val_loss: 225.1307 - val_acc: 0.9760 - lr: 0.0050\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 264.2515 - acc: 0.9682 - val_loss: 223.3165 - val_acc: 0.9767 - lr: 0.0050\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 269.4199 - acc: 0.9645 - val_loss: 222.2554 - val_acc: 0.9775 - lr: 0.0050\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 266.1634 - acc: 0.9682 - val_loss: 220.9708 - val_acc: 0.9771 - lr: 0.0050\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 267.6678 - acc: 0.9664 - val_loss: 219.3385 - val_acc: 0.9767 - lr: 0.0050\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 256.0519 - acc: 0.9682 - val_loss: 216.8528 - val_acc: 0.9767 - lr: 0.0050\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 264.3556 - acc: 0.9697 - val_loss: 214.6244 - val_acc: 0.9764 - lr: 0.0050\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 263.5459 - acc: 0.9664 - val_loss: 213.7767 - val_acc: 0.9760 - lr: 0.0050\n",
      "Epoch 207/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 252.0120 - acc: 0.9694 - val_loss: 213.5240 - val_acc: 0.9745 - lr: 0.0050\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 250.0757 - acc: 0.9697 - val_loss: 212.2767 - val_acc: 0.9745 - lr: 0.0050\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 254.9653 - acc: 0.9664 - val_loss: 209.4957 - val_acc: 0.9753 - lr: 0.0050\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 250.7348 - acc: 0.9686 - val_loss: 206.6654 - val_acc: 0.9775 - lr: 0.0050\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 250.6650 - acc: 0.9727 - val_loss: 205.4943 - val_acc: 0.9793 - lr: 0.0050\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 248.9440 - acc: 0.9701 - val_loss: 204.8863 - val_acc: 0.9790 - lr: 0.0050\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 248.2082 - acc: 0.9690 - val_loss: 203.4237 - val_acc: 0.9793 - lr: 0.0050\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 243.2263 - acc: 0.9690 - val_loss: 201.1464 - val_acc: 0.9793 - lr: 0.0050\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 240.8837 - acc: 0.9697 - val_loss: 198.5665 - val_acc: 0.9790 - lr: 0.0050\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 239.3015 - acc: 0.9719 - val_loss: 196.8473 - val_acc: 0.9797 - lr: 0.0050\n",
      "Epoch 217/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 244.7459 - acc: 0.9682 - val_loss: 196.4321 - val_acc: 0.9786 - lr: 0.0050\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 240.7895 - acc: 0.9723 - val_loss: 196.1122 - val_acc: 0.9775 - lr: 0.0050\n",
      "Epoch 219/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 254.8184 - acc: 0.9679 - val_loss: 195.3847 - val_acc: 0.9771 - lr: 0.0050\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 236.9138 - acc: 0.9694 - val_loss: 193.4161 - val_acc: 0.9778 - lr: 0.0050\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 237.3855 - acc: 0.9694 - val_loss: 190.4510 - val_acc: 0.9778 - lr: 0.0050\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 231.8788 - acc: 0.9727 - val_loss: 188.5437 - val_acc: 0.9790 - lr: 0.0050\n",
      "Epoch 223/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 225.3437 - acc: 0.9734 - val_loss: 188.2760 - val_acc: 0.9782 - lr: 0.0050\n",
      "Epoch 224/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 213.4608 - acc: 0.9749 - val_loss: 188.0267 - val_acc: 0.9786 - lr: 0.0050\n",
      "Epoch 225/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 233.3396 - acc: 0.9734 - val_loss: 186.4908 - val_acc: 0.9793 - lr: 0.0050\n",
      "Epoch 226/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 221.0106 - acc: 0.9727 - val_loss: 183.8289 - val_acc: 0.9797 - lr: 0.0050\n",
      "Epoch 227/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 222.4105 - acc: 0.9760 - val_loss: 181.5710 - val_acc: 0.9797 - lr: 0.0050\n",
      "Epoch 228/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 222.7846 - acc: 0.9756 - val_loss: 180.6864 - val_acc: 0.9808 - lr: 0.0050\n",
      "Epoch 229/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 223.4463 - acc: 0.9730 - val_loss: 180.4025 - val_acc: 0.9815 - lr: 0.0050\n",
      "Epoch 230/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 221.0123 - acc: 0.9730 - val_loss: 178.7292 - val_acc: 0.9808 - lr: 0.0050\n",
      "Epoch 231/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 226.3045 - acc: 0.9723 - val_loss: 176.5919 - val_acc: 0.9808 - lr: 0.0050\n",
      "Epoch 232/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 221.5386 - acc: 0.9719 - val_loss: 174.7231 - val_acc: 0.9804 - lr: 0.0050\n",
      "Epoch 233/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 213.8581 - acc: 0.9730 - val_loss: 173.3149 - val_acc: 0.9797 - lr: 0.0050\n",
      "Epoch 234/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 215.1317 - acc: 0.9716 - val_loss: 172.0656 - val_acc: 0.9808 - lr: 0.0050\n",
      "Epoch 235/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 209.6779 - acc: 0.9764 - val_loss: 170.4932 - val_acc: 0.9815 - lr: 0.0050\n",
      "Epoch 236/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 213.5743 - acc: 0.9753 - val_loss: 169.1021 - val_acc: 0.9826 - lr: 0.0050\n",
      "Epoch 237/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 220.0106 - acc: 0.9712 - val_loss: 167.5775 - val_acc: 0.9823 - lr: 0.0050\n",
      "Epoch 238/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 209.4484 - acc: 0.9786 - val_loss: 166.2144 - val_acc: 0.9830 - lr: 0.0050\n",
      "Epoch 239/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 207.3593 - acc: 0.9730 - val_loss: 165.1371 - val_acc: 0.9826 - lr: 0.0050\n",
      "Epoch 240/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 209.3134 - acc: 0.9727 - val_loss: 164.0471 - val_acc: 0.9834 - lr: 0.0050\n",
      "Epoch 241/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 206.1316 - acc: 0.9734 - val_loss: 162.7711 - val_acc: 0.9830 - lr: 0.0050\n",
      "Epoch 242/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 208.2100 - acc: 0.9730 - val_loss: 161.7891 - val_acc: 0.9830 - lr: 0.0050\n",
      "Epoch 243/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 194.0153 - acc: 0.9782 - val_loss: 160.9746 - val_acc: 0.9830 - lr: 0.0050\n",
      "Epoch 244/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 199.8112 - acc: 0.9749 - val_loss: 160.1405 - val_acc: 0.9830 - lr: 0.0050\n",
      "Epoch 245/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 199.8565 - acc: 0.9771 - val_loss: 159.2041 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 246/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 215.8534 - acc: 0.9727 - val_loss: 157.9760 - val_acc: 0.9841 - lr: 0.0050\n",
      "Epoch 247/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 199.7724 - acc: 0.9775 - val_loss: 156.7152 - val_acc: 0.9841 - lr: 0.0050\n",
      "Epoch 248/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 201.5956 - acc: 0.9775 - val_loss: 155.6058 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 249/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 199.6363 - acc: 0.9730 - val_loss: 154.5547 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 250/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 199.6135 - acc: 0.9742 - val_loss: 153.0368 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 251/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 200.1266 - acc: 0.9745 - val_loss: 151.6469 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 252/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 204.4194 - acc: 0.9742 - val_loss: 150.3187 - val_acc: 0.9841 - lr: 0.0050\n",
      "Epoch 253/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 205.0060 - acc: 0.9745 - val_loss: 149.5586 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 254/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 192.6125 - acc: 0.9738 - val_loss: 149.2890 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 255/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 186.1246 - acc: 0.9767 - val_loss: 148.6179 - val_acc: 0.9845 - lr: 0.0050\n",
      "Epoch 256/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 192.6683 - acc: 0.9775 - val_loss: 147.9533 - val_acc: 0.9845 - lr: 0.0050\n",
      "Epoch 257/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 189.7080 - acc: 0.9790 - val_loss: 146.3274 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 258/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 191.5669 - acc: 0.9775 - val_loss: 144.8665 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 259/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 184.3541 - acc: 0.9801 - val_loss: 143.9427 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 260/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 188.3831 - acc: 0.9782 - val_loss: 143.3883 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 261/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 180.7417 - acc: 0.9760 - val_loss: 142.6371 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 262/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 188.3203 - acc: 0.9760 - val_loss: 141.5999 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 263/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 195.5980 - acc: 0.9738 - val_loss: 140.9664 - val_acc: 0.9838 - lr: 0.0050\n",
      "Epoch 264/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 182.5596 - acc: 0.9771 - val_loss: 140.5612 - val_acc: 0.9849 - lr: 0.0050\n",
      "Epoch 265/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 178.2996 - acc: 0.9790 - val_loss: 140.0557 - val_acc: 0.9845 - lr: 0.0050\n",
      "Epoch 266/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 183.7755 - acc: 0.9767 - val_loss: 138.7623 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 267/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 175.2313 - acc: 0.9797 - val_loss: 137.2960 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 268/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 181.3414 - acc: 0.9760 - val_loss: 136.1213 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 269/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 174.3819 - acc: 0.9786 - val_loss: 135.0647 - val_acc: 0.9867 - lr: 0.0050\n",
      "Epoch 270/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 173.0192 - acc: 0.9793 - val_loss: 134.0445 - val_acc: 0.9867 - lr: 0.0050\n",
      "Epoch 271/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 179.5509 - acc: 0.9797 - val_loss: 132.7941 - val_acc: 0.9863 - lr: 0.0050\n",
      "Epoch 272/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 169.7448 - acc: 0.9804 - val_loss: 131.3963 - val_acc: 0.9863 - lr: 0.0050\n",
      "Epoch 273/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 173.1365 - acc: 0.9797 - val_loss: 130.2344 - val_acc: 0.9863 - lr: 0.0050\n",
      "Epoch 274/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 165.6458 - acc: 0.9815 - val_loss: 129.1856 - val_acc: 0.9863 - lr: 0.0050\n",
      "Epoch 275/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 172.0986 - acc: 0.9793 - val_loss: 128.4041 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 276/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 175.2216 - acc: 0.9786 - val_loss: 127.5246 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 277/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 163.9049 - acc: 0.9804 - val_loss: 126.8333 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 278/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 162.5741 - acc: 0.9812 - val_loss: 126.2818 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 279/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 173.2358 - acc: 0.9797 - val_loss: 125.6767 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 280/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 168.3591 - acc: 0.9771 - val_loss: 124.9046 - val_acc: 0.9849 - lr: 0.0050\n",
      "Epoch 281/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 173.4663 - acc: 0.9790 - val_loss: 123.9285 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 282/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 167.6244 - acc: 0.9793 - val_loss: 122.8753 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 283/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 179.1921 - acc: 0.9771 - val_loss: 121.7530 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 284/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 159.1014 - acc: 0.9823 - val_loss: 120.7481 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 285/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 153.6611 - acc: 0.9823 - val_loss: 120.1868 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 286/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 158.3569 - acc: 0.9808 - val_loss: 119.9656 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 287/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 160.3296 - acc: 0.9826 - val_loss: 119.9727 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 288/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 158.0415 - acc: 0.9819 - val_loss: 119.5026 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 289/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 155.0501 - acc: 0.9786 - val_loss: 118.5127 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 290/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 173.0732 - acc: 0.9778 - val_loss: 116.4789 - val_acc: 0.9852 - lr: 0.0050\n",
      "Epoch 291/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 153.0341 - acc: 0.9819 - val_loss: 115.1729 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 292/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 159.4211 - acc: 0.9790 - val_loss: 115.5604 - val_acc: 0.9856 - lr: 0.0050\n",
      "Epoch 293/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 167.8722 - acc: 0.9804 - val_loss: 116.1493 - val_acc: 0.9867 - lr: 0.0050\n",
      "Epoch 294/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 151.7653 - acc: 0.9834 - val_loss: 116.3032 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 295/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 159.4920 - acc: 0.9804 - val_loss: 114.8011 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 296/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 149.9660 - acc: 0.9845 - val_loss: 113.0219 - val_acc: 0.9882 - lr: 0.0050\n",
      "Epoch 297/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 159.9075 - acc: 0.9808 - val_loss: 111.6669 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 298/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 152.5099 - acc: 0.9812 - val_loss: 111.3522 - val_acc: 0.9867 - lr: 0.0050\n",
      "Epoch 299/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 150.0931 - acc: 0.9823 - val_loss: 111.4087 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 300/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 150.7877 - acc: 0.9815 - val_loss: 111.2135 - val_acc: 0.9849 - lr: 0.0050\n",
      "Epoch 301/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 148.4458 - acc: 0.9823 - val_loss: 110.4182 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 302/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 154.6145 - acc: 0.9786 - val_loss: 109.0532 - val_acc: 0.9860 - lr: 0.0050\n",
      "Epoch 303/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 156.7836 - acc: 0.9808 - val_loss: 107.4087 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 304/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 158.4039 - acc: 0.9804 - val_loss: 106.8770 - val_acc: 0.9886 - lr: 0.0050\n",
      "Epoch 305/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 142.8317 - acc: 0.9823 - val_loss: 107.0849 - val_acc: 0.9886 - lr: 0.0050\n",
      "Epoch 306/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 144.9546 - acc: 0.9834 - val_loss: 107.1409 - val_acc: 0.9886 - lr: 0.0050\n",
      "Epoch 307/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 152.1921 - acc: 0.9808 - val_loss: 106.2210 - val_acc: 0.9886 - lr: 0.0050\n",
      "Epoch 308/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 153.3180 - acc: 0.9801 - val_loss: 104.8078 - val_acc: 0.9889 - lr: 0.0050\n",
      "Epoch 309/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 155.8322 - acc: 0.9797 - val_loss: 103.3881 - val_acc: 0.9889 - lr: 0.0050\n",
      "Epoch 310/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 148.4454 - acc: 0.9826 - val_loss: 102.7407 - val_acc: 0.9882 - lr: 0.0050\n",
      "Epoch 311/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 151.9263 - acc: 0.9782 - val_loss: 103.1132 - val_acc: 0.9863 - lr: 0.0050\n",
      "Epoch 312/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 140.8338 - acc: 0.9830 - val_loss: 103.3730 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 313/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 148.1849 - acc: 0.9804 - val_loss: 102.8950 - val_acc: 0.9871 - lr: 0.0050\n",
      "Epoch 314/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 151.0273 - acc: 0.9815 - val_loss: 102.4266 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 315/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 154.5599 - acc: 0.9804 - val_loss: 101.1552 - val_acc: 0.9889 - lr: 0.0050\n",
      "Epoch 316/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 146.8952 - acc: 0.9826 - val_loss: 99.7863 - val_acc: 0.9889 - lr: 0.0050\n",
      "Epoch 317/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 144.6366 - acc: 0.9804 - val_loss: 98.4293 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 318/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 134.8587 - acc: 0.9830 - val_loss: 97.4532 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 319/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 144.3408 - acc: 0.9826 - val_loss: 97.1337 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 320/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 141.4466 - acc: 0.9856 - val_loss: 97.0508 - val_acc: 0.9900 - lr: 0.0050\n",
      "Epoch 321/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 140.2292 - acc: 0.9826 - val_loss: 96.8083 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 322/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 130.7730 - acc: 0.9826 - val_loss: 96.2574 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 323/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 134.1187 - acc: 0.9852 - val_loss: 95.4812 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 324/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 136.8468 - acc: 0.9826 - val_loss: 94.5114 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 325/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 135.1634 - acc: 0.9838 - val_loss: 93.8377 - val_acc: 0.9889 - lr: 0.0050\n",
      "Epoch 326/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 129.7403 - acc: 0.9852 - val_loss: 93.4482 - val_acc: 0.9886 - lr: 0.0050\n",
      "Epoch 327/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 124.2060 - acc: 0.9852 - val_loss: 93.4180 - val_acc: 0.9878 - lr: 0.0050\n",
      "Epoch 328/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 130.4216 - acc: 0.9852 - val_loss: 93.2991 - val_acc: 0.9882 - lr: 0.0050\n",
      "Epoch 329/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 127.6907 - acc: 0.9852 - val_loss: 92.6306 - val_acc: 0.9882 - lr: 0.0050\n",
      "Epoch 330/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 128.7053 - acc: 0.9838 - val_loss: 91.2837 - val_acc: 0.9882 - lr: 0.0050\n",
      "Epoch 331/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 132.6453 - acc: 0.9860 - val_loss: 89.9496 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 332/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 136.6096 - acc: 0.9819 - val_loss: 88.9884 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 333/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 133.2170 - acc: 0.9838 - val_loss: 88.2862 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 334/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 133.5589 - acc: 0.9830 - val_loss: 87.8030 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 335/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 147.9518 - acc: 0.9819 - val_loss: 86.8674 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 336/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 126.4617 - acc: 0.9830 - val_loss: 86.5491 - val_acc: 0.9897 - lr: 0.0050\n",
      "Epoch 337/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 129.9724 - acc: 0.9830 - val_loss: 86.5405 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 338/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 129.5754 - acc: 0.9834 - val_loss: 86.4758 - val_acc: 0.9882 - lr: 0.0050\n",
      "Epoch 339/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 134.4357 - acc: 0.9838 - val_loss: 85.8667 - val_acc: 0.9882 - lr: 0.0050\n",
      "Epoch 340/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 125.8033 - acc: 0.9871 - val_loss: 84.8086 - val_acc: 0.9886 - lr: 0.0050\n",
      "Epoch 341/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 123.6064 - acc: 0.9856 - val_loss: 83.8719 - val_acc: 0.9893 - lr: 0.0050\n",
      "Epoch 342/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 117.9743 - acc: 0.9860 - val_loss: 83.0218 - val_acc: 0.9900 - lr: 0.0050\n",
      "Epoch 343/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 130.0947 - acc: 0.9860 - val_loss: 82.2905 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 344/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 124.5918 - acc: 0.9867 - val_loss: 81.6437 - val_acc: 0.9915 - lr: 0.0050\n",
      "Epoch 345/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 125.0813 - acc: 0.9838 - val_loss: 81.2782 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 346/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 118.4796 - acc: 0.9849 - val_loss: 81.2521 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 347/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 111.4885 - acc: 0.9874 - val_loss: 81.4740 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 348/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 121.1192 - acc: 0.9856 - val_loss: 81.4049 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 349/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 128.3441 - acc: 0.9826 - val_loss: 81.1284 - val_acc: 0.9908 - lr: 0.0050\n",
      "Epoch 350/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 124.8982 - acc: 0.9841 - val_loss: 80.1955 - val_acc: 0.9904 - lr: 0.0050\n",
      "Epoch 351/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 124.5579 - acc: 0.9863 - val_loss: 79.2472 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 352/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 113.1560 - acc: 0.9863 - val_loss: 78.6312 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 353/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 124.7783 - acc: 0.9867 - val_loss: 78.6835 - val_acc: 0.9911 - lr: 0.0050\n",
      "Epoch 354/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 115.8399 - acc: 0.9863 - val_loss: 78.9402 - val_acc: 0.9915 - lr: 0.0050\n",
      "Epoch 355/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 112.3880 - acc: 0.9874 - val_loss: 78.7411 - val_acc: 0.9915 - lr: 0.0050\n",
      "Epoch 356/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 116.4779 - acc: 0.9867 - val_loss: 77.5956 - val_acc: 0.9922 - lr: 0.0050\n",
      "Epoch 357/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 115.5285 - acc: 0.9863 - val_loss: 76.5024 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 358/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 110.2079 - acc: 0.9886 - val_loss: 75.9341 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 359/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 113.4508 - acc: 0.9834 - val_loss: 75.4561 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 360/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 114.3974 - acc: 0.9874 - val_loss: 74.9694 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 361/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 121.1418 - acc: 0.9860 - val_loss: 74.1231 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 362/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 118.9686 - acc: 0.9841 - val_loss: 73.4905 - val_acc: 0.9922 - lr: 0.0050\n",
      "Epoch 363/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 106.9859 - acc: 0.9871 - val_loss: 72.9869 - val_acc: 0.9919 - lr: 0.0050\n",
      "Epoch 364/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 122.3603 - acc: 0.9867 - val_loss: 72.4766 - val_acc: 0.9922 - lr: 0.0050\n",
      "Epoch 365/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 104.7034 - acc: 0.9878 - val_loss: 72.0379 - val_acc: 0.9922 - lr: 0.0050\n",
      "Epoch 366/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 115.1040 - acc: 0.9852 - val_loss: 71.7450 - val_acc: 0.9919 - lr: 0.0050\n",
      "Epoch 367/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 113.3793 - acc: 0.9889 - val_loss: 71.5317 - val_acc: 0.9922 - lr: 0.0050\n",
      "Epoch 368/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 113.2385 - acc: 0.9863 - val_loss: 71.3687 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 369/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 114.9783 - acc: 0.9874 - val_loss: 71.1351 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 370/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 100.5367 - acc: 0.9886 - val_loss: 70.6913 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 371/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 105.0189 - acc: 0.9882 - val_loss: 69.9777 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 372/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 108.3248 - acc: 0.9889 - val_loss: 69.3598 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 373/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 108.8747 - acc: 0.9863 - val_loss: 68.8193 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 374/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 107.6111 - acc: 0.9871 - val_loss: 68.4786 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 375/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 100.7336 - acc: 0.9893 - val_loss: 68.4106 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 376/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 107.8542 - acc: 0.9886 - val_loss: 68.5253 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 377/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 102.0319 - acc: 0.9871 - val_loss: 68.4825 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 378/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 111.7211 - acc: 0.9867 - val_loss: 67.8995 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 379/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 110.6921 - acc: 0.9871 - val_loss: 67.0789 - val_acc: 0.9926 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 113.2497 - acc: 0.9856 - val_loss: 65.9863 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 381/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 102.2438 - acc: 0.9893 - val_loss: 65.3340 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 382/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 104.6831 - acc: 0.9852 - val_loss: 64.9926 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 383/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 101.0725 - acc: 0.9878 - val_loss: 64.7174 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 384/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 104.9970 - acc: 0.9878 - val_loss: 64.2261 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 385/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 107.2985 - acc: 0.9860 - val_loss: 63.9086 - val_acc: 0.9926 - lr: 0.0050\n",
      "Epoch 386/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 111.2376 - acc: 0.9856 - val_loss: 63.6368 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 387/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 99.0400 - acc: 0.9867 - val_loss: 63.4487 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 388/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 119.7021 - acc: 0.9856 - val_loss: 63.0351 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 389/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 96.3930 - acc: 0.9893 - val_loss: 62.5740 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 390/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 105.3715 - acc: 0.9863 - val_loss: 62.1516 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 391/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 104.8518 - acc: 0.9871 - val_loss: 61.7598 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 392/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 100.0466 - acc: 0.9871 - val_loss: 61.3925 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 393/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 98.2321 - acc: 0.9871 - val_loss: 61.0836 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 394/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 103.9193 - acc: 0.9874 - val_loss: 60.8176 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 395/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 91.9519 - acc: 0.9889 - val_loss: 60.6636 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 396/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 92.2637 - acc: 0.9889 - val_loss: 60.4422 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 397/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 98.3607 - acc: 0.9878 - val_loss: 60.1286 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 398/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 92.8193 - acc: 0.9889 - val_loss: 59.6447 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 399/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 97.0273 - acc: 0.9908 - val_loss: 59.1630 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 400/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 93.2440 - acc: 0.9882 - val_loss: 58.6097 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 401/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 99.2105 - acc: 0.9874 - val_loss: 58.3614 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 402/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 94.5351 - acc: 0.9904 - val_loss: 58.4131 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 403/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 93.2195 - acc: 0.9897 - val_loss: 58.4577 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 404/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 91.1556 - acc: 0.9874 - val_loss: 58.1459 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 405/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 106.6702 - acc: 0.9863 - val_loss: 57.3890 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 406/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 96.5718 - acc: 0.9874 - val_loss: 56.7486 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 407/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 97.9635 - acc: 0.9889 - val_loss: 56.7707 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 408/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 89.8016 - acc: 0.9897 - val_loss: 57.0817 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 409/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 98.6735 - acc: 0.9874 - val_loss: 57.1188 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 410/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 89.5579 - acc: 0.9893 - val_loss: 56.5221 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 411/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 93.5364 - acc: 0.9878 - val_loss: 55.6646 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 412/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 88.4372 - acc: 0.9897 - val_loss: 55.1207 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 413/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 89.6482 - acc: 0.9900 - val_loss: 55.2064 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 414/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 90.9737 - acc: 0.9911 - val_loss: 55.5485 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 415/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 93.9880 - acc: 0.9889 - val_loss: 55.2874 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 416/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 85.8142 - acc: 0.9904 - val_loss: 54.7028 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 417/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 87.4184 - acc: 0.9915 - val_loss: 54.2176 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 418/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 95.8241 - acc: 0.9886 - val_loss: 53.6315 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 419/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 114.5078 - acc: 0.9856 - val_loss: 53.2489 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 420/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 99.5086 - acc: 0.9893 - val_loss: 53.2664 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 421/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 101.7331 - acc: 0.9871 - val_loss: 53.3809 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 422/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 91.1996 - acc: 0.9900 - val_loss: 53.2077 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 423/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 86.7172 - acc: 0.9908 - val_loss: 53.1052 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 424/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 90.7353 - acc: 0.9897 - val_loss: 52.8776 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 425/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 105.3533 - acc: 0.9874 - val_loss: 52.5547 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 426/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 87.5142 - acc: 0.9915 - val_loss: 52.1814 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 427/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 88.6309 - acc: 0.9886 - val_loss: 52.1356 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 428/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 86.6712 - acc: 0.9915 - val_loss: 52.2215 - val_acc: 0.9934 - lr: 0.0050\n",
      "Epoch 429/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 84.1359 - acc: 0.9897 - val_loss: 52.0473 - val_acc: 0.9930 - lr: 0.0050\n",
      "Epoch 430/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 88.5774 - acc: 0.9900 - val_loss: 51.7983 - val_acc: 0.9937 - lr: 0.0050\n",
      "Epoch 431/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 85.7231 - acc: 0.9882 - val_loss: 51.2855 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 432/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 82.7231 - acc: 0.9900 - val_loss: 50.7074 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 433/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 82.1992 - acc: 0.9886 - val_loss: 50.2433 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 434/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 79.3148 - acc: 0.9926 - val_loss: 50.0994 - val_acc: 0.9945 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 80.6226 - acc: 0.9922 - val_loss: 49.9283 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 436/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 86.8327 - acc: 0.9904 - val_loss: 49.7484 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 437/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 81.9502 - acc: 0.9911 - val_loss: 49.3077 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 438/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 83.1279 - acc: 0.9904 - val_loss: 48.8976 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 439/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 87.4255 - acc: 0.9882 - val_loss: 48.6178 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 440/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 82.0664 - acc: 0.9915 - val_loss: 48.4185 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 441/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 81.8545 - acc: 0.9871 - val_loss: 48.2422 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 442/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 84.7746 - acc: 0.9904 - val_loss: 48.0121 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 443/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 79.5804 - acc: 0.9915 - val_loss: 47.7598 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 444/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 78.9762 - acc: 0.9926 - val_loss: 47.5076 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 445/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 79.8752 - acc: 0.9904 - val_loss: 47.1442 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 446/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 84.5297 - acc: 0.9919 - val_loss: 46.7518 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 447/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 83.8088 - acc: 0.9919 - val_loss: 46.4761 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 448/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 78.6119 - acc: 0.9908 - val_loss: 46.2531 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 449/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 86.1194 - acc: 0.9908 - val_loss: 46.0046 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 450/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 82.2954 - acc: 0.9911 - val_loss: 45.7822 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 451/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 77.6653 - acc: 0.9904 - val_loss: 45.5094 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 452/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 72.6357 - acc: 0.9922 - val_loss: 45.2269 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 453/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 81.9902 - acc: 0.9915 - val_loss: 44.9795 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 454/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 80.8157 - acc: 0.9911 - val_loss: 44.8230 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 455/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 78.5922 - acc: 0.9908 - val_loss: 44.7120 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 456/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 74.5511 - acc: 0.9919 - val_loss: 44.4885 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 457/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 74.0534 - acc: 0.9919 - val_loss: 44.2518 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 458/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 79.6794 - acc: 0.9908 - val_loss: 44.1551 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 459/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 85.8608 - acc: 0.9893 - val_loss: 44.1531 - val_acc: 0.9941 - lr: 0.0050\n",
      "Epoch 460/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 76.0128 - acc: 0.9897 - val_loss: 44.1989 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 461/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 83.2857 - acc: 0.9900 - val_loss: 44.1421 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 462/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 79.9220 - acc: 0.9915 - val_loss: 43.9502 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 463/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 72.6117 - acc: 0.9915 - val_loss: 43.6280 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 464/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 70.0286 - acc: 0.9919 - val_loss: 43.2586 - val_acc: 0.9945 - lr: 0.0050\n",
      "Epoch 465/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 75.5927 - acc: 0.9919 - val_loss: 42.9537 - val_acc: 0.9948 - lr: 0.0050\n",
      "Epoch 466/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 76.9752 - acc: 0.9915 - val_loss: 42.7009 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 467/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 68.8960 - acc: 0.9922 - val_loss: 42.4268 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 468/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 71.8460 - acc: 0.9930 - val_loss: 42.1076 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 469/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 79.7632 - acc: 0.9922 - val_loss: 41.8217 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 470/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 75.5340 - acc: 0.9911 - val_loss: 41.7255 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 471/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 80.9987 - acc: 0.9897 - val_loss: 41.7725 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 472/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 72.2612 - acc: 0.9904 - val_loss: 41.9773 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 473/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 80.1738 - acc: 0.9911 - val_loss: 41.8990 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 474/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 78.8659 - acc: 0.9893 - val_loss: 41.6399 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 475/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 78.9624 - acc: 0.9904 - val_loss: 41.2609 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 476/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 75.3092 - acc: 0.9911 - val_loss: 40.8849 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 477/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 74.5845 - acc: 0.9926 - val_loss: 40.5821 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 478/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 76.1620 - acc: 0.9915 - val_loss: 40.3551 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 479/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 72.6405 - acc: 0.9922 - val_loss: 40.1534 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 480/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 67.0126 - acc: 0.9926 - val_loss: 40.0146 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 481/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 69.2292 - acc: 0.9922 - val_loss: 39.9795 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 482/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 74.5211 - acc: 0.9926 - val_loss: 39.8426 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 483/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 73.8329 - acc: 0.9915 - val_loss: 39.7809 - val_acc: 0.9956 - lr: 0.0050\n",
      "Epoch 484/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 70.8832 - acc: 0.9922 - val_loss: 39.8302 - val_acc: 0.9952 - lr: 0.0050\n",
      "Epoch 485/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 74.9547 - acc: 0.9915 - val_loss: 40.0320 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 486/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 71.7960 - acc: 0.9911 - val_loss: 39.9898 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 487/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 74.9158 - acc: 0.9915 - val_loss: 39.6324 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 488/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 67.9578 - acc: 0.9908 - val_loss: 39.0102 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 489/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 83.1831 - acc: 0.9904 - val_loss: 38.7130 - val_acc: 0.9963 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 73.0064 - acc: 0.9904 - val_loss: 38.6582 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 491/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 65.9723 - acc: 0.9922 - val_loss: 38.5817 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 492/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 64.4230 - acc: 0.9926 - val_loss: 38.4210 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 493/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 80.5227 - acc: 0.9904 - val_loss: 38.2179 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 494/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 76.8539 - acc: 0.9904 - val_loss: 37.8755 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 495/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 63.9620 - acc: 0.9934 - val_loss: 37.7008 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 496/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 73.7649 - acc: 0.9911 - val_loss: 37.5895 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 497/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 69.7394 - acc: 0.9934 - val_loss: 37.5257 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 498/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 68.6960 - acc: 0.9922 - val_loss: 37.5857 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 499/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 68.1971 - acc: 0.9926 - val_loss: 37.5479 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 500/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 68.8861 - acc: 0.9930 - val_loss: 37.3941 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 501/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 64.5798 - acc: 0.9941 - val_loss: 37.1273 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 502/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 64.9501 - acc: 0.9930 - val_loss: 36.7092 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 503/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 71.8586 - acc: 0.9934 - val_loss: 36.2629 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 504/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 72.4478 - acc: 0.9945 - val_loss: 35.9583 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 505/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 67.6996 - acc: 0.9908 - val_loss: 35.7814 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 506/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 66.1192 - acc: 0.9926 - val_loss: 35.7364 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 507/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 67.3840 - acc: 0.9919 - val_loss: 35.7801 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 508/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 64.3182 - acc: 0.9937 - val_loss: 35.9444 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 509/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 64.2980 - acc: 0.9911 - val_loss: 35.9269 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 510/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 64.8999 - acc: 0.9915 - val_loss: 35.8180 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 511/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 66.9745 - acc: 0.9922 - val_loss: 35.7547 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 512/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 69.8104 - acc: 0.9911 - val_loss: 35.8373 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 513/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 66.5221 - acc: 0.9915 - val_loss: 35.8786 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 514/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 65.1905 - acc: 0.9919 - val_loss: 35.7202 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 515/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 67.1832 - acc: 0.9919 - val_loss: 35.3739 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 516/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 63.3934 - acc: 0.9926 - val_loss: 34.9460 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 517/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 63.6393 - acc: 0.9930 - val_loss: 34.4672 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 518/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 68.3793 - acc: 0.9919 - val_loss: 34.1174 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 519/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 62.5545 - acc: 0.9908 - val_loss: 33.8939 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 520/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 58.3814 - acc: 0.9922 - val_loss: 33.6996 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 521/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 57.8106 - acc: 0.9919 - val_loss: 33.5182 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 522/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 56.2220 - acc: 0.9934 - val_loss: 33.4303 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 523/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 62.1531 - acc: 0.9941 - val_loss: 33.4497 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 524/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 60.8717 - acc: 0.9934 - val_loss: 33.3884 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 525/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 70.8901 - acc: 0.9915 - val_loss: 33.3735 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 526/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 64.7352 - acc: 0.9922 - val_loss: 33.4611 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 527/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 69.3889 - acc: 0.9915 - val_loss: 33.6572 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 528/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 67.7762 - acc: 0.9926 - val_loss: 33.8323 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 529/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 63.3312 - acc: 0.9930 - val_loss: 33.8900 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 530/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 62.8684 - acc: 0.9930 - val_loss: 33.6237 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 531/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 58.9964 - acc: 0.9930 - val_loss: 33.3191 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 532/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 62.0656 - acc: 0.9922 - val_loss: 32.9092 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 533/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 62.5009 - acc: 0.9908 - val_loss: 32.6253 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 534/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 61.9733 - acc: 0.9930 - val_loss: 32.4125 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 535/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 62.9188 - acc: 0.9930 - val_loss: 32.2622 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 536/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 64.4238 - acc: 0.9922 - val_loss: 32.1086 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 537/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 61.0751 - acc: 0.9934 - val_loss: 31.9685 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 538/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 72.5475 - acc: 0.9908 - val_loss: 31.6653 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 539/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 63.1474 - acc: 0.9922 - val_loss: 31.3376 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 540/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 59.8066 - acc: 0.9919 - val_loss: 31.1014 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 541/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 60.1260 - acc: 0.9941 - val_loss: 31.0518 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 542/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 61.6706 - acc: 0.9911 - val_loss: 31.1329 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 543/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 64.0789 - acc: 0.9930 - val_loss: 31.1717 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 544/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 61.6079 - acc: 0.9922 - val_loss: 31.1677 - val_acc: 0.9967 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 60.2571 - acc: 0.9926 - val_loss: 31.2740 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 546/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 62.7847 - acc: 0.9930 - val_loss: 31.1717 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 547/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 56.4341 - acc: 0.9922 - val_loss: 30.9821 - val_acc: 0.9959 - lr: 0.0050\n",
      "Epoch 548/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 53.3231 - acc: 0.9934 - val_loss: 30.7186 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 549/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 59.0533 - acc: 0.9937 - val_loss: 30.6325 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 550/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 59.3267 - acc: 0.9937 - val_loss: 30.7935 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 551/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 54.1083 - acc: 0.9945 - val_loss: 31.0973 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 552/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 55.7664 - acc: 0.9941 - val_loss: 31.2815 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 553/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 57.1702 - acc: 0.9937 - val_loss: 31.2339 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 554/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 63.4137 - acc: 0.9945 - val_loss: 30.8042 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 555/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 53.9886 - acc: 0.9934 - val_loss: 30.2411 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 556/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 54.0132 - acc: 0.9937 - val_loss: 29.8321 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 557/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 50.0180 - acc: 0.9952 - val_loss: 29.5289 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 558/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 60.1579 - acc: 0.9930 - val_loss: 29.2091 - val_acc: 0.9963 - lr: 0.0050\n",
      "Epoch 559/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 59.0986 - acc: 0.9926 - val_loss: 29.0479 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 560/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 58.7391 - acc: 0.9926 - val_loss: 28.9805 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 561/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 52.6143 - acc: 0.9952 - val_loss: 28.9547 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 562/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 57.6008 - acc: 0.9941 - val_loss: 28.8817 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 563/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 64.4590 - acc: 0.9908 - val_loss: 28.6978 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 564/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 49.7934 - acc: 0.9959 - val_loss: 28.5903 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 565/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 56.6504 - acc: 0.9937 - val_loss: 28.4518 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 566/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 52.5344 - acc: 0.9930 - val_loss: 28.3787 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 567/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 52.5980 - acc: 0.9952 - val_loss: 28.3032 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 568/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 60.4291 - acc: 0.9922 - val_loss: 28.3171 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 569/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 54.4498 - acc: 0.9934 - val_loss: 28.3608 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 570/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 61.9401 - acc: 0.9915 - val_loss: 28.3089 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 571/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 55.3025 - acc: 0.9937 - val_loss: 28.2336 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 572/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 51.1448 - acc: 0.9941 - val_loss: 28.0632 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 573/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 56.0368 - acc: 0.9930 - val_loss: 27.8604 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 574/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 51.3895 - acc: 0.9952 - val_loss: 27.6948 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 575/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 57.1570 - acc: 0.9941 - val_loss: 27.5350 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 576/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 53.3868 - acc: 0.9934 - val_loss: 27.4135 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 577/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 58.1176 - acc: 0.9948 - val_loss: 27.4062 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 578/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 53.3011 - acc: 0.9930 - val_loss: 27.4019 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 579/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 52.7939 - acc: 0.9934 - val_loss: 27.4322 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 580/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 51.8228 - acc: 0.9945 - val_loss: 27.2722 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 581/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 54.6602 - acc: 0.9934 - val_loss: 26.9986 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 582/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 56.8036 - acc: 0.9941 - val_loss: 26.7845 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 583/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 51.8219 - acc: 0.9937 - val_loss: 26.4701 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 584/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 53.1565 - acc: 0.9941 - val_loss: 26.2764 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 585/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 53.0587 - acc: 0.9941 - val_loss: 26.3024 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 586/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 63.0808 - acc: 0.9922 - val_loss: 26.4567 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 587/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 53.9296 - acc: 0.9934 - val_loss: 26.8547 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 588/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 56.3321 - acc: 0.9937 - val_loss: 27.1502 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 589/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 56.9854 - acc: 0.9934 - val_loss: 27.2252 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 590/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 60.9891 - acc: 0.9922 - val_loss: 26.9602 - val_acc: 0.9967 - lr: 0.0050\n",
      "Epoch 591/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 55.0765 - acc: 0.9937 - val_loss: 26.4677 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 592/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 46.4885 - acc: 0.9963 - val_loss: 26.1629 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 593/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 45.6100 - acc: 0.9963 - val_loss: 26.1203 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 594/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 50.5386 - acc: 0.9948 - val_loss: 26.2972 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 595/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 55.7768 - acc: 0.9930 - val_loss: 26.5683 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 596/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 51.2637 - acc: 0.9945 - val_loss: 26.4872 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 597/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 47.2869 - acc: 0.9937 - val_loss: 26.2891 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 598/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 52.8220 - acc: 0.9945 - val_loss: 25.7517 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 599/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 50.6301 - acc: 0.9941 - val_loss: 25.2542 - val_acc: 0.9978 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 56.7749 - acc: 0.9945 - val_loss: 25.0811 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 601/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 44.7577 - acc: 0.9948 - val_loss: 25.1738 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 602/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 50.4744 - acc: 0.9959 - val_loss: 25.2906 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 603/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 49.6973 - acc: 0.9941 - val_loss: 25.2139 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 604/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 57.4955 - acc: 0.9919 - val_loss: 24.8699 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 605/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 50.1337 - acc: 0.9934 - val_loss: 24.4178 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 606/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 58.5426 - acc: 0.9922 - val_loss: 24.2464 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 607/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 52.8595 - acc: 0.9937 - val_loss: 24.3431 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 608/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 48.4581 - acc: 0.9952 - val_loss: 24.5807 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 609/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 46.7787 - acc: 0.9952 - val_loss: 24.8039 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 610/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 47.7280 - acc: 0.9952 - val_loss: 24.8872 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 611/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 57.6721 - acc: 0.9930 - val_loss: 24.7795 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 612/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 43.9470 - acc: 0.9952 - val_loss: 24.5907 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 613/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 58.0629 - acc: 0.9926 - val_loss: 24.4625 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 614/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 48.1410 - acc: 0.9956 - val_loss: 24.4352 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 615/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 47.1640 - acc: 0.9956 - val_loss: 24.4366 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 616/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 45.5221 - acc: 0.9945 - val_loss: 24.3679 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 617/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 46.6248 - acc: 0.9959 - val_loss: 24.1909 - val_acc: 0.9970 - lr: 0.0050\n",
      "Epoch 618/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 50.6582 - acc: 0.9952 - val_loss: 23.9152 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 619/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 48.6136 - acc: 0.9941 - val_loss: 23.6830 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 620/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 50.4262 - acc: 0.9941 - val_loss: 23.5363 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 621/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 44.3116 - acc: 0.9956 - val_loss: 23.4620 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 622/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 45.2572 - acc: 0.9956 - val_loss: 23.4108 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 623/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 42.0131 - acc: 0.9963 - val_loss: 23.3908 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 624/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 46.5610 - acc: 0.9952 - val_loss: 23.3670 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 625/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 43.4610 - acc: 0.9952 - val_loss: 23.3895 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 626/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 41.1475 - acc: 0.9956 - val_loss: 23.3240 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 627/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 43.2261 - acc: 0.9963 - val_loss: 23.2058 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 628/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 51.7848 - acc: 0.9945 - val_loss: 23.0276 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 629/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 47.1679 - acc: 0.9934 - val_loss: 22.8746 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 630/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 43.9430 - acc: 0.9948 - val_loss: 22.7807 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 631/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 40.4785 - acc: 0.9956 - val_loss: 22.6864 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 632/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 48.1533 - acc: 0.9937 - val_loss: 22.5884 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 633/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 47.0685 - acc: 0.9945 - val_loss: 22.4991 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 634/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 43.1545 - acc: 0.9948 - val_loss: 22.3341 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 635/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 51.6845 - acc: 0.9937 - val_loss: 22.2225 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 636/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 41.7544 - acc: 0.9952 - val_loss: 22.0763 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 637/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 47.9407 - acc: 0.9952 - val_loss: 21.9878 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 638/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 48.4415 - acc: 0.9941 - val_loss: 21.9640 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 639/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 50.9280 - acc: 0.9945 - val_loss: 21.9621 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 640/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 42.7494 - acc: 0.9948 - val_loss: 21.9146 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 641/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 45.4882 - acc: 0.9952 - val_loss: 21.7677 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 642/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 50.8296 - acc: 0.9941 - val_loss: 21.5978 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 643/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 48.7463 - acc: 0.9956 - val_loss: 21.4782 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 644/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 46.8223 - acc: 0.9952 - val_loss: 21.3501 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 645/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 43.1507 - acc: 0.9937 - val_loss: 21.2310 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 646/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 59.0734 - acc: 0.9937 - val_loss: 21.0973 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 647/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 44.7507 - acc: 0.9959 - val_loss: 20.9691 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 648/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 42.0730 - acc: 0.9948 - val_loss: 20.8814 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 649/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 50.1872 - acc: 0.9948 - val_loss: 20.8292 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 650/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 51.4812 - acc: 0.9952 - val_loss: 20.7515 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 651/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 46.0894 - acc: 0.9948 - val_loss: 20.6563 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 652/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 38.6239 - acc: 0.9963 - val_loss: 20.5762 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 653/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 44.1358 - acc: 0.9948 - val_loss: 20.4675 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 654/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 40.9815 - acc: 0.9956 - val_loss: 20.4120 - val_acc: 0.9982 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 39.3204 - acc: 0.9967 - val_loss: 20.4072 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 656/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 37.0392 - acc: 0.9963 - val_loss: 20.4342 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 657/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 40.8521 - acc: 0.9952 - val_loss: 20.4005 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 658/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 44.3554 - acc: 0.9956 - val_loss: 20.3429 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 659/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 44.9432 - acc: 0.9948 - val_loss: 20.3261 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 660/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 42.3752 - acc: 0.9963 - val_loss: 20.4102 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 661/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 33.4715 - acc: 0.9978 - val_loss: 20.4511 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 662/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 40.8650 - acc: 0.9959 - val_loss: 20.4616 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 663/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 38.7591 - acc: 0.9956 - val_loss: 20.3135 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 664/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 40.1727 - acc: 0.9948 - val_loss: 20.1792 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 665/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 35.5860 - acc: 0.9967 - val_loss: 19.9859 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 666/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 43.9610 - acc: 0.9963 - val_loss: 19.7825 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 667/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 41.9245 - acc: 0.9952 - val_loss: 19.6578 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 668/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 42.3671 - acc: 0.9937 - val_loss: 19.5059 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 669/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 40.5794 - acc: 0.9963 - val_loss: 19.4154 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 670/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 43.1043 - acc: 0.9952 - val_loss: 19.3420 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 671/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 36.3215 - acc: 0.9963 - val_loss: 19.2864 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 672/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 37.0428 - acc: 0.9956 - val_loss: 19.2584 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 673/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 39.7070 - acc: 0.9967 - val_loss: 19.2006 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 674/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 42.2165 - acc: 0.9948 - val_loss: 19.1853 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 675/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 44.8139 - acc: 0.9948 - val_loss: 19.2613 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 676/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 37.7967 - acc: 0.9970 - val_loss: 19.4378 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 677/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 51.5869 - acc: 0.9945 - val_loss: 19.5117 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 678/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 39.4779 - acc: 0.9959 - val_loss: 19.4418 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 679/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 44.0303 - acc: 0.9952 - val_loss: 19.2881 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 680/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 33.7130 - acc: 0.9974 - val_loss: 19.1900 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 681/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 34.1244 - acc: 0.9967 - val_loss: 19.1077 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 682/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 36.8704 - acc: 0.9959 - val_loss: 18.9979 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 683/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 40.4651 - acc: 0.9967 - val_loss: 18.8692 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 684/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 46.5714 - acc: 0.9945 - val_loss: 18.8160 - val_acc: 0.9974 - lr: 0.0050\n",
      "Epoch 685/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 35.4005 - acc: 0.9952 - val_loss: 18.8020 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 686/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 41.0846 - acc: 0.9956 - val_loss: 18.7889 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 687/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 44.8398 - acc: 0.9945 - val_loss: 18.6623 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 688/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 34.0106 - acc: 0.9963 - val_loss: 18.5122 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 689/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 44.4604 - acc: 0.9956 - val_loss: 18.4228 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 690/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 45.2578 - acc: 0.9948 - val_loss: 18.4145 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 691/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 41.3579 - acc: 0.9963 - val_loss: 18.4744 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 692/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 37.1815 - acc: 0.9959 - val_loss: 18.5150 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 693/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 35.8078 - acc: 0.9959 - val_loss: 18.3875 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 694/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 41.6264 - acc: 0.9963 - val_loss: 18.1997 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 695/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 37.9362 - acc: 0.9967 - val_loss: 18.0010 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 696/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 42.6579 - acc: 0.9945 - val_loss: 17.8659 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 697/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 35.6919 - acc: 0.9967 - val_loss: 17.8146 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 698/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 32.4494 - acc: 0.9974 - val_loss: 17.8031 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 699/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 40.8788 - acc: 0.9952 - val_loss: 17.8072 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 700/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 37.0216 - acc: 0.9963 - val_loss: 17.8097 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 701/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 32.5034 - acc: 0.9970 - val_loss: 17.8709 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 702/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 35.6203 - acc: 0.9967 - val_loss: 17.9260 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 703/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 34.7571 - acc: 0.9959 - val_loss: 17.8200 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 704/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 38.7440 - acc: 0.9956 - val_loss: 17.7394 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 705/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 43.5076 - acc: 0.9956 - val_loss: 17.7078 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 706/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 42.0459 - acc: 0.9941 - val_loss: 17.7150 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 707/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 40.5932 - acc: 0.9948 - val_loss: 17.7167 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 708/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 34.2773 - acc: 0.9963 - val_loss: 17.6914 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 709/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 38.4395 - acc: 0.9952 - val_loss: 17.5857 - val_acc: 0.9985 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 710/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 42.5676 - acc: 0.9952 - val_loss: 17.5308 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 711/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 32.3795 - acc: 0.9959 - val_loss: 17.4777 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 712/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 34.9158 - acc: 0.9967 - val_loss: 17.4348 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 713/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 42.3760 - acc: 0.9952 - val_loss: 17.3838 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 714/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 37.5788 - acc: 0.9963 - val_loss: 17.3589 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 715/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 37.2372 - acc: 0.9967 - val_loss: 17.3455 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 716/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 34.7676 - acc: 0.9967 - val_loss: 17.2902 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 717/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 38.4961 - acc: 0.9963 - val_loss: 17.2024 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 718/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 32.0826 - acc: 0.9967 - val_loss: 17.0609 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 719/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 32.2192 - acc: 0.9970 - val_loss: 16.9402 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 720/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 35.3803 - acc: 0.9963 - val_loss: 16.8423 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 721/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 36.6951 - acc: 0.9967 - val_loss: 16.7871 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 722/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 42.4359 - acc: 0.9948 - val_loss: 16.8235 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 723/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 42.3904 - acc: 0.9945 - val_loss: 16.9250 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 724/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 31.7834 - acc: 0.9970 - val_loss: 17.0130 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 725/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 34.4635 - acc: 0.9959 - val_loss: 17.1180 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 726/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 39.5519 - acc: 0.9945 - val_loss: 17.1214 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 727/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 37.2562 - acc: 0.9963 - val_loss: 17.0702 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 728/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 38.7975 - acc: 0.9959 - val_loss: 17.0199 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 729/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 37.3053 - acc: 0.9959 - val_loss: 16.9246 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 730/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 33.1276 - acc: 0.9967 - val_loss: 16.8182 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 731/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 41.7221 - acc: 0.9959 - val_loss: 16.6932 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 732/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 34.4219 - acc: 0.9967 - val_loss: 16.5753 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 733/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 35.1976 - acc: 0.9967 - val_loss: 16.5413 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 734/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 29.3472 - acc: 0.9978 - val_loss: 16.4527 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 735/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 40.0473 - acc: 0.9959 - val_loss: 16.3760 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 736/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 34.1853 - acc: 0.9967 - val_loss: 16.2557 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 737/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 33.6635 - acc: 0.9959 - val_loss: 16.1420 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 738/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 34.3438 - acc: 0.9967 - val_loss: 16.0558 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 739/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 38.0653 - acc: 0.9963 - val_loss: 16.0226 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 740/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 29.5129 - acc: 0.9978 - val_loss: 16.0517 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 741/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 42.1337 - acc: 0.9945 - val_loss: 16.0701 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 742/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 31.6772 - acc: 0.9974 - val_loss: 16.1918 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 743/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 36.1773 - acc: 0.9956 - val_loss: 16.2752 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 744/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 30.4484 - acc: 0.9970 - val_loss: 16.2721 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 745/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 34.1159 - acc: 0.9959 - val_loss: 16.1847 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 746/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 34.3544 - acc: 0.9967 - val_loss: 16.0563 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 747/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 37.2318 - acc: 0.9963 - val_loss: 15.9116 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 748/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 32.3554 - acc: 0.9970 - val_loss: 15.8191 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 749/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 36.1745 - acc: 0.9948 - val_loss: 15.7623 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 750/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 37.5176 - acc: 0.9963 - val_loss: 15.7336 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 751/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 35.9208 - acc: 0.9959 - val_loss: 15.7341 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 752/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 31.2903 - acc: 0.9967 - val_loss: 15.7597 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 753/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 31.6539 - acc: 0.9963 - val_loss: 15.7861 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 754/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 31.9631 - acc: 0.9970 - val_loss: 15.7795 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 755/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 32.0468 - acc: 0.9959 - val_loss: 15.7900 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 756/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 40.0035 - acc: 0.9959 - val_loss: 15.8463 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 757/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 31.3555 - acc: 0.9967 - val_loss: 15.9821 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 758/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 34.9507 - acc: 0.9970 - val_loss: 16.1915 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 759/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 31.4903 - acc: 0.9974 - val_loss: 16.2373 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 760/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 43.0021 - acc: 0.9948 - val_loss: 16.1291 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 761/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 33.6890 - acc: 0.9970 - val_loss: 15.9810 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 762/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 33.9524 - acc: 0.9963 - val_loss: 15.8331 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 763/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 32.2956 - acc: 0.9963 - val_loss: 15.6964 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 764/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 38.5491 - acc: 0.9959 - val_loss: 15.6229 - val_acc: 0.9982 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 35.9130 - acc: 0.9956 - val_loss: 15.4986 - val_acc: 0.9978 - lr: 0.0050\n",
      "Epoch 766/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 37.7468 - acc: 0.9948 - val_loss: 15.3598 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 767/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 32.9415 - acc: 0.9963 - val_loss: 15.1841 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 768/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 32.4715 - acc: 0.9967 - val_loss: 15.0925 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 769/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 29.4944 - acc: 0.9970 - val_loss: 15.0842 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 770/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 34.7326 - acc: 0.9963 - val_loss: 15.0645 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 771/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 40.5177 - acc: 0.9956 - val_loss: 15.0088 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 772/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 35.7641 - acc: 0.9970 - val_loss: 14.9701 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 773/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 32.6280 - acc: 0.9967 - val_loss: 14.9149 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 774/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 34.1992 - acc: 0.9959 - val_loss: 14.8317 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 775/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 34.2198 - acc: 0.9956 - val_loss: 14.7802 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 776/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 37.2375 - acc: 0.9959 - val_loss: 14.7448 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 777/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 40.2276 - acc: 0.9959 - val_loss: 14.7271 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 778/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 29.9277 - acc: 0.9963 - val_loss: 14.7831 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 779/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 35.7232 - acc: 0.9959 - val_loss: 14.7786 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 780/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 33.5434 - acc: 0.9952 - val_loss: 14.8006 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 781/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 31.2108 - acc: 0.9963 - val_loss: 14.7857 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 782/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 34.8555 - acc: 0.9967 - val_loss: 14.7011 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 783/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 36.0868 - acc: 0.9952 - val_loss: 14.6275 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 784/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 32.0329 - acc: 0.9967 - val_loss: 14.5296 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 785/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 38.9226 - acc: 0.9952 - val_loss: 14.4524 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 786/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 31.6804 - acc: 0.9956 - val_loss: 14.4072 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 787/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 30.2285 - acc: 0.9970 - val_loss: 14.4204 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 788/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 34.6968 - acc: 0.9952 - val_loss: 14.4279 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 789/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 31.0065 - acc: 0.9963 - val_loss: 14.4072 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 790/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 30.4014 - acc: 0.9963 - val_loss: 14.3834 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 791/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 28.7919 - acc: 0.9970 - val_loss: 14.3897 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 792/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 29.9364 - acc: 0.9970 - val_loss: 14.3756 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 793/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 38.1346 - acc: 0.9959 - val_loss: 14.3603 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 794/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 34.2098 - acc: 0.9963 - val_loss: 14.3082 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 795/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 30.1723 - acc: 0.9967 - val_loss: 14.2820 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 796/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 30.8107 - acc: 0.9967 - val_loss: 14.2336 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 797/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 31.4102 - acc: 0.9963 - val_loss: 14.1872 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 798/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 35.0337 - acc: 0.9963 - val_loss: 14.1454 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 799/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 30.5002 - acc: 0.9963 - val_loss: 14.0892 - val_acc: 0.9982 - lr: 0.0050\n",
      "Epoch 800/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 27.6133 - acc: 0.9970 - val_loss: 13.9827 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 801/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 32.3028 - acc: 0.9963 - val_loss: 13.8887 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 802/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 30.3568 - acc: 0.9970 - val_loss: 13.8147 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 803/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 31.4762 - acc: 0.9963 - val_loss: 13.7444 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 804/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 36.5879 - acc: 0.9948 - val_loss: 13.7072 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 805/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 32.1043 - acc: 0.9970 - val_loss: 13.6647 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 806/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 32.3614 - acc: 0.9963 - val_loss: 13.6272 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 807/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 31.0099 - acc: 0.9967 - val_loss: 13.6054 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 808/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 31.8939 - acc: 0.9963 - val_loss: 13.6169 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 809/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.1259 - acc: 0.9974 - val_loss: 13.6093 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 810/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 27.3363 - acc: 0.9970 - val_loss: 13.5843 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 811/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 27.2905 - acc: 0.9974 - val_loss: 13.5706 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 812/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 31.4895 - acc: 0.9959 - val_loss: 13.4985 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 813/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 28.7711 - acc: 0.9963 - val_loss: 13.4146 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 814/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 29.4373 - acc: 0.9967 - val_loss: 13.3099 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 815/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 28.7852 - acc: 0.9967 - val_loss: 13.2477 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 816/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 24.7092 - acc: 0.9978 - val_loss: 13.2040 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 817/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 33.0308 - acc: 0.9963 - val_loss: 13.1956 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 818/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 28.3990 - acc: 0.9978 - val_loss: 13.1602 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 819/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 29.2887 - acc: 0.9974 - val_loss: 13.1081 - val_acc: 0.9985 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 32.0259 - acc: 0.9963 - val_loss: 13.0651 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 821/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 34.1458 - acc: 0.9963 - val_loss: 13.0506 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 822/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 28.4693 - acc: 0.9970 - val_loss: 13.0586 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 823/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 28.4146 - acc: 0.9970 - val_loss: 13.1249 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 824/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 25.7248 - acc: 0.9970 - val_loss: 13.2072 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 825/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 29.0444 - acc: 0.9970 - val_loss: 13.2713 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 826/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 31.6308 - acc: 0.9970 - val_loss: 13.2578 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 827/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 27.3461 - acc: 0.9970 - val_loss: 13.2025 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 828/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 26.8416 - acc: 0.9978 - val_loss: 13.0809 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 829/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 27.6528 - acc: 0.9974 - val_loss: 12.8966 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 830/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 31.3791 - acc: 0.9959 - val_loss: 12.8093 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 831/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 26.2955 - acc: 0.9982 - val_loss: 12.7452 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 832/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 26.3381 - acc: 0.9978 - val_loss: 12.6770 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 833/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 30.6954 - acc: 0.9967 - val_loss: 12.6167 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 834/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.8949 - acc: 0.9985 - val_loss: 12.5664 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 835/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 33.6036 - acc: 0.9956 - val_loss: 12.5058 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 836/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 29.9853 - acc: 0.9956 - val_loss: 12.4685 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 837/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26.6332 - acc: 0.9963 - val_loss: 12.4924 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 838/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 28.1394 - acc: 0.9974 - val_loss: 12.4888 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 839/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 29.3501 - acc: 0.9956 - val_loss: 12.4760 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 840/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 31.1343 - acc: 0.9967 - val_loss: 12.4633 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 841/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 24.6507 - acc: 0.9974 - val_loss: 12.4573 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 842/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 26.8162 - acc: 0.9970 - val_loss: 12.4782 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 843/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 29.2543 - acc: 0.9974 - val_loss: 12.5162 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 844/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 32.2479 - acc: 0.9963 - val_loss: 12.5618 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 845/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 30.0956 - acc: 0.9978 - val_loss: 12.5033 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 846/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 28.6376 - acc: 0.9974 - val_loss: 12.4398 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 847/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.2566 - acc: 0.9967 - val_loss: 12.3838 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 848/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 25.6461 - acc: 0.9974 - val_loss: 12.3330 - val_acc: 0.9989 - lr: 0.0050\n",
      "Epoch 849/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 26.5054 - acc: 0.9967 - val_loss: 12.3259 - val_acc: 0.9989 - lr: 0.0050\n",
      "Epoch 850/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.6118 - acc: 0.9978 - val_loss: 12.3435 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 851/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 25.5280 - acc: 0.9963 - val_loss: 12.3395 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 852/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 26.3142 - acc: 0.9974 - val_loss: 12.3036 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 853/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 29.4730 - acc: 0.9963 - val_loss: 12.2393 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 854/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 24.5561 - acc: 0.9985 - val_loss: 12.1776 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 855/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 31.7818 - acc: 0.9970 - val_loss: 12.1036 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 856/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 24.9431 - acc: 0.9978 - val_loss: 12.0589 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 857/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 26.3782 - acc: 0.9970 - val_loss: 12.0137 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 858/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 29.5897 - acc: 0.9970 - val_loss: 11.9855 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 859/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.0901 - acc: 0.9974 - val_loss: 11.9751 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 860/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 28.3537 - acc: 0.9963 - val_loss: 11.9851 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 861/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 27.9541 - acc: 0.9963 - val_loss: 12.0349 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 862/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 35.5936 - acc: 0.9959 - val_loss: 12.1250 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 863/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 24.2429 - acc: 0.9974 - val_loss: 12.2053 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 864/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.4721 - acc: 0.9970 - val_loss: 12.2398 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 865/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 25.9674 - acc: 0.9978 - val_loss: 12.2508 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 866/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 21.7612 - acc: 0.9974 - val_loss: 12.1928 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 867/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 27.2463 - acc: 0.9970 - val_loss: 12.1059 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 868/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 25.7095 - acc: 0.9974 - val_loss: 11.9634 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 869/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 26.9791 - acc: 0.9978 - val_loss: 11.8066 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 870/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 21.1148 - acc: 0.9978 - val_loss: 11.6792 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 871/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 25.7474 - acc: 0.9978 - val_loss: 11.5366 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 872/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 24.9407 - acc: 0.9967 - val_loss: 11.4543 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 873/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 26.6410 - acc: 0.9963 - val_loss: 11.4313 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 874/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 24.7181 - acc: 0.9974 - val_loss: 11.4645 - val_acc: 0.9985 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 27.7456 - acc: 0.9967 - val_loss: 11.4658 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 876/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 26.9462 - acc: 0.9963 - val_loss: 11.4472 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 877/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.4438 - acc: 0.9970 - val_loss: 11.4681 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 878/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 24.0542 - acc: 0.9974 - val_loss: 11.5239 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 879/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.8361 - acc: 0.9974 - val_loss: 11.5298 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 880/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 30.9304 - acc: 0.9963 - val_loss: 11.5026 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 881/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 30.6464 - acc: 0.9974 - val_loss: 11.5007 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 882/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 26.0092 - acc: 0.9963 - val_loss: 11.5206 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 883/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 27.8361 - acc: 0.9974 - val_loss: 11.5552 - val_acc: 0.9989 - lr: 0.0050\n",
      "Epoch 884/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 25.9258 - acc: 0.9974 - val_loss: 11.6065 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 885/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 24.5530 - acc: 0.9970 - val_loss: 11.6700 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 886/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.7211 - acc: 0.9970 - val_loss: 11.7456 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 887/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 25.6655 - acc: 0.9974 - val_loss: 11.7217 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 888/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 31.3883 - acc: 0.9963 - val_loss: 11.5162 - val_acc: 0.9985 - lr: 0.0050\n",
      "Epoch 889/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.6659 - acc: 0.9967 - val_loss: 11.3451 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 890/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 23.7357 - acc: 0.9970 - val_loss: 11.1928 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 891/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 26.1738 - acc: 0.9978 - val_loss: 11.0503 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 892/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.2287 - acc: 0.9985 - val_loss: 11.0028 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 893/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22.0871 - acc: 0.9974 - val_loss: 11.0466 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 894/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 26.4124 - acc: 0.9978 - val_loss: 11.1307 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 895/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26.1385 - acc: 0.9970 - val_loss: 11.2335 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 896/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 21.1093 - acc: 0.9978 - val_loss: 11.3564 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 897/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 26.4489 - acc: 0.9974 - val_loss: 11.4611 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 898/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 25.9587 - acc: 0.9970 - val_loss: 11.5041 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 899/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 28.2823 - acc: 0.9967 - val_loss: 11.5199 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 900/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 28.8615 - acc: 0.9963 - val_loss: 11.4410 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 901/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22.2392 - acc: 0.9982 - val_loss: 11.3836 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 902/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 25.5109 - acc: 0.9967 - val_loss: 11.3852 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 903/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.2389 - acc: 0.9974 - val_loss: 11.4408 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 904/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.9174 - acc: 0.9974 - val_loss: 11.4967 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 905/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 25.6046 - acc: 0.9978 - val_loss: 11.5143 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 906/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 30.0372 - acc: 0.9970 - val_loss: 11.4717 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 907/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26.3871 - acc: 0.9967 - val_loss: 11.3692 - val_acc: 0.9985 - lr: 0.0045\n",
      "Epoch 908/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.3612 - acc: 0.9985 - val_loss: 11.2804 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 909/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 24.0047 - acc: 0.9974 - val_loss: 11.1715 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 910/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 24.7713 - acc: 0.9967 - val_loss: 11.1072 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 911/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 25.8290 - acc: 0.9970 - val_loss: 11.0687 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 912/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 25.4840 - acc: 0.9967 - val_loss: 11.0300 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 913/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 24.6925 - acc: 0.9967 - val_loss: 10.9963 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 914/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 21.1714 - acc: 0.9985 - val_loss: 10.9596 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 915/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 21.6235 - acc: 0.9974 - val_loss: 10.9196 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 916/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 24.1066 - acc: 0.9967 - val_loss: 10.8550 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 917/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.3853 - acc: 0.9978 - val_loss: 10.7923 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 918/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 33.0566 - acc: 0.9948 - val_loss: 10.7387 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 919/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.1657 - acc: 0.9978 - val_loss: 10.6943 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 920/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 22.1368 - acc: 0.9982 - val_loss: 10.6602 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 921/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 21.7494 - acc: 0.9982 - val_loss: 10.6534 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 922/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26.8894 - acc: 0.9963 - val_loss: 10.6257 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 923/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.4058 - acc: 0.9967 - val_loss: 10.6219 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 924/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.2380 - acc: 0.9970 - val_loss: 10.6246 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 925/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 20.4922 - acc: 0.9974 - val_loss: 10.6172 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 926/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 27.8762 - acc: 0.9963 - val_loss: 10.5959 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 927/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22.7343 - acc: 0.9974 - val_loss: 10.5676 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 928/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.7856 - acc: 0.9982 - val_loss: 10.5519 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 929/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.4979 - acc: 0.9985 - val_loss: 10.5340 - val_acc: 0.9985 - lr: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 25.1175 - acc: 0.9970 - val_loss: 10.5174 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 931/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 20.7288 - acc: 0.9985 - val_loss: 10.4912 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 932/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 29.0805 - acc: 0.9963 - val_loss: 10.4638 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 933/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 22.5506 - acc: 0.9978 - val_loss: 10.4136 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 934/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 24.2551 - acc: 0.9967 - val_loss: 10.3878 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 935/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 28.8714 - acc: 0.9967 - val_loss: 10.3507 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 936/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.4429 - acc: 0.9978 - val_loss: 10.3215 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 937/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 24.5303 - acc: 0.9978 - val_loss: 10.3174 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 938/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22.4199 - acc: 0.9978 - val_loss: 10.3654 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 939/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26.4582 - acc: 0.9967 - val_loss: 10.4242 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 940/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 29.6322 - acc: 0.9970 - val_loss: 10.4189 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 941/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.6524 - acc: 0.9978 - val_loss: 10.4262 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 942/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.1461 - acc: 0.9978 - val_loss: 10.4120 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 943/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26.6130 - acc: 0.9967 - val_loss: 10.3988 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 944/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.4050 - acc: 0.9978 - val_loss: 10.3796 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 945/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22.5085 - acc: 0.9970 - val_loss: 10.3544 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 946/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 21.4124 - acc: 0.9970 - val_loss: 10.3591 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 947/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 21.9930 - acc: 0.9978 - val_loss: 10.4011 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 948/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 22.9971 - acc: 0.9974 - val_loss: 10.4593 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 949/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 27.0183 - acc: 0.9970 - val_loss: 10.4854 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 950/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.1845 - acc: 0.9974 - val_loss: 10.4766 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 951/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.2682 - acc: 0.9970 - val_loss: 10.4640 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 952/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.7711 - acc: 0.9982 - val_loss: 10.4552 - val_acc: 0.9985 - lr: 0.0040\n",
      "Epoch 953/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.4784 - acc: 0.9970 - val_loss: 10.4418 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 954/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26.9504 - acc: 0.9967 - val_loss: 10.4164 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 955/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 24.2193 - acc: 0.9967 - val_loss: 10.4005 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 956/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 24.2484 - acc: 0.9967 - val_loss: 10.3777 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 957/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.0206 - acc: 0.9974 - val_loss: 10.3351 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 958/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 30.0488 - acc: 0.9967 - val_loss: 10.2445 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 959/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 19.3956 - acc: 0.9982 - val_loss: 10.1855 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 960/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.7574 - acc: 0.9978 - val_loss: 10.1331 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 961/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 18.8047 - acc: 0.9970 - val_loss: 10.1034 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 962/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 20.4429 - acc: 0.9978 - val_loss: 10.0710 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 963/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22.1002 - acc: 0.9974 - val_loss: 10.0541 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 964/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 24.0345 - acc: 0.9970 - val_loss: 10.0668 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 965/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 25.4848 - acc: 0.9970 - val_loss: 10.0780 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 966/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 20.7305 - acc: 0.9985 - val_loss: 10.0799 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 967/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 27.5165 - acc: 0.9970 - val_loss: 10.0629 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 968/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.6129 - acc: 0.9978 - val_loss: 10.0324 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 969/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22.7817 - acc: 0.9974 - val_loss: 10.0147 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 970/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 24.7581 - acc: 0.9970 - val_loss: 10.0273 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 971/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.2853 - acc: 0.9978 - val_loss: 10.0913 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 972/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.5824 - acc: 0.9974 - val_loss: 10.1821 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 973/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.1098 - acc: 0.9982 - val_loss: 10.2462 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 974/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.4787 - acc: 0.9970 - val_loss: 10.2912 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 975/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.7122 - acc: 0.9974 - val_loss: 10.3064 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 976/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 21.9194 - acc: 0.9982 - val_loss: 10.2039 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 977/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.9174 - acc: 0.9970 - val_loss: 10.1276 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 978/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.5775 - acc: 0.9978 - val_loss: 10.0317 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 979/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22.4245 - acc: 0.9970 - val_loss: 9.9263 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 980/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22.7800 - acc: 0.9974 - val_loss: 9.8656 - val_acc: 0.9989 - lr: 0.0036\n",
      "Epoch 981/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 25.7133 - acc: 0.9974 - val_loss: 9.8135 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 982/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22.7441 - acc: 0.9967 - val_loss: 9.7805 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 983/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 20.1437 - acc: 0.9978 - val_loss: 9.7803 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 984/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 20.1458 - acc: 0.9970 - val_loss: 9.7912 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 985/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step - loss: 23.5123 - acc: 0.9970 - val_loss: 9.7967 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 986/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.6101 - acc: 0.9970 - val_loss: 9.8085 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 987/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.0737 - acc: 0.9974 - val_loss: 9.8152 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 988/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 22.3845 - acc: 0.9978 - val_loss: 9.8040 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 989/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 25.5820 - acc: 0.9970 - val_loss: 9.7842 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 990/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.4963 - acc: 0.9978 - val_loss: 9.7766 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 991/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 22.0250 - acc: 0.9974 - val_loss: 9.8004 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 992/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 21.2953 - acc: 0.9978 - val_loss: 9.8169 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 993/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.8746 - acc: 0.9974 - val_loss: 9.8478 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 994/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.9660 - acc: 0.9985 - val_loss: 9.8658 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 995/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.8451 - acc: 0.9970 - val_loss: 9.8771 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 996/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.9116 - acc: 0.9978 - val_loss: 9.8713 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 997/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.8588 - acc: 0.9978 - val_loss: 9.8499 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 998/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22.0708 - acc: 0.9978 - val_loss: 9.8120 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 999/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 21.3536 - acc: 0.9982 - val_loss: 9.7526 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1000/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 21.1300 - acc: 0.9978 - val_loss: 9.6872 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1001/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 24.0729 - acc: 0.9967 - val_loss: 9.6078 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1002/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 18.2615 - acc: 0.9982 - val_loss: 9.5691 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1003/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 21.7894 - acc: 0.9978 - val_loss: 9.5488 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1004/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.2818 - acc: 0.9978 - val_loss: 9.5636 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1005/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.3966 - acc: 0.9974 - val_loss: 9.5834 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1006/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.2673 - acc: 0.9967 - val_loss: 9.5770 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1007/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 21.7997 - acc: 0.9974 - val_loss: 9.5594 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1008/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 18.0631 - acc: 0.9985 - val_loss: 9.5414 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1009/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.1295 - acc: 0.9978 - val_loss: 9.5206 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1010/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.9925 - acc: 0.9978 - val_loss: 9.5125 - val_acc: 0.9989 - lr: 0.0036\n",
      "Epoch 1011/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.6759 - acc: 0.9982 - val_loss: 9.5581 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1012/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.1709 - acc: 0.9978 - val_loss: 9.6316 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1013/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 22.4617 - acc: 0.9982 - val_loss: 9.6801 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1014/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 22.1955 - acc: 0.9978 - val_loss: 9.6528 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1015/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.3375 - acc: 0.9978 - val_loss: 9.6098 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1016/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 22.9699 - acc: 0.9967 - val_loss: 9.6184 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1017/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 20.9291 - acc: 0.9970 - val_loss: 9.5677 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1018/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22.3482 - acc: 0.9974 - val_loss: 9.5312 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1019/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 20.4568 - acc: 0.9974 - val_loss: 9.4333 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1020/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.6836 - acc: 0.9982 - val_loss: 9.3703 - val_acc: 0.9989 - lr: 0.0036\n",
      "Epoch 1021/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.2689 - acc: 0.9959 - val_loss: 9.2931 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1022/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 21.0680 - acc: 0.9978 - val_loss: 9.2434 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1023/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 25.4946 - acc: 0.9970 - val_loss: 9.2185 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1024/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.0421 - acc: 0.9974 - val_loss: 9.2066 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1025/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.1421 - acc: 0.9978 - val_loss: 9.2061 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1026/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 19.9608 - acc: 0.9974 - val_loss: 9.1944 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1027/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 20.0968 - acc: 0.9978 - val_loss: 9.1531 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1028/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22.6446 - acc: 0.9974 - val_loss: 9.1023 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1029/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.0470 - acc: 0.9974 - val_loss: 9.0829 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1030/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 20.4109 - acc: 0.9978 - val_loss: 9.0671 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1031/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 17.9407 - acc: 0.9982 - val_loss: 9.0813 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1032/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 22.6815 - acc: 0.9970 - val_loss: 9.1058 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1033/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 21.2230 - acc: 0.9967 - val_loss: 9.1487 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1034/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.1601 - acc: 0.9970 - val_loss: 9.2312 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1035/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26.8424 - acc: 0.9967 - val_loss: 9.2962 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1036/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.6057 - acc: 0.9963 - val_loss: 9.3254 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1037/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.9137 - acc: 0.9982 - val_loss: 9.3226 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1038/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.7709 - acc: 0.9978 - val_loss: 9.2800 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1039/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 21.9451 - acc: 0.9974 - val_loss: 9.2272 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1040/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step - loss: 21.4008 - acc: 0.9970 - val_loss: 9.1399 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1041/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 22.3939 - acc: 0.9974 - val_loss: 9.0143 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1042/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 21.2841 - acc: 0.9970 - val_loss: 8.9502 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1043/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.1027 - acc: 0.9982 - val_loss: 8.9299 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1044/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26.1088 - acc: 0.9970 - val_loss: 8.9523 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1045/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 18.9163 - acc: 0.9982 - val_loss: 8.9854 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1046/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.3837 - acc: 0.9967 - val_loss: 9.0222 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1047/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 21.3841 - acc: 0.9982 - val_loss: 9.0477 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1048/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.4212 - acc: 0.9978 - val_loss: 9.0345 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1049/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 21.7801 - acc: 0.9970 - val_loss: 9.0023 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1050/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 19.1063 - acc: 0.9985 - val_loss: 8.9529 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1051/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.4878 - acc: 0.9982 - val_loss: 8.9125 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1052/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.6382 - acc: 0.9978 - val_loss: 8.8850 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1053/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.4736 - acc: 0.9974 - val_loss: 8.8668 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1054/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 19.8988 - acc: 0.9978 - val_loss: 8.8708 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1055/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.4017 - acc: 0.9982 - val_loss: 8.8503 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1056/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.1638 - acc: 0.9978 - val_loss: 8.8271 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1057/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.9094 - acc: 0.9978 - val_loss: 8.8217 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1058/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.0364 - acc: 0.9974 - val_loss: 8.8438 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1059/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 21.5802 - acc: 0.9970 - val_loss: 8.8660 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1060/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.4059 - acc: 0.9982 - val_loss: 8.8583 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1061/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.7210 - acc: 0.9982 - val_loss: 8.8284 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1062/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22.8383 - acc: 0.9974 - val_loss: 8.7844 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1063/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 18.0519 - acc: 0.9982 - val_loss: 8.7429 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1064/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.5819 - acc: 0.9978 - val_loss: 8.7398 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1065/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.1455 - acc: 0.9978 - val_loss: 8.7671 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1066/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 21.0073 - acc: 0.9978 - val_loss: 8.8121 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1067/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14.3438 - acc: 0.9989 - val_loss: 8.8754 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1068/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.2256 - acc: 0.9978 - val_loss: 8.9612 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1069/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.2904 - acc: 0.9978 - val_loss: 9.0567 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1070/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 20.7072 - acc: 0.9974 - val_loss: 9.0955 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1071/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.3891 - acc: 0.9985 - val_loss: 9.0866 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1072/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.9478 - acc: 0.9978 - val_loss: 9.0557 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1073/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.3731 - acc: 0.9974 - val_loss: 8.9986 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1074/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.4934 - acc: 0.9974 - val_loss: 8.9212 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1075/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.8647 - acc: 0.9982 - val_loss: 8.8271 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1076/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.6477 - acc: 0.9982 - val_loss: 8.7305 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1077/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.0008 - acc: 0.9978 - val_loss: 8.6655 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1078/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 20.8708 - acc: 0.9967 - val_loss: 8.6269 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1079/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 19.0069 - acc: 0.9982 - val_loss: 8.6142 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1080/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.8323 - acc: 0.9982 - val_loss: 8.6205 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1081/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.9607 - acc: 0.9982 - val_loss: 8.6486 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1082/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.7137 - acc: 0.9967 - val_loss: 8.6780 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1083/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.6088 - acc: 0.9978 - val_loss: 8.7155 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1084/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 25.2228 - acc: 0.9974 - val_loss: 8.7557 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1085/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22.1499 - acc: 0.9967 - val_loss: 8.7521 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1086/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.6200 - acc: 0.9985 - val_loss: 8.7125 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1087/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 21.1333 - acc: 0.9974 - val_loss: 8.6934 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1088/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 19.1811 - acc: 0.9982 - val_loss: 8.6725 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1089/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.7162 - acc: 0.9989 - val_loss: 8.6332 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1090/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 19.0140 - acc: 0.9985 - val_loss: 8.6101 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1091/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 21.5747 - acc: 0.9959 - val_loss: 8.5879 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1092/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.9614 - acc: 0.9982 - val_loss: 8.5726 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1093/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 20.5964 - acc: 0.9974 - val_loss: 8.5932 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1094/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.2343 - acc: 0.9982 - val_loss: 8.6096 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1095/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 19.1335 - acc: 0.9970 - val_loss: 8.6023 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1096/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.6861 - acc: 0.9982 - val_loss: 8.5735 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1097/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 20.0569 - acc: 0.9978 - val_loss: 8.5317 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1098/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.5326 - acc: 0.9982 - val_loss: 8.4860 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1099/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.0080 - acc: 0.9982 - val_loss: 8.4295 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1100/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 21.0052 - acc: 0.9970 - val_loss: 8.4157 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1101/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.0358 - acc: 0.9974 - val_loss: 8.4280 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1102/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.6121 - acc: 0.9970 - val_loss: 8.4686 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1103/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.5149 - acc: 0.9982 - val_loss: 8.5019 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1104/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 19.7882 - acc: 0.9982 - val_loss: 8.5354 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1105/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 28.3173 - acc: 0.9967 - val_loss: 8.5431 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1106/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.1756 - acc: 0.9985 - val_loss: 8.5519 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1107/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.2221 - acc: 0.9985 - val_loss: 8.5501 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1108/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.7497 - acc: 0.9989 - val_loss: 8.5455 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1109/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 27.8532 - acc: 0.9967 - val_loss: 8.5173 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1110/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 14.0822 - acc: 0.9985 - val_loss: 8.4916 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1111/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 18.1216 - acc: 0.9982 - val_loss: 8.4730 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1112/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22.3498 - acc: 0.9970 - val_loss: 8.4543 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1113/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.9617 - acc: 0.9978 - val_loss: 8.4137 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1114/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 21.7881 - acc: 0.9970 - val_loss: 8.3705 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1115/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 24.1298 - acc: 0.9970 - val_loss: 8.3393 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1116/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.3314 - acc: 0.9978 - val_loss: 8.3071 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1117/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 19.6369 - acc: 0.9974 - val_loss: 8.3000 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1118/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.4574 - acc: 0.9982 - val_loss: 8.3011 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1119/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.0095 - acc: 0.9970 - val_loss: 8.3083 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1120/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22.0355 - acc: 0.9978 - val_loss: 8.3230 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1121/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 29.1861 - acc: 0.9970 - val_loss: 8.3431 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1122/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.3644 - acc: 0.9978 - val_loss: 8.3586 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1123/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 20.7951 - acc: 0.9970 - val_loss: 8.3855 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1124/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.5078 - acc: 0.9974 - val_loss: 8.4135 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1125/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.9336 - acc: 0.9985 - val_loss: 8.4249 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1126/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.8024 - acc: 0.9982 - val_loss: 8.4191 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1127/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 22.6468 - acc: 0.9967 - val_loss: 8.4145 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1128/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22.3203 - acc: 0.9967 - val_loss: 8.4184 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1129/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.3221 - acc: 0.9974 - val_loss: 8.4190 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1130/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.1868 - acc: 0.9985 - val_loss: 8.4287 - val_acc: 0.9989 - lr: 0.0036\n",
      "Epoch 1131/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 17.1916 - acc: 0.9982 - val_loss: 8.4233 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1132/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 17.9289 - acc: 0.9974 - val_loss: 8.3488 - val_acc: 0.9985 - lr: 0.0036\n",
      "Epoch 1133/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.6217 - acc: 0.9982 - val_loss: 8.2717 - val_acc: 0.9989 - lr: 0.0033\n",
      "Epoch 1134/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 15.3415 - acc: 0.9982 - val_loss: 8.2140 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1135/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 18.2867 - acc: 0.9978 - val_loss: 8.1779 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1136/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 19.9095 - acc: 0.9978 - val_loss: 8.1431 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1137/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.8483 - acc: 0.9978 - val_loss: 8.1256 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1138/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 17.2993 - acc: 0.9985 - val_loss: 8.1249 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1139/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.5590 - acc: 0.9967 - val_loss: 8.1414 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1140/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 14.6145 - acc: 0.9985 - val_loss: 8.1664 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1141/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3579 - acc: 0.9982 - val_loss: 8.1956 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1142/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.5853 - acc: 0.9978 - val_loss: 8.2090 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1143/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 19.6340 - acc: 0.9978 - val_loss: 8.2213 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1144/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 17.0759 - acc: 0.9970 - val_loss: 8.2372 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1145/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.6499 - acc: 0.9978 - val_loss: 8.2301 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1146/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.9408 - acc: 0.9974 - val_loss: 8.1976 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1147/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 17.9170 - acc: 0.9978 - val_loss: 8.1529 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1148/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.7880 - acc: 0.9978 - val_loss: 8.0948 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1149/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 19.6594 - acc: 0.9974 - val_loss: 8.0643 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1150/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 17.0802 - acc: 0.9985 - val_loss: 8.0593 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1151/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.8797 - acc: 0.9978 - val_loss: 8.0747 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1152/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.5846 - acc: 0.9985 - val_loss: 8.0965 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1153/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 18.4319 - acc: 0.9974 - val_loss: 8.1231 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1154/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.2450 - acc: 0.9970 - val_loss: 8.1334 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1155/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.5626 - acc: 0.9982 - val_loss: 8.1420 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1156/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.4183 - acc: 0.9978 - val_loss: 8.1684 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1157/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.6033 - acc: 0.9978 - val_loss: 8.1839 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1158/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.0231 - acc: 0.9978 - val_loss: 8.2037 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1159/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 20.3671 - acc: 0.9970 - val_loss: 8.1737 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1160/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 14.4114 - acc: 0.9985 - val_loss: 8.1591 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1161/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 22.5997 - acc: 0.9970 - val_loss: 8.1326 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1162/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 21.7623 - acc: 0.9967 - val_loss: 8.1198 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1163/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.1957 - acc: 0.9978 - val_loss: 8.1112 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1164/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14.6271 - acc: 0.9985 - val_loss: 8.1143 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1165/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 24.5377 - acc: 0.9982 - val_loss: 8.1217 - val_acc: 0.9985 - lr: 0.0033\n",
      "Epoch 1166/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 15.4133 - acc: 0.9982 - val_loss: 8.1372 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1167/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.0245 - acc: 0.9985 - val_loss: 8.1407 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1168/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.1017 - acc: 0.9982 - val_loss: 8.1436 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1169/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.8006 - acc: 0.9982 - val_loss: 8.1453 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1170/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 19.1190 - acc: 0.9970 - val_loss: 8.1186 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1171/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4499 - acc: 0.9982 - val_loss: 8.0854 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1172/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3465 - acc: 0.9985 - val_loss: 8.0332 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1173/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 17.5671 - acc: 0.9978 - val_loss: 7.9935 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1174/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.1895 - acc: 0.9985 - val_loss: 7.9726 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1175/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 14.7005 - acc: 0.9978 - val_loss: 7.9683 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1176/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4506 - acc: 0.9982 - val_loss: 7.9650 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1177/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.4905 - acc: 0.9978 - val_loss: 7.9536 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1178/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 15.7455 - acc: 0.9982 - val_loss: 7.9472 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1179/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.1123 - acc: 0.9974 - val_loss: 7.9491 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1180/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 20.9858 - acc: 0.9970 - val_loss: 7.9441 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1181/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.7738 - acc: 0.9985 - val_loss: 7.9444 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1182/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.8231 - acc: 0.9978 - val_loss: 7.9341 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1183/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 15.7504 - acc: 0.9982 - val_loss: 7.9099 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1184/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.7988 - acc: 0.9982 - val_loss: 7.8939 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1185/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.8317 - acc: 0.9978 - val_loss: 7.8782 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1186/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.8108 - acc: 0.9974 - val_loss: 7.8690 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1187/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 15.1343 - acc: 0.9982 - val_loss: 7.8912 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1188/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.7850 - acc: 0.9978 - val_loss: 7.9444 - val_acc: 0.9989 - lr: 0.0030\n",
      "Epoch 1189/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15.4449 - acc: 0.9978 - val_loss: 7.9887 - val_acc: 0.9989 - lr: 0.0030\n",
      "Epoch 1190/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.5135 - acc: 0.9974 - val_loss: 8.0157 - val_acc: 0.9989 - lr: 0.0030\n",
      "Epoch 1191/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.5909 - acc: 0.9985 - val_loss: 8.0331 - val_acc: 0.9989 - lr: 0.0030\n",
      "Epoch 1192/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 14.8123 - acc: 0.9985 - val_loss: 8.0216 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1193/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 18.7927 - acc: 0.9982 - val_loss: 8.0087 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1194/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 15.1255 - acc: 0.9985 - val_loss: 7.9717 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1195/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.1618 - acc: 0.9974 - val_loss: 7.9445 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1196/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 13.7266 - acc: 0.9985 - val_loss: 7.9312 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1197/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.1867 - acc: 0.9982 - val_loss: 7.9451 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1198/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.8349 - acc: 0.9970 - val_loss: 7.9694 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1199/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 13.4335 - acc: 0.9989 - val_loss: 8.0137 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1200/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.6966 - acc: 0.9967 - val_loss: 8.0498 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1201/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 19.1611 - acc: 0.9982 - val_loss: 8.0909 - val_acc: 0.9985 - lr: 0.0030\n",
      "Epoch 1202/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 20.2495 - acc: 0.9970 - val_loss: 8.1091 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1203/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.6761 - acc: 0.9985 - val_loss: 8.1414 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1204/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.0845 - acc: 0.9978 - val_loss: 8.1562 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1205/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 15.5563 - acc: 0.9982 - val_loss: 8.1910 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1206/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.4278 - acc: 0.9985 - val_loss: 8.2058 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1207/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 18.6705 - acc: 0.9982 - val_loss: 8.1882 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1208/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.7081 - acc: 0.9974 - val_loss: 8.1707 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1209/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.7707 - acc: 0.9982 - val_loss: 8.1292 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1210/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.7481 - acc: 0.9978 - val_loss: 8.0741 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1211/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.7156 - acc: 0.9978 - val_loss: 7.9931 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1212/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.0704 - acc: 0.9982 - val_loss: 7.9162 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1213/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.1087 - acc: 0.9978 - val_loss: 7.8554 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1214/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.6086 - acc: 0.9985 - val_loss: 7.8091 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1215/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 12.9591 - acc: 0.9985 - val_loss: 7.7822 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1216/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.0226 - acc: 0.9978 - val_loss: 7.7713 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1217/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.8483 - acc: 0.9993 - val_loss: 7.7660 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1218/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.4759 - acc: 0.9982 - val_loss: 7.7705 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1219/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.9836 - acc: 0.9974 - val_loss: 7.7843 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1220/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.8217 - acc: 0.9985 - val_loss: 7.8102 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1221/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.2729 - acc: 0.9970 - val_loss: 7.8201 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1222/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14.1028 - acc: 0.9985 - val_loss: 7.8116 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1223/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.8199 - acc: 0.9978 - val_loss: 7.8035 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1224/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.7119 - acc: 0.9985 - val_loss: 7.7856 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1225/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.2669 - acc: 0.9985 - val_loss: 7.7783 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1226/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.5876 - acc: 0.9982 - val_loss: 7.7747 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1227/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.4163 - acc: 0.9985 - val_loss: 7.7629 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1228/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 17.0707 - acc: 0.9982 - val_loss: 7.7645 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1229/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.0264 - acc: 0.9982 - val_loss: 7.7724 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1230/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.7659 - acc: 0.9978 - val_loss: 7.7736 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1231/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.8297 - acc: 0.9974 - val_loss: 7.7603 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1232/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 21.1961 - acc: 0.9974 - val_loss: 7.7555 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1233/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.3869 - acc: 0.9978 - val_loss: 7.7603 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1234/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.3858 - acc: 0.9978 - val_loss: 7.7614 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1235/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 19.1357 - acc: 0.9978 - val_loss: 7.7504 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1236/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14.9647 - acc: 0.9982 - val_loss: 7.7362 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1237/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 15.1464 - acc: 0.9982 - val_loss: 7.7227 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1238/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.1044 - acc: 0.9985 - val_loss: 7.7124 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1239/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.8921 - acc: 0.9985 - val_loss: 7.6912 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1240/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.8188 - acc: 0.9974 - val_loss: 7.6769 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1241/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.6575 - acc: 0.9974 - val_loss: 7.6672 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1242/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15.1677 - acc: 0.9985 - val_loss: 7.6669 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1243/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 15.9200 - acc: 0.9985 - val_loss: 7.6548 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1244/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 19.2969 - acc: 0.9978 - val_loss: 7.6358 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1245/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 13.9355 - acc: 0.9985 - val_loss: 7.6282 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1246/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.4938 - acc: 0.9967 - val_loss: 7.6216 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1247/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 12.9439 - acc: 0.9978 - val_loss: 7.6175 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1248/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.8123 - acc: 0.9982 - val_loss: 7.6117 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1249/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 14.6575 - acc: 0.9978 - val_loss: 7.6072 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1250/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.0919 - acc: 0.9982 - val_loss: 7.6098 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1251/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.8698 - acc: 0.9974 - val_loss: 7.6067 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1252/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.3259 - acc: 0.9974 - val_loss: 7.5991 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1253/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.8815 - acc: 0.9974 - val_loss: 7.5946 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1254/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.1504 - acc: 0.9978 - val_loss: 7.5995 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1255/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.6802 - acc: 0.9982 - val_loss: 7.6072 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1256/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15.8416 - acc: 0.9982 - val_loss: 7.6045 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1257/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 18.3020 - acc: 0.9974 - val_loss: 7.6128 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1258/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.7880 - acc: 0.9978 - val_loss: 7.6228 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1259/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 12.8233 - acc: 0.9982 - val_loss: 7.6197 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1260/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 16.7977 - acc: 0.9978 - val_loss: 7.6056 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1261/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.7906 - acc: 0.9978 - val_loss: 7.5816 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1262/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 17.8332 - acc: 0.9974 - val_loss: 7.5744 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1263/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.3358 - acc: 0.9982 - val_loss: 7.5805 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1264/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3247 - acc: 0.9978 - val_loss: 7.5893 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1265/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.2967 - acc: 0.9974 - val_loss: 7.5977 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1266/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.0062 - acc: 0.9978 - val_loss: 7.6114 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1267/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 20.4809 - acc: 0.9967 - val_loss: 7.6170 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1268/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 19.6177 - acc: 0.9967 - val_loss: 7.6301 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1269/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.7513 - acc: 0.9978 - val_loss: 7.6228 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1270/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.3238 - acc: 0.9985 - val_loss: 7.6194 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1271/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 12.3093 - acc: 0.9985 - val_loss: 7.6222 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1272/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.5351 - acc: 0.9982 - val_loss: 7.6160 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1273/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.0234 - acc: 0.9989 - val_loss: 7.6002 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1274/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.8381 - acc: 0.9974 - val_loss: 7.5774 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1275/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.7322 - acc: 0.9982 - val_loss: 7.5584 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1276/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 18.5279 - acc: 0.9970 - val_loss: 7.5503 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1277/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.8068 - acc: 0.9978 - val_loss: 7.5450 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1278/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.8594 - acc: 0.9982 - val_loss: 7.5608 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1279/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 19.3975 - acc: 0.9963 - val_loss: 7.5898 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1280/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.0425 - acc: 0.9978 - val_loss: 7.6109 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1281/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14.8221 - acc: 0.9982 - val_loss: 7.6078 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1282/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 20.2250 - acc: 0.9970 - val_loss: 7.5868 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1283/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.1762 - acc: 0.9974 - val_loss: 7.5822 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1284/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.1001 - acc: 0.9970 - val_loss: 7.5586 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1285/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.6040 - acc: 0.9985 - val_loss: 7.5361 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1286/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.0545 - acc: 0.9985 - val_loss: 7.5345 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1287/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15.4723 - acc: 0.9985 - val_loss: 7.5338 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1288/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 20.6910 - acc: 0.9974 - val_loss: 7.5351 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1289/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.3858 - acc: 0.9982 - val_loss: 7.5341 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1290/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 18.3202 - acc: 0.9967 - val_loss: 7.5462 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1291/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.0762 - acc: 0.9982 - val_loss: 7.5479 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1292/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.2803 - acc: 0.9985 - val_loss: 7.5407 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1293/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.1462 - acc: 0.9982 - val_loss: 7.5473 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1294/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 13.1333 - acc: 0.9985 - val_loss: 7.5488 - val_acc: 0.9989 - lr: 0.0027\n",
      "Epoch 1295/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12.5940 - acc: 0.9985 - val_loss: 7.5517 - val_acc: 0.9989 - lr: 0.0027\n",
      "Epoch 1296/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.0268 - acc: 0.9985 - val_loss: 7.5362 - val_acc: 0.9989 - lr: 0.0027\n",
      "Epoch 1297/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.0962 - acc: 0.9978 - val_loss: 7.5177 - val_acc: 0.9989 - lr: 0.0027\n",
      "Epoch 1298/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 18.8111 - acc: 0.9978 - val_loss: 7.5169 - val_acc: 0.9989 - lr: 0.0027\n",
      "Epoch 1299/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 15.9441 - acc: 0.9978 - val_loss: 7.5054 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1300/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.2118 - acc: 0.9982 - val_loss: 7.4694 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1301/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.0898 - acc: 0.9985 - val_loss: 7.4425 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1302/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.0602 - acc: 0.9989 - val_loss: 7.4428 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1303/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.8113 - acc: 0.9985 - val_loss: 7.4584 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1304/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14.4247 - acc: 0.9985 - val_loss: 7.4934 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1305/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.5088 - acc: 0.9978 - val_loss: 7.5505 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1306/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.5978 - acc: 0.9978 - val_loss: 7.6173 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1307/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.1976 - acc: 0.9985 - val_loss: 7.6931 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1308/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.5567 - acc: 0.9982 - val_loss: 7.7331 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1309/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.5317 - acc: 0.9970 - val_loss: 7.7514 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1310/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14.9645 - acc: 0.9974 - val_loss: 7.7552 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1311/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 17.6526 - acc: 0.9982 - val_loss: 7.7692 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1312/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.4996 - acc: 0.9978 - val_loss: 7.7732 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1313/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.5144 - acc: 0.9982 - val_loss: 7.7284 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1314/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 19.5941 - acc: 0.9974 - val_loss: 7.6610 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1315/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 15.6393 - acc: 0.9982 - val_loss: 7.5947 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1316/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.0484 - acc: 0.9982 - val_loss: 7.5374 - val_acc: 0.9985 - lr: 0.0027\n",
      "Epoch 1317/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 19.5307 - acc: 0.9978 - val_loss: 7.5061 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1318/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.2923 - acc: 0.9985 - val_loss: 7.4964 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1319/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.3393 - acc: 0.9978 - val_loss: 7.4937 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1320/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.2160 - acc: 0.9978 - val_loss: 7.4814 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1321/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.9486 - acc: 0.9982 - val_loss: 7.4724 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1322/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.5774 - acc: 0.9974 - val_loss: 7.4591 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1323/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.3110 - acc: 0.9982 - val_loss: 7.4481 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1324/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.1818 - acc: 0.9989 - val_loss: 7.4343 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1325/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14.8889 - acc: 0.9982 - val_loss: 7.4239 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1326/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.6091 - acc: 0.9982 - val_loss: 7.4213 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1327/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.6040 - acc: 0.9978 - val_loss: 7.4199 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1328/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.6461 - acc: 0.9978 - val_loss: 7.4292 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1329/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.8386 - acc: 0.9982 - val_loss: 7.4400 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1330/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.3481 - acc: 0.9978 - val_loss: 7.4511 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1331/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.5161 - acc: 0.9978 - val_loss: 7.4495 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1332/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 18.8716 - acc: 0.9974 - val_loss: 7.4508 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1333/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.1801 - acc: 0.9982 - val_loss: 7.4533 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1334/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.5056 - acc: 0.9982 - val_loss: 7.4517 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1335/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 14.0801 - acc: 0.9985 - val_loss: 7.4386 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1336/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.4589 - acc: 0.9982 - val_loss: 7.4071 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1337/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.0285 - acc: 0.9985 - val_loss: 7.3781 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1338/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.2631 - acc: 0.9982 - val_loss: 7.3609 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1339/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.3247 - acc: 0.9974 - val_loss: 7.3547 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1340/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.1663 - acc: 0.9974 - val_loss: 7.3575 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1341/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.3650 - acc: 0.9982 - val_loss: 7.3575 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1342/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.6372 - acc: 0.9982 - val_loss: 7.3508 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1343/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.2942 - acc: 0.9978 - val_loss: 7.3476 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1344/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.9994 - acc: 0.9978 - val_loss: 7.3259 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1345/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.8974 - acc: 0.9985 - val_loss: 7.3006 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1346/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.1895 - acc: 0.9982 - val_loss: 7.2719 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1347/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 17.2189 - acc: 0.9978 - val_loss: 7.2478 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1348/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.6521 - acc: 0.9974 - val_loss: 7.2292 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1349/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 13.3013 - acc: 0.9985 - val_loss: 7.2152 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1350/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.8137 - acc: 0.9982 - val_loss: 7.2066 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1351/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.3727 - acc: 0.9985 - val_loss: 7.1994 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1352/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.0745 - acc: 0.9970 - val_loss: 7.1976 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1353/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.8762 - acc: 0.9982 - val_loss: 7.2182 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1354/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.9334 - acc: 0.9970 - val_loss: 7.2605 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1355/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 12.8167 - acc: 0.9985 - val_loss: 7.3036 - val_acc: 0.9989 - lr: 0.0024\n",
      "Epoch 1356/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.0488 - acc: 0.9982 - val_loss: 7.3356 - val_acc: 0.9989 - lr: 0.0024\n",
      "Epoch 1357/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14.4155 - acc: 0.9978 - val_loss: 7.3514 - val_acc: 0.9989 - lr: 0.0024\n",
      "Epoch 1358/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.3834 - acc: 0.9978 - val_loss: 7.3561 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1359/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.2787 - acc: 0.9974 - val_loss: 7.3633 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1360/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14.2660 - acc: 0.9974 - val_loss: 7.3789 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1361/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.1195 - acc: 0.9974 - val_loss: 7.3879 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1362/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14.1170 - acc: 0.9985 - val_loss: 7.4131 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1363/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.1471 - acc: 0.9985 - val_loss: 7.4260 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1364/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.6181 - acc: 0.9985 - val_loss: 7.4151 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1365/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.7762 - acc: 0.9978 - val_loss: 7.3992 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1366/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 17.1207 - acc: 0.9974 - val_loss: 7.3585 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1367/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 20.3622 - acc: 0.9974 - val_loss: 7.3035 - val_acc: 0.9985 - lr: 0.0024\n",
      "Epoch 1368/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14.5311 - acc: 0.9978 - val_loss: 7.2601 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1369/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 18.6065 - acc: 0.9974 - val_loss: 7.2106 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1370/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 13.7925 - acc: 0.9982 - val_loss: 7.1749 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1371/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.5129 - acc: 0.9982 - val_loss: 7.1500 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1372/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 14.1737 - acc: 0.9982 - val_loss: 7.1353 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1373/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15.0827 - acc: 0.9978 - val_loss: 7.1277 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1374/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.7722 - acc: 0.9978 - val_loss: 7.1314 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1375/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.4644 - acc: 0.9978 - val_loss: 7.1402 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1376/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.6421 - acc: 0.9989 - val_loss: 7.1485 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1377/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.9992 - acc: 0.9970 - val_loss: 7.1589 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1378/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 19.1321 - acc: 0.9967 - val_loss: 7.1682 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1379/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.1502 - acc: 0.9985 - val_loss: 7.1769 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1380/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.3110 - acc: 0.9982 - val_loss: 7.1850 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1381/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14.2443 - acc: 0.9978 - val_loss: 7.1998 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1382/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.5156 - acc: 0.9978 - val_loss: 7.2035 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1383/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.2237 - acc: 0.9978 - val_loss: 7.1973 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1384/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 13.5737 - acc: 0.9982 - val_loss: 7.1864 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1385/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.7865 - acc: 0.9974 - val_loss: 7.1746 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1386/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.6698 - acc: 0.9978 - val_loss: 7.1632 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1387/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.5476 - acc: 0.9982 - val_loss: 7.1650 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1388/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.4796 - acc: 0.9978 - val_loss: 7.1737 - val_acc: 0.9985 - lr: 0.0022\n",
      "Epoch 1389/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.3810 - acc: 0.9978 - val_loss: 7.1867 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1390/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 13.7885 - acc: 0.9982 - val_loss: 7.2030 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1391/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.0438 - acc: 0.9985 - val_loss: 7.2348 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1392/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.7170 - acc: 0.9978 - val_loss: 7.2591 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1393/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14.8017 - acc: 0.9982 - val_loss: 7.2636 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1394/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 12.9828 - acc: 0.9985 - val_loss: 7.2614 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1395/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12.9064 - acc: 0.9978 - val_loss: 7.2569 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1396/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 12.9679 - acc: 0.9978 - val_loss: 7.2374 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1397/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 12.8658 - acc: 0.9985 - val_loss: 7.2092 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1398/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.5590 - acc: 0.9974 - val_loss: 7.1940 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1399/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14.9839 - acc: 0.9982 - val_loss: 7.1656 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1400/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 20.2988 - acc: 0.9974 - val_loss: 7.1401 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1401/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 14.5344 - acc: 0.9982 - val_loss: 7.1201 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1402/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14.9275 - acc: 0.9982 - val_loss: 7.1090 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1403/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14.1038 - acc: 0.9985 - val_loss: 7.0993 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1404/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14.4086 - acc: 0.9978 - val_loss: 7.0886 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1405/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.5811 - acc: 0.9985 - val_loss: 7.0848 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1406/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.1632 - acc: 0.9985 - val_loss: 7.0756 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1407/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.9842 - acc: 0.9974 - val_loss: 7.0672 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1408/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.8238 - acc: 0.9982 - val_loss: 7.0523 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1409/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.5304 - acc: 0.9985 - val_loss: 7.0330 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1410/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.0240 - acc: 0.9985 - val_loss: 7.0187 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1411/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.2354 - acc: 0.9985 - val_loss: 6.9995 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1412/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.3782 - acc: 0.9985 - val_loss: 6.9830 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1413/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 13.7556 - acc: 0.9982 - val_loss: 6.9694 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1414/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.7196 - acc: 0.9974 - val_loss: 6.9696 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1415/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 13.5656 - acc: 0.9978 - val_loss: 6.9731 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1416/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14.8042 - acc: 0.9978 - val_loss: 6.9803 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1417/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.1393 - acc: 0.9982 - val_loss: 6.9848 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1418/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 13.2321 - acc: 0.9985 - val_loss: 6.9906 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1419/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.1048 - acc: 0.9982 - val_loss: 6.9962 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1420/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.2042 - acc: 0.9985 - val_loss: 7.0051 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1421/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.1701 - acc: 0.9978 - val_loss: 7.0008 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1422/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 13.1771 - acc: 0.9982 - val_loss: 6.9854 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1423/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.6314 - acc: 0.9978 - val_loss: 6.9711 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1424/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14.2210 - acc: 0.9985 - val_loss: 6.9588 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1425/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 17.9780 - acc: 0.9974 - val_loss: 6.9542 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1426/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.4843 - acc: 0.9982 - val_loss: 6.9490 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1427/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.2008 - acc: 0.9978 - val_loss: 6.9432 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1428/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.3121 - acc: 0.9978 - val_loss: 6.9424 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1429/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 12.5467 - acc: 0.9985 - val_loss: 6.9477 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1430/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.0863 - acc: 0.9982 - val_loss: 6.9570 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1431/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12.1856 - acc: 0.9985 - val_loss: 6.9659 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1432/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.1065 - acc: 0.9985 - val_loss: 6.9723 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1433/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 14.0163 - acc: 0.9982 - val_loss: 6.9800 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1434/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 19.2902 - acc: 0.9970 - val_loss: 6.9905 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1435/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.5511 - acc: 0.9982 - val_loss: 7.0087 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1436/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 12.3587 - acc: 0.9985 - val_loss: 7.0349 - val_acc: 0.9985 - lr: 0.0019\n",
      "Epoch 1437/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14.1215 - acc: 0.9982 - val_loss: 7.0670 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1438/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11.9059 - acc: 0.9989 - val_loss: 7.0975 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1439/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 13.7397 - acc: 0.9978 - val_loss: 7.1197 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1440/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14.7016 - acc: 0.9985 - val_loss: 7.1328 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1441/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.8822 - acc: 0.9982 - val_loss: 7.1510 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1442/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.2632 - acc: 0.9989 - val_loss: 7.1526 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1443/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.6265 - acc: 0.9985 - val_loss: 7.1667 - val_acc: 0.9989 - lr: 0.0019\n",
      "Epoch 1444/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15.9754 - acc: 0.9978 - val_loss: 7.1657 - val_acc: 0.9989 - lr: 0.0017\n",
      "Epoch 1445/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.9592 - acc: 0.9974 - val_loss: 7.1586 - val_acc: 0.9989 - lr: 0.0017\n",
      "Epoch 1446/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3032 - acc: 0.9970 - val_loss: 7.1394 - val_acc: 0.9989 - lr: 0.0017\n",
      "Epoch 1447/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4097 - acc: 0.9974 - val_loss: 7.1160 - val_acc: 0.9989 - lr: 0.0017\n",
      "Epoch 1448/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.2287 - acc: 0.9978 - val_loss: 7.1080 - val_acc: 0.9989 - lr: 0.0017\n",
      "Epoch 1449/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.8148 - acc: 0.9978 - val_loss: 7.1102 - val_acc: 0.9989 - lr: 0.0017\n",
      "Epoch 1450/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 13.9968 - acc: 0.9978 - val_loss: 7.1221 - val_acc: 0.9989 - lr: 0.0017\n",
      "Epoch 1451/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.1853 - acc: 0.9974 - val_loss: 7.1407 - val_acc: 0.9985 - lr: 0.0017\n",
      "Epoch 1452/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3291 - acc: 0.9978 - val_loss: 7.1627 - val_acc: 0.9985 - lr: 0.0017\n",
      "Epoch 1453/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12.9329 - acc: 0.9985 - val_loss: 7.1759 - val_acc: 0.9985 - lr: 0.0017\n",
      "Epoch 1454/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 14.0393 - acc: 0.9982 - val_loss: 7.1857 - val_acc: 0.9985 - lr: 0.0017\n",
      "Epoch 1455/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 18.2086 - acc: 0.9982 - val_loss: 7.1914 - val_acc: 0.9985 - lr: 0.0017\n",
      "Epoch 1456/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.8225 - acc: 0.9985 - val_loss: 7.1804 - val_acc: 0.9985 - lr: 0.0017\n",
      "Epoch 1457/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.8967 - acc: 0.9985 - val_loss: 7.1733 - val_acc: 0.9985 - lr: 0.0017\n",
      "Epoch 1458/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 13.2178 - acc: 0.9978 - val_loss: 7.1717 - val_acc: 0.9985 - lr: 0.0017\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=PATIENCE//2, min_lr=5e-6, factor=.9)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_va.load(),\n",
    "    validation_steps=loader_va.steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4367816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Train', lw=2)\n",
    "plt.plot(history.history['val_loss'], label='Val', lw=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22c511",
   "metadata": {},
   "source": [
    "### 1.5 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e29f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model.\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5849 - acc: 0.9982\n",
      "Done.\n",
      "Test loss: 9.584897994995117\n",
      "Test accuracy: 0.9981536269187927\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(\"Evaluating model.\")\n",
    "loader_te = SingleLoader(dataset)\n",
    "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90d3b6",
   "metadata": {},
   "source": [
    "#### Exercise 1.4.1\n",
    "\n",
    "Add one more hidden GAT layer, build, compile, train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ec539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "in_x = keras.Input(shape=(dataset[0].x.shape[1],))\n",
    "in_a = keras.Input(shape=(dataset[0].a.shape[0],), sparse=True)\n",
    "\n",
    "# Add dropout on features (but not adjacency matrix)\n",
    "dropout_1 = keras.layers.Dropout(.1)(in_x)\n",
    "\n",
    "# Add GAT layer\n",
    "gat_layer_1 = spktrl.layers.GATConv(\n",
    "    channels=16,\n",
    "    attn_heads=8,\n",
    "    concat_heads=True,\n",
    "    dropout_rate=.05,\n",
    "    activation='selu',\n",
    "    kernel_initializer='lecun_normal'\n",
    ")([dropout_1, in_a])\n",
    "\n",
    "# Add dropout\n",
    "dropout_2 = keras.layers.Dropout(.1)(gat_layer_1)\n",
    "\n",
    "\n",
    "\n",
    "######## YOUR CODE STARTS HERE ########\n",
    "\n",
    "# Add another GAT layer\n",
    "gat_layer_2 = ...\n",
    "\n",
    "# Add another dropout layer\n",
    "dropout_3 = ...\n",
    "\n",
    "######## YOUR CODE ENDS HERE ########\n",
    "\n",
    "\n",
    "# Final GAT layer\n",
    "gat_out = spktrl.layers.GATConv(\n",
    "    channels=dataset[0].n_labels,\n",
    "    attn_heads=8,\n",
    "    concat_heads=False,\n",
    "    dropout_rate=.05,\n",
    "    activation='softmax'\n",
    ")([dropout_3, in_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enclose the layers in the model\n",
    "model = keras.Model(inputs=[in_x, in_a], outputs=gat_out)\n",
    "\n",
    "# Set some params\n",
    "LR = 5e-3 # 5e-3  # Learning rate\n",
    "EPOCHS = 10000  # Number of training epochs\n",
    "PATIENCE = 30  # Patience for early stopping\n",
    "\n",
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(lr=LR)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.CategoricalCrossentropy(reduction='sum'),\n",
    "    weighted_metrics=['acc'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc49a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=PATIENCE//2, min_lr=5e-6, factor=.9)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "######## YOUR CODE STARTS HERE ########\n",
    "history = model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_va.load(),\n",
    "    validation_steps=...,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=...\n",
    ")\n",
    "######## YOUR CODE ENDS HERE ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train', lw=2)\n",
    "plt.plot(history.history['val_loss'], label='Val', lw=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47217a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print(\"Evaluating model.\")\n",
    "loader_te = SingleLoader(dataset)\n",
    "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce3473",
   "metadata": {},
   "source": [
    "## 2. Graph classification with model sub-classing API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e09359",
   "metadata": {},
   "source": [
    "We'll use **Proteins** dataset, a part of [TU Datasets](https://chrsmrrs.github.io/datasets/).\n",
    "\n",
    "Proteins dataset is stored in a **disjoint** format.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/disjoint.png\" width=400>\n",
    "\n",
    "\n",
    "We'll need not only adjacency matrix and feature matrix, but also index matrix to identify which nodes belong to which batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe3ec90",
   "metadata": {},
   "source": [
    "### 2.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f03b6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded PROTEINS.\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(\"PROTEINS\", clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7076559",
   "metadata": {},
   "source": [
    "#### Exercise 2.1.1\n",
    "\n",
    "Check how many nodes are in the 8th graph of **Proteins** dataset.\n",
    "\n",
    "How many are there in 172nd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b652b457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=19, n_node_features=4, n_edge_features=None, n_labels=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "dataset[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10022eed",
   "metadata": {},
   "source": [
    "### 2.2 Split + dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae672425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / test split\n",
    "idxs = np.random.permutation(len(dataset))  # Random split\n",
    "split = int(0.9 * len(dataset))\n",
    "idx_tr, idx_te = np.split(idxs, [split])\n",
    "\n",
    "# Get train and test datsets\n",
    "dataset_tr, dataset_te = dataset[idx_tr], dataset[idx_te]\n",
    "\n",
    "# Get loaders \n",
    "loader_tr = DisjointLoader(dataset_tr, batch_size=32, epochs=10)\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e79139",
   "metadata": {},
   "source": [
    "### 2.3 Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02c709a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(keras.models.Model):\n",
    "    \n",
    "    def __init__(self, channels, n_layers, dropout_rate=.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = spktrl.layers.GCNConv(channels)\n",
    "        self.convs = []\n",
    "        \n",
    "        for _ in range(1, n_layers):\n",
    "            self.convs.append(\n",
    "                spktrl.layers.GCNConv(channels)\n",
    "            )\n",
    "        self.pool = spktrl.layers.GlobalAvgPool()\n",
    "        self.dense1 = keras.layers.Dense(channels, activation='relu')\n",
    "        self.dropout = keras.layers.Dropout(dropout_rate)\n",
    "        self.dense2 = keras.layers.Dense(dataset.n_labels, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a, i = inputs\n",
    "        x = self.conv1([x, a])\n",
    "        for conv in self.convs:\n",
    "            x = conv([x, a])\n",
    "        x = self.pool([x, i])\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80546ca3",
   "metadata": {},
   "source": [
    "### 2.3 Compile, train & evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a9ec3f",
   "metadata": {},
   "source": [
    "#### 2.3.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a18eceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some params\n",
    "LR = 5e-3 # 5e-3  # Learning rate\n",
    "EPOCHS = 10  # Number of training epochs\n",
    "PATIENCE = 30  # Patience for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "774074c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = GCN(\n",
    "    channels=16,\n",
    "    dropout_rate=.1,\n",
    "    n_layers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00e2994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = keras.optimizers.RMSprop(LR)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.CategoricalCrossentropy(reduction='sum'),\n",
    "    weighted_metrics=['acc'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48612ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 7/28 [======>.......................] - ETA: 0s - loss: 258.7665 - acc: 0.4866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\envs\\tf-spektral-minimal\\lib\\site-packages\\spektral\\data\\utils.py:213: UserWarning: you are shuffling a 'TUDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 22ms/step - loss: 123.7635 - acc: 0.5576 - val_loss: 23.7878 - val_acc: 0.3367\n",
      "Epoch 2/10\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 25.7452 - acc: 0.6202WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 25.2934 - acc: 0.6237\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 22.1513 - acc: 0.6556\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 21.1284 - acc: 0.6340\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 21.0358 - acc: 0.6465\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 20.9220 - acc: 0.6465\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 20.8778 - acc: 0.6465\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 20.6952 - acc: 0.6465\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 20.6270 - acc: 0.6465\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 20.6415 - acc: 0.6465\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_te.load(),\n",
    "    validation_steps=loader_te.steps_per_epoch,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfdacfd",
   "metadata": {},
   "source": [
    "#### Exercise 2.3.1\n",
    "\n",
    "Train a GCN with:\n",
    "\n",
    "* 32 channels \n",
    "* 6 layers\n",
    "* Adam optimizer (use the same learning rate, `LR`)\n",
    "\n",
    "Are the results better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f265e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loaders \n",
    "loader_tr = DisjointLoader(dataset_tr, batch_size=32, epochs=10)\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=32, epochs=1)\n",
    "\n",
    "######## YOUR CODE STARTS HERE ########\n",
    "model = ...\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = ...\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.CategoricalCrossentropy(reduction='sum'),\n",
    "    weighted_metrics=['acc'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_te.load(),\n",
    "    validation_steps=loader_te.steps_per_epoch,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be30e85a",
   "metadata": {},
   "source": [
    "## 3. Building a custom dataset\n",
    "\n",
    "To build your own dataset, you should store your data in a specific location. \n",
    "\n",
    "Locally it's: `~/.spektral/datasets/[ClassName]`\n",
    "\n",
    "You can overwrite it by defining the `path` property of a `Dataset` class. \n",
    "\n",
    "\n",
    "\n",
    "Path on **Colab**: `/usr/local/lib/python3.7/dist-packages/spectral/datasets`\n",
    "\n",
    "\n",
    "___________________________\n",
    "\n",
    "<img src=\"img/tensorcell.png\" width=150>\n",
    "\n",
    "<br>\n",
    "\n",
    "Now, we're going to look at a dataset class that we used in one of our experiments at [TensorCell](https://www.tensorcell.com/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "___________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bccdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorcellDataset(Dataset):\n",
    "    \n",
    "    \"\"\"A Tensorcell dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_variant, allow_self_loops=True, circular_mapping=False, add_constant_feature=False, add_one_hot_index=False, **kwargs):\n",
    "        \"\"\"\n",
    "        :param dataset_variant: A dataset to pick. Currently takes: `ochota_100k`, `centrum_100k`, `mokotow_100k`\n",
    "        :type dataset_variant: str\n",
    "        :param circular_mapping: If node values should be mapped to a unit circle\n",
    "        :type circular_dataset: bool\n",
    "\n",
    "        ...\n",
    "        :return: None\n",
    "        :rtype: None\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_variant = dataset_variant\n",
    "        self.allow_self_loops = allow_self_loops\n",
    "        self.circular_mapping = circular_mapping\n",
    "        self.add_constant_feature = add_constant_feature\n",
    "        self.add_one_hot_index = add_one_hot_index\n",
    "        \n",
    "        # Construct filenames\n",
    "        dataset_info = dataset_variant.split('_')\n",
    "        district = dataset_info[0]\n",
    "        n_rows = dataset_info[1]\n",
    "        \n",
    "        self.filename_A = f'{district}_A.txt'\n",
    "        self.filename_Xy = f'{district}_X_{n_rows}.txt'\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        :return: output\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        \n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "        \n",
    "        # Read files\n",
    "        adjacency_matrix = np.loadtxt(os.path.join(self.path, self.filename_A))\n",
    "        features = np.loadtxt(os.path.join(self.path, self.filename_Xy), delimiter=',')\n",
    "\n",
    "        # Add/remove self loops in the adjacency matrix\n",
    "        if self.allow_self_loops:\n",
    "            np.fill_diagonal(adjacency_matrix, 1)\n",
    "        else:\n",
    "            np.fill_diagonal(adjacency_matrix, 0)\n",
    "\n",
    "        \n",
    "        # Construct graph objects\n",
    "        for row in range(features.shape[0]):\n",
    "\n",
    "            # If `circular_mapping` -> map to a circular representation\n",
    "            if self.circular_mapping:\n",
    "                x = self.get_circular_components(features[row, :-1]).T\n",
    "            else:\n",
    "                x = features[row, :-1][:, np.newaxis]\n",
    "\n",
    "            # Add constant feature 1\n",
    "            if self.add_constant_feature:\n",
    "                x = np.hstack([x, np.ones(x.shape[0])[:, np.newaxis]])\n",
    "\n",
    "            # Add one-hot encoded node label\n",
    "            if self.add_one_hot_index:\n",
    "\n",
    "                x_plus_oh = []\n",
    "\n",
    "                for i, d in enumerate(x):\n",
    "                    one_hot_index = np.zeros(x.shape[0])\n",
    "                    one_hot_index[i] = 1\n",
    "                    x_plus_oh.append(np.hstack([d, one_hot_index]))\n",
    "\n",
    "                x = np.array(x_plus_oh)\n",
    "\n",
    "            # Construct a graph \n",
    "            output.append(\n",
    "                Graph(\n",
    "                    x=x, \n",
    "                    a=adjacency_matrix, \n",
    "                    y=features[row, -1])\n",
    "            )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorcellDataset('ochota_100k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-spektral-minimal]",
   "language": "python",
   "name": "conda-env-tf-spektral-minimal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
